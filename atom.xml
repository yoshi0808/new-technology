<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>New technologies in our life</title>
  
  <subtitle>Device,Network,Code,etc...</subtitle>
  <link href="https://yoshi0808.github.io/new-technology/atom.xml" rel="self"/>
  
  <link href="https://yoshi0808.github.io/new-technology/"/>
  <updated>2024-06-26T21:22:07.373Z</updated>
  <id>https://yoshi0808.github.io/new-technology/</id>
  
  <author>
    <name>阿部　吉伸(Yoshinobu ABE)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ubiquiti Cloud Gateway Ultra</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/06/25/UCG-Ultra/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/06/25/UCG-Ultra/</id>
    <published>2024-06-25T01:20:00.000Z</published>
    <updated>2024-06-26T21:22:07.373Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/06/25/UCG-Ultra/0.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p><p>UniFiの新しい小型ゲートウェイUniFi Cloud Gatewayのセットアップ、機能紹介、ホームユーザー向けのセキュリティ対策の実例を掲載しています。検証のため製品提供を受けていますのでこの記事はPR要素を含みます。</p><span id="more"></span><h2 id="Cloud-Gateway-Ultra（UCG-Ultra）"><a href="#Cloud-Gateway-Ultra（UCG-Ultra）" class="headerlink" title="Cloud Gateway Ultra（UCG-Ultra）"></a>Cloud Gateway Ultra（UCG-Ultra）</h2><p>3月には、UniFi初心者向けにUniFi Express（UX）の導入に関する記事を記載しました。UXはワンルームなどの比較的限られた範囲のWi-FiとUniFiゲートウェイがAll in oneとなったハードウェアですが、新しく発売されたCloud Gateway Ultraは、 Wi-Fi APやネットワークスイッチなどを追加、拡張することを想定しているゲートウェイです。Ubiquiti製品の一番人気はなんといってもアクセスポイント（Wi-Fi）ですが、複数のAPをはじめ、スイッチも拡張を想定するユーザーが購入対象となるでしょう。米国では$129と極めて廉価です。</p><p>手短にUCG-Ultraを説明すると以下の通りです。</p><blockquote class="blockquote-center"><p>30以上のUniFiデバイス&#x2F;300以上のクライアントサポート、1 Gbps IPSルーティング、およびマルチWANロードバランシングを備えたコンパクトなCloud Gateway</p></blockquote><p> 日本におけるUbiquitiの知名度もだいぶ上がってきたと感じています。これからUniFiを導入したいユーザーとしては、まず通信の見える化のためにUniFiゲートウェイを導入し、随時、人気のあるAPを追加していきたいと考えられているのではないでしょうか。私個人としては、UCG-UltraはIDS&#x2F;IPSも装備されているので自宅環境のセキュリティ面の強化という意味で期待ができるものと考えています。</p><h2 id="UCG-Ultraの説明ページ"><a href="#UCG-Ultraの説明ページ" class="headerlink" title="UCG-Ultraの説明ページ"></a>UCG-Ultraの説明ページ</h2><p>製品の説明ページは以下になります。</p><blockquote><p>UCG-Ultra<br> <a href="https://jp.store.ui.com/jp/ja/pro/category/cloud-gateways-compact/products/ucg-ultra">https://jp.store.ui.com/jp/ja/pro/category/cloud-gateways-compact/products/ucg-ultra</a></p></blockquote><ul><li>WAN:2.5GbE RJ45ポートx 1</li><li>LAN:GbE RJ45ポートx 4</li><li>IDS&#x2F;IPSスループット1Gbps</li><li>LTEバックアップによる追加のインターネットフェイルオーバー</li><li>アプリケーション認識ファイアウォールルール</li><li>シグネチャベースのIDS&#x2F;IPS脅威検出</li><li>コンテンツ、国、ドメイン、広告のフィルタリング</li><li>VLAN&#x2F;サブネットに基づくトラフィックセグメンテーション</li><li>完全なステートフルファイアウォール</li><li>ワンクリックのTeleportおよびIdentity VPN</li></ul><h2 id="この記事でのインターネットの構成"><a href="#この記事でのインターネットの構成" class="headerlink" title="この記事でのインターネットの構成"></a>この記事でのインターネットの構成</h2><p>私はauひかりホーム（10ギガ）を導入しており、貸与されたホームゲートウェイ（HGW）があります。その後ろにUCG-Ultraを配置する形式となります。</p><img src="/new-technology/2024/06/25/UCG-Ultra/diaglam.drawio.png" class="" width="240" title="alt"><h2 id="セットアップ"><a href="#セットアップ" class="headerlink" title="セットアップ"></a>セットアップ</h2><p>UCG-Ultraはスマホだけでセットアップ可能です。アプリをダウンロードし、Bluetoothで接続して行います。</p><p>製品と付属品です。本体、電源ケーブル、30cmのLANケーブルが付属します。</p><img src="/new-technology/2024/06/25/UCG-Ultra/2.png" class="" width="800" title="alt"><p>PortはWAN（2.5Gbps）x1、LAN（1Gbps）x4です。</p><img src="/new-technology/2024/06/25/UCG-Ultra/3.png" class="" width="800" title="alt"><p>さて、説明書のQRコードをiPhoneのカメラで読み込み、スマホアプリ（UniFi）をダウンロードしましょう。</p><p>Ubiquitiのアカウントを作成します。<br><a href="https://account.ui.com/login">https://account.ui.com/login</a></p><p>スマホアプリUniFiを起動後、UIアカウントにログインします。スマホアプリがBluetooth経由でUCG-Ultraを見つけると画面にセットアップ開始を促します。</p><img src="/new-technology/2024/06/25/UCG-Ultra/6.png" class="" width="360" title="alt"><img src="/new-technology/2024/06/25/UCG-Ultra/8.png" class="" width="360" title="alt"><p>UCG-UltraにはWi-Fiは無いので、UCG-Ultraの名前を決めたらセットアップが完了します。また、途中インターネット速度テストが行われ、さらにファームウェアのアップデートが自動で行われていきます。</p><img src="/new-technology/2024/06/25/UCG-Ultra/9.png" class="" width="360" title="alt"><p>WAN　Portの速度である2.5Gbpsの速度がきちんと出ています。</p><img src="/new-technology/2024/06/25/UCG-Ultra/10.png" class="" width="360" title="alt"><p>あっさりとセットアップ完了です。</p><img src="/new-technology/2024/06/25/UCG-Ultra/11.png" class="" width="360" title="alt"><p>ファームウェアの自動更新が行われます。</p><img src="/new-technology/2024/06/25/UCG-Ultra/11-1.png" class="" width="800" title="alt"><p>ここまで、全く迷うことがありません。</p><h2 id="初期画面"><a href="#初期画面" class="headerlink" title="初期画面"></a>初期画面</h2><p>さて、アプリの表記では、HGWのDHCPによって割り当てられた<code>192.168.0.2</code>というUCG-UltraのWAN側IPアドレス、および、LAN側のIPアドレス<code>192.168.1.1</code>が振られています。</p><img src="/new-technology/2024/06/25/UCG-Ultra/12.png" class="" width="360" title="alt"><p>LANのネットワーク、WANの情報が表示されています。LANはデフォルトVLANが1となっています（かつネイティブVLAN（タグ無し）。<br>WANにはバックアップとしてのSecondary表記があります。今回はPrimaryをauひかりに接続していますが、別の回線または公衆回線（SIMを使う無線ルーター）に接続できます。</p><img src="/new-technology/2024/06/25/UCG-Ultra/13.png" class="" width="360" title="alt"><mark class="label primary">設定</mark>から、<mark class="label primary">コンソール</mark>を選択すると、<mark class="label primary">コンソール管理</mark>画面が表示されます。UniFi OSはv3.2.18となっていますが、Networkアプリケーション（UNA）はUpdate可能なようです。早速Updateをタップします。<img src="/new-technology/2024/06/25/UCG-Ultra/14.png" class="" width="360" title="alt"><p>UCG-UltraのUNAはv8.2.93となりました。</p><p>今回は初回操作なので手動でアップデートすることにしましたが、毎日夜中3時に自動でアップデートチェックが行われ、自動でアップデートされます。また、Release Channelについては、”Official”(通常）、”Release Candidate”（リリース候補）、あとはUIアカウントのページから”Early Access”(ベータ版）を有効にすれば、3つのバージョンを選択できます。</p><blockquote><p>UI Account<br> <a href="https://account.ui.com/profile">https://account.ui.com/profile</a></p></blockquote><p>慣れるまではOfficialにしておくのがお勧めです。<br>Early Accessは事前確認する利用条件にある通り、守秘義務が存在します。許可なくその内容を第三者に開示してはいけません。安定しない場合も多く、広くユーザーに互換性を確認してもらうためのものです。</p><p>さて、ここまでで初期セットアップは完了です。<br>この段階でUCG-Ultraはインターネットへ接続可能になっているので、設定で利用したスマホアプリはUbiquitiクラウド経由でUCG-Ultraの操作が可能となっています。自宅でも外出中でもUCG-Ultraを操作できます。Cloud Gatewayという名前に相応しい基本機能です。</p><h2 id="セットアップの補足"><a href="#セットアップの補足" class="headerlink" title="セットアップの補足"></a>セットアップの補足</h2><p>私の環境（auひかり）ではとても簡単にセットアップが完了しました。なお、UniFiのゲートウェイ全般は現在、Officialリリースにおいてインターネットマルチフィード社が提供するtransix IPv4接続 (DS-Lite) への対応はされていますが、その他のIPv4 over IPv6の対応は現時点でサポート外となっています。</p><p>UniFiゲートウェイに関するガイドを以下に記載します。</p><ul><li><p>ネットワークが不安定、Lineなどでやり取りができなくなる。<br> 以下のガイドにMSS Clampingの設定で解決するという投稿がありますので確認ください。<br> Facebook Ubiquiti日本公式コミュニティ<br> <a href="https://www.facebook.com/groups/uijapan/learning_content/?filter=167949146143924&amp;post=3507234616157550">https://www.facebook.com/groups/uijapan/learning_content/?filter=167949146143924&amp;post=3507234616157550</a><br> この設定についてはUCG-Ultraにブラウザでログインし、WANのMSS Clampingの値をCustomの1414や1420等に設定する必要があります。具体的な設定はISPにより異なります。</p></li><li><p>IPv6 IPoE transix IPv4 (DS-Lite)の設定手順｜Ubiquiti UniFi<br> <a href="https://note.com/ui_japan/n/n3154ff641db5">https://note.com/ui_japan/n/n3154ff641db5</a></p></li></ul><p>インターネットマルチフィードのDS-Liteは以下のISPが対象となります。</p><ul><li>株式会社インターネットイニシアティブ<br> IIJ IPv6 FiberAccess&#x2F;Fサービス タイプIPoE</li><li>株式会社インターネットイニシアティブ<br> IIJmioひかり</li><li>株式会社インターネットイニシアティブ<br> IIJmio FiberAccess&#x2F;NF</li><li>株式会社インターリンク<br> ZOOT NATIVE</li><li>エキサイト株式会社<br> excite MEC光</li><li>エキサイト株式会社<br> BB.excite光Fit</li><li>エキサイト株式会社<br> BB.exciteコネクトIPoE接続プラン</li><li>スターティア株式会社<br> マネージドゲート2</li><li>メディアウェイブシステムズ株式会社<br> Hybrid64 (ハイブリッド・ろくよん）</li><li>メディアウェイブシステムズ株式会社<br> メディアひかり</li></ul><p>（引用： <a href="https://www.mfeed.ad.jp/transix/customers/">https://www.mfeed.ad.jp/transix/customers/</a>）</p><p>FacebookのUbiquiti日本公式コミュニティの情報によれば、ASAHIネットなど、対応ISPを増やす対応に取り組まれているようです。なお、PPPoEやDS-Liteのデータ転送時に、MSSの調整、すなわちデータ部分を切り詰める必要が発生するのは仕方のない事です。ネットワーク機器は専用チップ（ASIC)が処理する事が基本であり、CPUがデータ処理すると、途端にパフォーマンスがダウンしてしまいます。これは一般的に考えられるよりもネットワーク機器のCPUが非力なためです。UCG-UltraはUXよりCPUが強化され、IDS&#x2F;IPSが実行できるようになりましたが、それでもスマホ相当であり、小型PCと比較しても非力です。</p><table><thead><tr><th>CPU</th><th>CPU Mark</th></tr></thead><tbody><tr><td>ARM Cortex-A53 4 Core 1512 MHz※UCG-Ultra</td><td>472</td></tr><tr><td>Intel   Celeron J1900 @ 1.99GHz</td><td>1,150</td></tr><tr><td>Intel N100</td><td>5,552</td></tr></tbody></table><blockquote><p>Passmark software<br> <a href="https://www.cpubenchmark.net/cpu_list.php">https://www.cpubenchmark.net/cpu_list.php</a></p></blockquote><p>日本は世界の中でも通信速度においては先進的であり、日本のユーザーの目線が高いのは事実です。PPPoEが存在するのは日本に限った話ではありませんが、PPPoEとIDS&#x2F;IPSとを併用するとCPUパワーも必要になりパフォーマンスの問題は発生しやすいようです。<br>UCG-Ultraの技術仕様のIDS&#x2F;IPSの項には「<strong>ISP の実装によって PPPoEでは性能が低下する可能性があります。</strong>」と記載されています。</p><p>私が利用しているauひかりは、PPPoEやDS-Liteを使わず1,500バイトをLAN同様に転送できますので、パフォーマンスの問題は発生しません。他にもCATVなどもこういった問題にはあまり関わる事がありません。一方、DS-LiteなどではIPv6の複数サブネットの配布（Prefix Delegation）は魅力的なのも事実でありISPの選定は悩ましいものがあります。</p><p>なお、ここではIPv6の説明は割愛しますが、auひかりのホームゲートウェイ（HGW）からUXにPrefix DelegationでIPv6サブネットを1つ割り振る設定を以下の記事で記載しています。その他、通知機能やSSH、プライベートDNS、VPNなどの基本設定についても記載しています。</p><ul><li><a href="/new-technology/2024/03/06/unifi-express/" title="UniFi Express">UniFi Express</a></li><li><p>Ubiquiti日本公式コミュニティ<br> <a href="https://www.facebook.com/groups/uijapan">https://www.facebook.com/groups/uijapan</a></p></li></ul><p>初期セットアップは終了し、Windows PCをUCG-Ultraに繋いで、IPv4、IPv6の割り当てが確認できました。</p><img src="/new-technology/2024/06/25/UCG-Ultra/wan.png" class="" width="1024" title="alt"><p>Windowsは以下のようにIPアドレスが振られています。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Windows IP 構成</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">イーサネット アダプター イーサネット:</span><br><span class="line"></span><br><span class="line">   接続固有の DNS サフィックス . . . . .: localdomain</span><br><span class="line">   IPv6 アドレス . . . . . . . . . . . .: 240f:103:xxxx:3:17f7:xxxx:xxxx:4c40</span><br><span class="line">   一時 IPv6 アドレス. . . . . . . . . .: 240f:103:xxxx:3:2594:xxxx:xxxx:e4c7</span><br><span class="line">   リンクローカル IPv6 アドレス. . . . .: fe80::7baf:af2:aa9:55a0%18</span><br><span class="line">   IPv4 アドレス . . . . . . . . . . . .: 192.168.1.170</span><br><span class="line">   サブネット マスク . . . . . . . . . .: 255.255.255.0</span><br><span class="line">   デフォルト ゲートウェイ . . . . . . .: fe80::xxxx:xxff:fexx:xxxx%18</span><br><span class="line">                                          192.168.1.1</span><br></pre></td></tr></table></figure><h2 id="UCG-Ultraを利用したセキュリティ強化"><a href="#UCG-Ultraを利用したセキュリティ強化" class="headerlink" title="UCG-Ultraを利用したセキュリティ強化"></a>UCG-Ultraを利用したセキュリティ強化</h2><h3 id="UCG-Ultraは何が出来るのか"><a href="#UCG-Ultraは何が出来るのか" class="headerlink" title="UCG-Ultraは何が出来るのか"></a>UCG-Ultraは何が出来るのか</h3><p>セキュリティに関しては話をシンプルにするため、一旦IPv4のみ割り当てが行われた状態で確認していきます。</p><h4 id="ジオロケーション"><a href="#ジオロケーション" class="headerlink" title="ジオロケーション"></a>ジオロケーション</h4><p>IPアドレスによる国別の認識が出来ています。</p><img src="/new-technology/2024/06/25/UCG-Ultra/geo.png" class="" width="1024" title="alt"><h4 id="トラフィック識別"><a href="#トラフィック識別" class="headerlink" title="トラフィック識別"></a>トラフィック識別</h4><img src="/new-technology/2024/06/25/UCG-Ultra/traffic.png" class="" width="1024" title="alt"><p>IDS&#x2F;IPSの設定をしていない初期設定状態でもトラフィックの識別はできています。この状態でのPCのスピードテストはワイヤレート（下り947Mbps&#x2F;上り942Mbps）の速度が出ています。</p><h4 id="IDS-IPS"><a href="#IDS-IPS" class="headerlink" title="IDS&#x2F;IPS"></a>IDS&#x2F;IPS</h4><p>IDS&#x2F;IPSの説明は以下の通りです。</p><table><thead><tr><th>略称</th><th>名称</th><th>動作</th></tr></thead><tbody><tr><td>IDS</td><td>Intrusion Detection System</td><td>アラートのみ</td></tr><tr><td>IPS</td><td>Intrusion Prevension System</td><td>防御（当該通信をReset）</td></tr></tbody></table><p>一般的にブラウザで利用するトラフィックは一般的に9割以上がhttps通信と言われており、SSL&#x2F;TLSにより暗号化されています。暗号化されている通信はその間にUCG-Ultraが入り込んでも情報を奪取できません。それでもトラフィック識別ができているのは、接続先のIPアドレスに加え、SSL&#x2F;TLSによるハンドシェイク時にリクエストされるSNI（Server Name Indicator）が平文で相手のFQDNをリクエストするため、どんなアプリケーションを利用しているのか判定する事が可能になっています。例えば、Appleのサイトにhttps接続する場合に最初のハンドシェイク時にSNIの情報が確認できます。</p><img src="/new-technology/2024/06/25/UCG-Ultra/wireshark.png" class="" width="1024" title="alt"><p>UCG-Ultraで識別が不能な場合は、UniFiのトラフィック識別においてSSL&#x2F;TLSで一括りとなっています。またhttps通信をTCPではなくUDPを使い高速化したQUICプロトコルもあります。セキュリティレベルの高い事業者では、このQUICを認めないなどもある一方でGoogle系サービス（Gmail、Youtube）や国内の大手報道機関ではQUICプロトコルが採用されています。正直、SSL&#x2F;TLS、QUICが通信の大半と予想されます。</p><p>ユーザーとしては疑わしい通信は排除するIPSが一般的に使われます。しかしながら前述の通り暗号化された通信が大半である環境下において、IPSがシグネチャベースで検出する能力を持っていても、暗号化されたパケットは検査できません。これを実現するならばSSL&#x2F;TLSインスペクションといったSSL&#x2F;TLS解析の仕組みが必要ですが、大量のCPUリソースを使うことや端末毎にCA証明書のインストールが必要であるため個人向けには一般的ではありません。</p><p>マルウェアやウィルスが配布されるような危険なサーバーに接続しようとしたところでDNSやIPS（SNIによる接続先検証）で防御することがまずはホームユーザー向けの対策と言えるでしょう。</p><h4 id="広告ブロック"><a href="#広告ブロック" class="headerlink" title="広告ブロック"></a>広告ブロック</h4><p>UNAの設定（歯車アイコン）から、<mark class="label primary">セキュリティ</mark>を選択します。<br>ここでは<mark class="label primary">広告ブロック</mark>にチェックしておきます。他に追加の設定は不要です。<br>DNSシールドはDNSによる名前解決時にDoH（DNS over HTTPS）を使い、GoogleまたはCloudflareで名前解決するものです。TLS&#x2F;SSLで暗号化されているので、プロバイダや途中の経路において、どこにアクセスしているのか判らないようにする目的があります。日本のISPはDDoS対策のために独自のDNSフィルタを実施していることや、その情報を売却するなどの行為が厳しいために日本においてはDNSシールドの重要性はあまり無いものと考えられます。<br>なお、このDNSフィルタを使っていても、広告ブロックは有効です。</p><h3 id="UCG-Ultraを使ったセキュリティの高め方"><a href="#UCG-Ultraを使ったセキュリティの高め方" class="headerlink" title="UCG-Ultraを使ったセキュリティの高め方"></a>UCG-Ultraを使ったセキュリティの高め方</h3><p>UCG-Ultraを使ってどのようにセキュリティを高めるかという観点では、使える機能は使うべきということになるでしょう。利用することで特にデメリットとなることはパフォーマンスに関する観点くらいだと考えられます。</p><ul><li>IoT機器をお持ちであれば、PCなど多くのInternetとやり取りする機器とはネットワークを分離する。同様にリモートワークで使う会社貸与のPCなども自分が所有するPCとは分離することをお勧めします。これはタグVLANを設定し実現します。UniFiのAPを使うことでさらにSSID毎に属するVLANを変えられます。</li><li>広告フィルタを行う。これは広告サイトが必ずしも安全とは言えないこと、不要なトラフィックが減らせます。</li><li>IPSでリスクのあるサイトをブロックする。不要なVPNサイトが止められリスクを軽減できます。</li><li>国別フィルタを使って不要国を止める。米国から一定量の攻撃がある事からも米国を止めるのは現実的でありませんが、普段アクセスしない国が明確なのであれば停止すべきでしょう。</li></ul><h3 id="国別フィルタ、IPSの具体例"><a href="#国別フィルタ、IPSの具体例" class="headerlink" title="国別フィルタ、IPSの具体例"></a>国別フィルタ、IPSの具体例</h3><p>設定はとても簡単です。一例としては以下の通りです。</p><img src="/new-technology/2024/06/25/UCG-Ultra/ips.png" class="" width="640" title="alt"><p>フィルタリングは通知とブロック（IPS相当）とし、検出感度は高めに設定してあります。<br>さらに、ネットワーク（LAN）の画面からコンテンツフィルタを有効にします。</p><img src="/new-technology/2024/06/25/UCG-Ultra/lan.png" class="" width="640" title="alt"><p>コンテンツフィルタリングは仕事、家族と選択できますが、家族にしておけばVPNを止められます。</p><p>国別フィルタは、フィルタをすり抜ける可能性もあります。中国のメーカーであっても、サーバーをAkamai（セキュリティベンダー）上に構築していたり、コンテンツデリバリネットワーク（CDN）やCloudflareにあれば同様に判定が難しくなります。</p><p>また、危険なサイトに関する情報についてはIPv4に関しては情報共有は積極的に行われるものの、IPv6についてはその情報共有が少ないのが実情です。今後、IPv6のコンテンツフィルタ機能が拡充されたとしても、IPv4だけのネットワークの方がセキュリティ上は安全ともいえるジレンマを抱えることになります。</p><p>UCG-Ultraではロシアや中国企業のWebサイトでアクセスできない（パケットは拒否される）事を確認できています。フィッシングの手口ではこれらの国はよく使われるため、これらの抑止策はフェールセーフとして期待できます。</p><p>私の環境ではこの設定を行った上でのInternet速度テストは以下の通りでした。</p><img src="/new-technology/2024/06/25/UCG-Ultra/speedtest2.png" class="" width="320" title="alt"><p>ダウンロードが947Mbpsから925Mbpsに下がりましたが、殆ど誤差でしょう。私の環境だと、パフォーマンスを意識してセキュリティレベルを下げる必要は無さそうです。</p><p>(2024-06-27追記)<br>なお、UCG-Ultraのスペックシートでは、IPS利用時に1Gbpsのルーティング機能とある通り、LANからWANへのスループットはクライアントを2台同時に利用した場合、上限はスペック通り合計で1Gbps程度です。セットアップ時は特に気にしていなかったのですが、IPSを外してみた場合のクライアント2台でもやはり1Gbps。運用としてはIPSを使う事が前提となるので結果は変わらないのでしょうが、WAN Portが2.5Gbpsであるにも関わらずLAN-WANのスループットが1Gbpsというのは少し疑問が残りました。前述した通り、UCG-Ultra本体からのスピードテストは2.5Gbpsワイヤレートしっかりと出ているのですが。</p><h3 id="アプリケーションのブロックとFirewallのブロック"><a href="#アプリケーションのブロックとFirewallのブロック" class="headerlink" title="アプリケーションのブロックとFirewallのブロック"></a>アプリケーションのブロックとFirewallのブロック</h3><p>UniFiゲートウェイには、アプリケーションタイプでの制御（許可、ブロック）と従来型のFirewallのネットワーク、Port単位の制御の2通りがあります。Ubiquitiはそれぞれ、<mark class="label primary">シンプル</mark>、<mark class="label primary">高度な</mark>と分かれています。<mark class="label primary">シンプル</mark>の方がアクセス統計のアプリから止められるため直感的で簡単です。ネットワークに慣れている方は従来のIPネットワーク、Portで止める方法もあります。ただ、自宅でサーバーを立てる時にPort8443などでWebサーバーを立てる事が多いように、必ずしもSSL&#x2F;TLSがPort443とは限りません。そういう意味ではアプリケーションで止めていく方が時代の流れには沿っていると考えられます。</p><p>シンプルのルール表示の例です。</p><img src="/new-technology/2024/06/25/UCG-Ultra/fw1.png" class="" width="1024" title="alt"><p>高度なルール表示の例です。</p><img src="/new-technology/2024/06/25/UCG-Ultra/fw2.png" class="" width="1024" title="alt"><p>シンプルなルールでInternetに出ていくアプリケーションのうち、DNS(53&#x2F;TCP,UDP)、DoT（DNS over TLS(853&#x2F;TCP)）、DoH（DNS over HTTPS(443&#x2F;TCP)）とを止めるルールです。基本的にDNSはUCG-UltraがInternetに名前解決を問い合わせするため、クライアントがInternetとDNSで直接セッションを張る必要はないとして、ブロックするルールです（ユーザーの考え方次第でこのルールが多くの人に適合するというわけではありません）。</p><img src="/new-technology/2024/06/25/UCG-Ultra/fw3.png" class="" width="640" title="alt"><p>従来型のファイアウォール設定、つまり高度なルールの設定です。Port 53&#x2F;TCP,UDPをInternetに出ていくものをブロックする設定を保険的に明示しています。</p><img src="/new-technology/2024/06/25/UCG-Ultra/fw4.png" class="" width="640" title="alt"><p>高度なルールでDoTはPort853を指定して止める方法はありますが、DoHは暗号化されているのでファイアウォールでは検出不可能です。しかし、UCG-UltraはDoHの接続先（SNI)を見てブロックしているものと考えられ、シンプルなルールを使うことで簡単にアクセス制御ができます。</p><p>最近はサイバーの脅威保護にDNSを使って情報資産を保護する取り組みは多い一方、ブラウザを提供しているITベンダーは広告を回避されたくないためユーザーが指定したDNSを参照せず、ベンダーが提供するDNSを（DoHを使って）参照しようとします。DoHでユーザーが用意したDNSの広告ブロックをバイパスするためです。ただこれがサイバー対策を迂回されてしまうリスクにもなります。</p><p>SSL&#x2F;TLSインスペクションを使ったとしても完璧ではなく、最終的にはセキュリティ機器がどれだけ早く脅威情報を取り込めるかどうかに掛かっています。個人に対するサイバー攻撃で一番多いのはフィッシング詐欺です。このような仕組みでセキュリティを高めることに加え、多要素認証などを組み合わせる事でフィッシングの脅威から保護する事が重要です。</p><blockquote><p>Ubiquiti Deep Dive into Advanced Firewall Rules<br> <a href="https://help.ui.com/hc/en-us/articles/115003173168-Deep-Dive-into-Advanced-Firewall-Rules">https://help.ui.com/hc/en-us/articles/115003173168-Deep-Dive-into-Advanced-Firewall-Rules</a></p></blockquote><h3 id="仮想ネットワーク（VLAN）"><a href="#仮想ネットワーク（VLAN）" class="headerlink" title="仮想ネットワーク（VLAN）"></a>仮想ネットワーク（VLAN）</h3><p>前述した通り、IoT機器などのために、普段使うネットワークと分離するために新しいネットワークを作成できます。私の場合、ChromebookやAmazon Echo、Amazon FireTVなどは全てゲストネットワークとして、PCやスマホで普段使うネットワークとは分離しています。<br>UniFiでは「仮想ネットワーク」としてVLANを定義しています。ネットワークの設定から「新しい仮想ネットワーク」を選択します。</p><img src="/new-technology/2024/06/25/UCG-Ultra/guest.png" class="" width="1024" title="alt"><p>ここでの例はGuestという名前を付けました。ネットワークアドレスは<code>192.168.10.0/24</code>、IPアドレスの第3オクテットに合わせてVLAN IDは10としています。ネットワーク分離を有効にし、Defaultネットワークとはお互いにルーティングできないようにしつつもInternetへのアクセスは可能としています。DHCPも有効になります。</p><p>続いてPortマネージャーから、UCG-Ultraのポートを設定変更します。ここでは単一の端末を接続できるための設定をします。</p><img src="/new-technology/2024/06/25/UCG-Ultra/port.png" class="" width="1024" title="alt"><p>ネイティブVLANネットワークはguestを選択します。つまりタグ10のVLANをネイティブ（タグ無し）として設定します。さらに他のネットワーク（Default)のパケットがタグ付きで外に出て行かないように、タグ付きVLAN管理の項目は<mark class="label primary">すべてをブロック</mark>にチェックを付けておきます。</p><p>この2か所の設定で、Port2に端末を接続することで上記で作成したネットワーク（VLAN&#x3D;10)のIPアドレスが割り当てられます。<br>以下はUCG-UltraのPort2に接続したChromebookの画面です。</p><img src="/new-technology/2024/06/25/UCG-Ultra/chromebook.png" class="" width="480" title="alt"><p>これでIoTはインターネットにはアクセスできますが、自宅の重要な機器とは分離されます。PCがマルウェアに感染し、やがてセキュリティ上脆弱なIoTに感染してしまうということを防止できます。その逆も然りです。</p><p>NASやサーバーがある場合、Default、ゲストだけでなく、サーバー用のVLANを作成し、Defaultとサーバーとは高度なファイアウォールを使用し、最低限度のプロトコルを通すなどすればよりセキュアな環境が整います。</p><p>また、今回は詳細の説明を割愛しますが、ルーティング機能も業務レベルの機能が用意されています。</p><img src="/new-technology/2024/06/25/UCG-Ultra/routing.png" class="" width="1024" title="alt"><p>特定のドメインや地域などでルーティング先を変えるポリシーベースのルーティングやOSPF、L3スイッチなどを追加した場合の静的ルーティングに加え、DNSのカスタム設定（Aレコードだけではなく、MX、CNAME）などネットワーク機器としてはかなり多機能です。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>今回は、Cloud Gateway Ultraをセキュリティの観点から検証してみました。今後APやネットワークスイッチを導入する小型ネットワークを敷設される場合には候補になるプロダクトであると考えられます。</p><blockquote><p>UI Japan Store Cloud Gateway Ultra<br><a href="https://jp.store.ui.com/jp/ja/pro/category/cloud-gateways-compact/products/ucg-ultra">https://jp.store.ui.com/jp/ja/pro/category/cloud-gateways-compact/products/ucg-ultra</a></p></blockquote><p>価格は23,899円です。</p><h2 id="Interop24"><a href="#Interop24" class="headerlink" title="Interop24"></a>Interop24</h2><p>6月12日〜14日の幕張で行われたInterop24でUbiquiti製品が紹介されていましたので、写真を撮ってきました。</p><p>UXG-LiteとUCG-Ultra（これだとサイズ感が分からないですね。。。）</p><img src="/new-technology/2024/06/25/UCG-Ultra/interop1.png" class="" width="1024" title="alt"><p>PoEスイッチ　Switch Ultra</p><img src="/new-technology/2024/06/25/UCG-Ultra/interop2.png" class="" width="1024" title="alt"><p>UCG-UltraはPoEを持っていないので、UniFi APを接続する際は、別途PoEアダプタが必要となります。このSwitch UltraはPoEによる電源供給ができるのでAPや監視カメラなどを将来的に拡張していくのにちょうど良いスイッチかもしれません。</p><blockquote><p>Switch Ultra<br> <a href="https://jp.store.ui.com/jp/ja/pro/category/switching-utility/collections/pro-ultra">https://jp.store.ui.com/jp/ja/pro/category/switching-utility/collections/pro-ultra</a></p></blockquote><h2 id="補足説明"><a href="#補足説明" class="headerlink" title="補足説明"></a>補足説明</h2><blockquote><p>Ubiquiti Japan ホームページ<br> <a href="https://note.com/ui_japan">https://note.com/ui_japan</a></p></blockquote><blockquote><p>Ubiquiti コミュニティ（日本）<br> <a href="https://www.facebook.com/groups/uijapan">https://www.facebook.com/groups/uijapan</a></p></blockquote><blockquote><p>Ubiquiti Community（米国中心）<br> <a href="https://community.ui.com/">https://community.ui.com/</a></p></blockquote><p>（製品提供：Ubiquiti Japan株式会社）</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/06/25/UCG-Ultra/0.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;
&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;UniFiの新しい小型ゲートウェイUniFi Cloud Gatewayのセットアップ、機能紹介、ホームユーザー向けのセキュリティ対策の実例を掲載しています。検証のため製品提供を受けていますのでこの記事はPR要素を含みます。&lt;/p&gt;</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    <category term="Network" scheme="https://yoshi0808.github.io/new-technology/categories/Network/"/>
    
    
    <category term="UniFi" scheme="https://yoshi0808.github.io/new-technology/tags/UniFi/"/>
    
  </entry>
  
  <entry>
    <title>Sophos Firewall v20 MR1</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/06/08/xg-v20mr1/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/06/08/xg-v20mr1/</id>
    <published>2024-06-07T19:01:00.000Z</published>
    <updated>2024-06-08T03:15:09.397Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/06/08/xg-v20mr1/Title.png" class="" title="alt"><h2 id="Sophos-Firewall-v20"><a href="#Sophos-Firewall-v20" class="headerlink" title="Sophos Firewall v20"></a>Sophos Firewall v20</h2><p>Sophos Firewall v20 MR1が2024年05月15日に発表されました。デバイスからのアクセス制御でAD SSO, Captive Portal, RADIUS SSO, Client Authentication, Chromebookなどの認証制御が細かく設定できること、VPNのエンハンスが挙げられます。 </p><span id="more"></span><p>v20　MR1の詳細な説明はSophos Communityを参照してください。</p><blockquote><p><a href="https://community.sophos.com/sophos-xg-firewall/b/blog/posts/sophos-firewall-os-v20-mr1-is-now-available">https://community.sophos.com/sophos-xg-firewall/b/blog/posts/sophos-firewall-os-v20-mr1-is-now-available</a></p></blockquote><p>リリースノートはこちらです</p><blockquote><p><a href="https://docs.sophos.com/releasenotes/index.html?productGroupID=nsg&amp;productID=xg&amp;versionID=20.0">https://docs.sophos.com/releasenotes/index.html?productGroupID=nsg&amp;productID=xg&amp;versionID=20.0</a></p></blockquote><h2 id="Sophos-Firewallのアップデート"><a href="#Sophos-Firewallのアップデート" class="headerlink" title="Sophos Firewallのアップデート"></a>Sophos Firewallのアップデート</h2><p>管理画面にログイン後、左ペインメニューの<mark class="label primary">バックアップ＆ファームウェア</mark>の<mark class="label primary">ファームウェアの確認</mark>でアップデートの案内が順次来ます。</p><img src="/new-technology/2024/06/08/xg-v20mr1/mr1-1.png" class="" width="800" title="alt"><p>個別にバージョンアップのファイルを入手するには、以下のURLからダウンロードします。</p><p><a href="https://support.sophos.com/support/s/article/KB-000043162?language=en_US">https://support.sophos.com/support/s/article/KB-000043162?language=en_US</a></p><ol><li>上記画面で<mark class="label primary">Sophos Firewall</mark>の<mark class="label primary">ファームウェア</mark>の<mark class="label primary">ソフトウェア</mark>のLinkをクリックします。</li><li>“SW-20.0.1_MR-1.SFW-342.sig”をダウンロードします。</li><li>Sophos Firewallの管理画面にログインし、左ペインメニューの<mark class="label primary">バックアップ＆ファームウェア</mark>の<mark class="label primary">ファームウェアのタブメニュー</mark>から以下の画面に赤丸で囲った矢印のアイコンをクリックし、ダウンロードしたモジュールをアップロードします。</li></ol><img src="/new-technology/2024/06/08/xg-v20mr1/verup.png" class="" width="800" title="alt"><p>アップロード＆再起動ボタンをクリックし、v20 MR1へのアップグレードを完了させます。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/06/08/xg-v20mr1/Title.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;h2 id=&quot;Sophos-Firewall-v20&quot;&gt;&lt;a href=&quot;#Sophos-Firewall-v20&quot; class=&quot;headerlink&quot; title=&quot;Sophos Firewall v20&quot;&gt;&lt;/a&gt;Sophos Firewall v20&lt;/h2&gt;&lt;p&gt;Sophos Firewall v20 MR1が2024年05月15日に発表されました。デバイスからのアクセス制御でAD SSO, Captive Portal, RADIUS SSO, Client Authentication, Chromebookなどの認証制御が細かく設定できること、VPNのエンハンスが挙げられます。 &lt;/p&gt;</summary>
    
    
    
    <category term="Security" scheme="https://yoshi0808.github.io/new-technology/categories/Security/"/>
    
    
    <category term="XG Firewall" scheme="https://yoshi0808.github.io/new-technology/tags/XG-Firewall/"/>
    
  </entry>
  
  <entry>
    <title>Proxmox 8.2へのアップグレード</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/05/02/update-ProxmoxTo82/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/05/02/update-ProxmoxTo82/</id>
    <published>2024-05-02T13:58:30.000Z</published>
    <updated>2024-05-03T00:02:29.363Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/05/02/update-ProxmoxTo82/Title.png" class="" title="alt"><p class="onepoint">この記事で実現すること</p><p>2024-04-24にProxmox VE8.2が発表されています。ここではGUIでアップグレード（中身はapt upgrade）で説明するまでもないのですが、既知の不具合があり、ちょうど私のNIC（X710DA4）ではこの不具合の影響を受けることになったため、対応策についてまとめています。</p><span id="more"></span><h2 id="新機能"><a href="#新機能" class="headerlink" title="新機能"></a>新機能</h2><p>新機能については以下の通りです。</p><ul><li>Support for automated and unattended installation</li><li>Import wizard for VMware ESXi VMs</li><li>Modernized Firewall based on nftables</li><li>LXC device passthrough</li><li>Advanced Backup settings</li><li>Support for custom ACME-enabled CAs</li><li>UI improvements</li><li>Debian 12.5 (Bookworm), but using a newer Linux kernel 6.8;</li><li>New versions: QEMU 8.1, Ceph Reef 18.2, LXC 6.0, and Open ZFS 2.2;</li></ul><p>積極的にLinux Kernelのアップデートが行われていますね。</p><blockquote><p>Proxmox VE 8.2 What’s new<br> <a href="https://www.proxmox.com/en/services/videos/proxmox-virtual-environment/whats-new-in-proxmox-ve-8-2">https://www.proxmox.com/en/services/videos/proxmox-virtual-environment/whats-new-in-proxmox-ve-8-2</a></p></blockquote><h2 id="既知の不具合"><a href="#既知の不具合" class="headerlink" title="既知の不具合"></a>既知の不具合</h2><p>不具合については以下のページでまとめられています。</p><blockquote><p>Known Issues &amp; Breaking Changes<br> <a href="https://pve.proxmox.com/wiki/Roadmap#Proxmox_VE_8.2">https://pve.proxmox.com/wiki/Roadmap#Proxmox_VE_8.2</a></p></blockquote><p>IntelのNICでX710シリーズでは以下の影響を受けます。カーネル変更を受けてインタフェース名の末尾に<code>P0</code>という文字列が加わるとのこと。</p><p>Kernel: Change in Network Interface Names<br>Upgrading kernels always carries the risk of network interface names changing, which can lead to invalid network configurations after a reboot. In this case, you must either update the network configuration to reflect the name changes, or pin the network interface to its name beforehand.</p><p>See the reference documentation on how to pin the interface names based on MAC Addresses.</p><p>Currently, the following models are known to be affected at higher rates:</p><p>Models using i40e. Their names can get an additional port suffix like p0 added.</p><p>その他は、以下の項目が挙げられています。</p><ul><li>Kernel: DKMS(it may happen that installed DKMS modules will not build anymore)</li><li>Kernel: Split Lock Detection Slowing Down VMs</li><li>Old Ceph Crash Reports</li></ul><h2 id="アップグレード"><a href="#アップグレード" class="headerlink" title="アップグレード"></a>アップグレード</h2><p>ここでは8.1から8.2へのアップグレードを想定しています。<br>前述した通り、X710シリーズのNICをお持ちの方は、アップグレード後にネットワークインタフェース名の不一致によってネットワーク経由でProxmoxに到達できなくなります。従い、アップグレード後はモニタを接続し、ローカルのShellでネットワークインタフェース名を変更することになります。<br>GUIからは以下の通り実行します。その後再起動が必要です。</p><img src="/new-technology/2024/05/02/update-ProxmoxTo82/pve1.png" class="" title="alt"><p>Proxmoxのノードを選択の上、「アップデート」の項目から再表示し、アップグレードを実行します。</p><p>終了後、再起動させてアップグレード処理を完了させます。</p><h2 id="ネットワークインタフェースの変更"><a href="#ネットワークインタフェースの変更" class="headerlink" title="ネットワークインタフェースの変更"></a>ネットワークインタフェースの変更</h2><p>私の持っているインタフェースは8.1の時は以下の通りでした。</p><img src="/new-technology/2024/05/02/update-ProxmoxTo82/pve2.png" class="" title="alt"><p>8.2では以下になります（修正完了後）</p><img src="/new-technology/2024/05/02/update-ProxmoxTo82/pve3.png" class="" title="alt"><p>４つのインタフェースの末尾にnp0〜np3の文字列が加えられています。</p><p>さて、物理ノードにモニターを接続し、Proxmoxを起動します。</p><ol><li>ip address showで実際のインタフェース名を調べます。<code>ip a</code><br> 以下のように新しいカーネルでのインタフェース名を確認します。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2: enp1s0f0np0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq master vmbr0 state UP group default qlen 1000</span><br><span class="line">   <span class="built_in">link</span>/ether 3c:fd:fe:xx:xx:xx brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure></li><li>&#x2F;etc&#x2F;network&#x2F;interfacesファイルを修正します。ファイルのバックアップ取得をしてから実施をお勧めします。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@pve1:~<span class="comment"># cd /etc/network</span></span><br><span class="line">root@pve1:/etc/network<span class="comment"># cp interfaces interfaces.bak</span></span><br><span class="line">root@pve1:/etc/network<span class="comment"># vi interfaces</span></span><br></pre></td></tr></table></figure> viなどでinterfacesファイルの以下の項目を見つけインタフェース名を<code>ip a</code>で出力されたインタフェース名に合わせます。<br> ちょうど<code>bridge-ports</code>の行です。これをインタフェースの数だけ修正します（私の場合は4Portなので４つ）。   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">auto vmbr0</span><br><span class="line">iface vmbr0 inet static</span><br><span class="line">       address 192.168.2.x/24</span><br><span class="line">       gateway 192.168.2.x</span><br><span class="line">       bridge-ports enp1s0f0</span><br><span class="line">       bridge-stp off</span><br><span class="line">       bridge-fd 0</span><br></pre></td></tr></table></figure></li><li>ネットワークをリスタートします。<code>service networking restart</code></li></ol><p>これで対応は完了です。</p><h2 id="その他（古いカーネルでの起動）"><a href="#その他（古いカーネルでの起動）" class="headerlink" title="その他（古いカーネルでの起動）"></a>その他（古いカーネルでの起動）</h2><p>その他の何らかのトラブルでが発生した場合、古いカーネルで起動したい場合は、Bootメニューに古いカーネルが選択できます（UEFIのGRUB）。<br>今回の8.1からのアップグレードでは、古いカーネルは、6.5.13-5、新しいカーネルは、6.8.4-2でした。</p><p>もししばらく古いカーネルで起動したいということであれば、以下のコマンドで古いカーネルにピン留めできます。<br><code>proxmox-boot-tool kernel pin 6.5.13-5-pve</code></p><p>新しいカーネルに戻す時は以下のコマンドで元に戻します。<br><code>proxmox-boot-tool kernel pin 6.8.4-2-pve</code></p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/05/02/update-ProxmoxTo82/Title.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;2024-04-24にProxmox VE8.2が発表されています。ここではGUIでアップグレード（中身はapt upgrade）で説明するまでもないのですが、既知の不具合があり、ちょうど私のNIC（X710DA4）ではこの不具合の影響を受けることになったため、対応策についてまとめています。&lt;/p&gt;</summary>
    
    
    
    
    <category term="proxmox" scheme="https://yoshi0808.github.io/new-technology/tags/proxmox/"/>
    
  </entry>
  
  <entry>
    <title>XCP-ngのVM新規作成</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/04/07/xcpng-newvm/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/04/07/xcpng-newvm/</id>
    <published>2024-04-06T15:17:27.000Z</published>
    <updated>2024-05-10T22:14:08.010Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/04/07/xcpng-newvm/Title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p>ESXi代替としての仮想環境ソフトウェアのXCP-ng、またそのオペレーションをGUIで支援するXen Orchestraを利用して新規のVMを作成します。<span id="more"></span><h2 id="VMにおけるネットワークの考え方"><a href="#VMにおけるネットワークの考え方" class="headerlink" title="VMにおけるネットワークの考え方"></a>VMにおけるネットワークの考え方</h2><p>前回の記事「<a href="/new-technology/2024/04/07/xcpng/" title="XCP-ngとXen Orchestra">XCP-ngとXen Orchestra</a>」では、PIFs（物理ネットワーク）とPrivate Networkを学びました。基本的にVLANを使わないのであれば、新規VMを構築する場合に物理ネットワークのPortに仮想MACアドレスが自動的に割り当てられます。ユーザーはどのPort（どのネットワーク）を使うか指定するだけです。複数のPortを持つNICがある場合は、VMの作成時にどのPortを使うのか（または複数選択）指定します。</p><h2 id="セットアップの前提条件"><a href="#セットアップの前提条件" class="headerlink" title="セットアップの前提条件"></a>セットアップの前提条件</h2><p>今回ここで新規VMを作成するのはXCP-ng8.3Betaであり、サーバーはRyzen9 7900となります。この操作に関しては8.2.1と違い殆どありません。今回インストールするRocky Linux 9のテンプレートも変わらず使えます。</p><h2 id="ISOsフォルダにisoファイルをアップロード"><a href="#ISOsフォルダにisoファイルをアップロード" class="headerlink" title="ISOsフォルダにisoファイルをアップロード"></a>ISOsフォルダにisoファイルをアップロード</h2><p>前回の記事では”ISOs”というISO専用フォルダをXCP-ng用に作成しました。このフォルダにインストールするISOを入れてみます。<br>左ペインの<mark class="label primary">Import</mark>→<mark class="label primary">Disk</mark>と進みます。</p><img src="/new-technology/2024/04/07/xcpng-newvm/xo1.png" class="" width="1024" title="alt"><mark class="label primary">Select SR</mark>とあるので、対象のXCP-ngのノードに属する"ISOs"フォルダを選択します。そしてそこにISOファイルをDrag&Dropします。ここではRocky Linux（Rocky-9-Workstation...iso）をアップロードしてみます。Rocky LinuxはEnterprise向けであり長期サポートを謳っているプロダクトです。<h2 id="VMの新規構築"><a href="#VMの新規構築" class="headerlink" title="VMの新規構築"></a>VMの新規構築</h2><p>左ペインの<mark class="label primary">New</mark>→<mark class="label primary">VM</mark>と進みます。VMの新規作成画面になります。</p><ol><li>先頭のプルダウンでVMを導入するXCP-ngサーバーを選択します。2台以上のXCP-ngでPoolの設定が行われている場合はPool単位に指定します。</li><li>Info：VMのOSテンプレートを選択します。ここでは”Rocky Linux 9”を選択します。</li><li>Performance: vCPUとメモリの量を決めます。</li><li>Install Settings: アップロードしたISOファイルを選択します。</li></ol><img src="/new-technology/2024/04/07/xcpng-newvm/xo2.png" class="" width="800" title="alt"><ol start="5"><li>Interfaces: 利用するネットワークに応じて”Pool-wide Network associate with ethx” を選択します。”Host Internel…”は選択しません。もし、2つ以上の論理NICを加える場合は、<mark class="label primary">+ Add interface</mark>ボタンをクリックします。</li><li>Disks: 論理Diskの容量を設定します。</li><li><mark class="label primary">Show advanced settings</mark>ボタンをクリックします。</li></ol><img src="/new-technology/2024/04/07/xcpng-newvm/xo3.png" class="" width="800" title="alt"><ol start="8"><li>上記のように”Auto power on”（XCP-ngがBoot時にVM起動）、OSがUEFI対応の場合は、”UEFI”のトグルをONにします。なお、Max vCPUsにデフォルトで1という値が入っているので削除しています。</li></ol><p>さて、準備ができたので、画面右下の”Create”ボタンをクリックしてVMの作成、起動を行います。</p><h2 id="VMの起動（Rocky-Linuxのインストール）"><a href="#VMの起動（Rocky-Linuxのインストール）" class="headerlink" title="VMの起動（Rocky Linuxのインストール）"></a>VMの起動（Rocky Linuxのインストール）</h2><p>自動起動後、XOの当該VMの<mark class="label primary">Console</mark>のタブでは実際のRocky Linuxのインストール画面が見られます。</p><img src="/new-technology/2024/04/07/xcpng-newvm/rocky1.png" class="" width="800" title="alt"><p>GNOMEなので、UbuntuもRocky Linuxも大きくは変わりませんが、Installしていきます。</p><img src="/new-technology/2024/04/07/xcpng-newvm/rocky2.png" class="" width="800" title="alt"><p>Ubuntuライクに管理者は作成せず、新規ユーザーを管理者として設定します。<br>インストール終了後は自身で再起動を選択します。その後、Rocky Linuxが起動してきます。</p><h2 id="VMToolsのインストール"><a href="#VMToolsのインストール" class="headerlink" title="VMToolsのインストール"></a>VMToolsのインストール</h2><p>さて、Rocky Linuxが起動してきた後に、インストールで利用したマウントを解除し、代わりにVMToolsのSRをマウントします。</p><img src="/new-technology/2024/04/07/xcpng-newvm/rocky3.png" class="" width="800" title="alt"><p>プルダウンから”guest-tools.iso”を選択します。その後Rocky Linuxを再起動します。</p><p>端末を起動し、Shellから、以下のコマンドを順に投入します。マウント、Toolsのインストール、アンマウントです。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mount /dev/cdrom /mnt</span><br><span class="line">sudo /mnt/Linux/install.sh</span><br><span class="line">sudo umount /dev/cdrom</span><br></pre></td></tr></table></figure><p>これが終われば、特にリブートは不要でVMToolsのインストールが完了します。XCP-ngからリブート、シャットダウンが行え、また<mark class="label primary">Network</mark>のタブではL3の情報（IPアドレス）が表示出来るようになります。</p><img src="/new-technology/2024/04/07/xcpng-newvm/xo4.png" class="" width="1024" title="alt"><p>MACアドレスはVMを作成する時に自動で作成されています。ここでは”3e:2a:a8:24:12:c8”となっています。基本的にこのMACアドレスは不変ですが、バックアップから戻すときなどはまたMACアドレスが生成される事になるので、XCP-ngの管理上はクローンなのかVMの移動なのかを明確にオペレーションすることが求められます。こういう仕組みはESXiでもそうですし常識的な範囲の話ですね。</p><p>これでVMの導入については完了です。</p><h2 id="VMの設定変更"><a href="#VMの設定変更" class="headerlink" title="VMの設定変更"></a>VMの設定変更</h2><p>VMの構築後、<mark class="label primary">Advanced</mark>のタブを見てみます。</p><img src="/new-technology/2024/04/07/xcpng-newvm/xo5.png" class="" width="1024" title="alt"><p>Ubuntu22、Debian12のデスクトップ環境がある場合は、Video RAMの8MiBを16MiBに変更しておいた方が良いです。デフォルト値では画面操作がとても遅い状況になります。</p><mark class="label primary">NIC type</mark>がRealtek...となっていますが、これは気にしなくて良いそうです。基本的にはOS起動時に必要なドライバが組み込まれるので問題ありません。<mark class="label primary">CPU limits</mark>と<mark class="label primary">Memory limits</mark>は、減らす方向であればOSを稼働させたままで変更可能です。起動時の最大値に戻すこともできます。なお、起動時の初期値は動作中には行えず、一度VMを停止する必要があります。<h2 id="モジュールのインストール"><a href="#モジュールのインストール" class="headerlink" title="モジュールのインストール"></a>モジュールのインストール</h2><p>Debian系と異なり、Rocky Linuxでモジュールをインストールする際は<code>sudo dnf -y install module-name</code>を使います。<br>SSHとiperf3はまず基本セットでしょうか。SSHはConfigの設定でPort22を空けるなど多少追加設定が必要です。また、iperf3で待ち受けする場合は、Firewallの設定も必要になってきます。セキュアなOSだけに少し手間が掛かりますね。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dnf -y install openssh-server</span><br><span class="line">$ sudo dnf -y install iperf3</span><br></pre></td></tr></table></figure><h2 id="Ryzen9でのパフォーマンス"><a href="#Ryzen9でのパフォーマンス" class="headerlink" title="Ryzen9でのパフォーマンス"></a>Ryzen9でのパフォーマンス</h2><p>前回記事で記載したように、XCP-ngをRyzenで構築した場合、Ubuntuではiperf3のネットワークパフォーマンス（送信）が2Gbps程度と厳しい状況でした。しかし、Rocky Linux9に関しては、iperf3の上り&#x2F;下り共に9.0Gbps&#x2F;9.3Gbpsであり、Retryは、145&#x2F;0と素晴らしい内容でした。今回は、XCP-ng8.3BetaをRyzen9 7900で、XCP-ng8.2.1に関してはintel CPUでそれぞれセットアップの確認をしており、どちらとも問題はありません。</p><p>個人的にはあと3年半稼働できるESXi8を中心に使いつつ、少しづつProxmoxとXCP-ngも検証を続けていければと考えています。<br>ProxmoxにおけるRocky Linuxのiperf3は上り下り共に9.3Gbps前後出ていますが、送信時のRetryが13,000程度と異常値が出ています。ESXiでは当たり前のように使えていたものがいざ他のものに移ろうとすると、なかなか大変である事を実感しています。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/04/07/xcpng-newvm/Title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;
ESXi代替としての仮想環境ソフトウェアのXCP-ng、またそのオペレーションをGUIで支援するXen Orchestraを利用して新規のVMを作成します。</summary>
    
    
    
    
    <category term="XCP-ng" scheme="https://yoshi0808.github.io/new-technology/tags/XCP-ng/"/>
    
  </entry>
  
  <entry>
    <title>XCP-ngとXen Orchestra</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/04/07/xcpng/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/04/07/xcpng/</id>
    <published>2024-04-06T15:00:00.000Z</published>
    <updated>2024-04-07T08:26:26.357Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/04/07/xcpng/title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p>ESXi代替としての仮想環境ソフトウェアのXCP-ng、またそのオペレーションをGUIで支援するXen Orchestraの概要およびセットアップを行います。Xen Orchestraは有償ソフトウェアですが、オープンシステムとして提供されており、コンパイル、ビルドすることで無償で利用できます。<span id="more"></span><h2 id="ESXi代替としてのXCP-ng"><a href="#ESXi代替としてのXCP-ng" class="headerlink" title="ESXi代替としてのXCP-ng"></a>ESXi代替としてのXCP-ng</h2><p>無償版ESXiが新規で利用できなくなった現在、個人向けの仮想化基盤としての代替ソフトウェアはProxmoxが有力です。インストールも簡単でVMの作成までに迷うことが殆どありません。私個人としては、ProxmoxはあくまでPCという領域の範囲で便利なソフトウェアという認識を持っています。モジュールの更新が<code>apt update</code>であったり、バックアップ一覧がファイル名を意識させるものであったり、どこかでLinuxの延長として見てしまうところにあるのでしょうか。<br>個人向けであっても、仮想環境は、運用面における信頼性、保守性は重要と考えるユーザーには、もう1つの選択としてXCP-ngが候補となります。</p><p>XCP-ngはフランスのVatesという会社が提供しているプロダクトで、Citrix社のXenを引き継いで（技術提供を受けて）仮想環境の運用面と安定性を重要視して構築されているオープンシステムです。ESXiやProxmoxと比較し、CPU、メモリなどの基本的なスループットは劣ります。しかし、VM同士が互いに確実に分離され安定性が高いという意味においてはESXi同等です。KVMやProxmoxはメモリアクセスの観点では明確な分離が行われていないのでスループットは高くなります。</p><p>つまりXCP-ng、Proxmoxはそれぞれの良さがあり、選択するのはユーザー次第です。1台のみでお手軽な仮想環境を作るのであれば、Proxmox一択となるでしょう。一方で2台以上、障害時のフェールオーバーを想定したり、バックアップなどの運用を重視するのであればXCP-ngのメリットが出てきます。XCP-ngは単純に仮想マシンが動作するリソースとなるサーバーであり、それを操作するのは別途XenOrchestraというGUIツールが必要でこれは別ノードのLinux上に構築します。従い3台構成が1つの目安となります。1台はProxmoxまたはベアメタルでXenOrchestraをセットアップし、別のノードにXCP-ngをセットアップすることになります。最低構成は2台です。もちろん最終的にXenOrchestraのLinux-VMをXCP-ngにインポートすれば1台でXCP-ng+XenOrchestraを運用可能です（障害発生時はその回復に手間が掛かりますが）。</p><p>ホームユーザーとして本格的な連続稼働を前提として仮想環境を利用される場合に検討対象となります。</p><img src="/new-technology/2024/04/07/xcpng/XCP-ng1.png" class="" width="360" title="alt"><h2 id="現時点で未解決の事項"><a href="#現時点で未解決の事項" class="headerlink" title="現時点で未解決の事項"></a>現時点で未解決の事項</h2><h3 id="Ryzen-CPUと主要Linuxディストリビューション"><a href="#Ryzen-CPUと主要Linuxディストリビューション" class="headerlink" title="Ryzen CPUと主要Linuxディストリビューション"></a>Ryzen CPUと主要Linuxディストリビューション</h3><p>なお、1か月ほどRyzen環境でXCP-ngを試行錯誤しましたが、主要なLinux distribution（Ubuntu,Debian,Mint）のiperf3のスループットが不十分な状況であり、解決できませんでした。インターネットに対する接続のspeedtestは4Gbps-5Gbps程度出ている状況でこちらは全く問題がなく、原因がよく分かっていません。<br>Ryzen5 5600G、Ryzen9 7900と2種類のPCを用意して最新のバージョン8.2.1および8.3ベータで検証しましたがいずれもiperf3では送信ネットワークスループットが2Gbps程度でした。RyzenでもCPUの種類によっては高速に動作するようですが、巷に事例としてあるのは限られたCPUとマザーボードとの組み合わせのみになるようです。例外的に、Rocky LinuxだけはRyzenでも全く問題はなくiperf3でワイヤレートの速度が出ます。Windowsに関しては検証できていません。</p><p>結局、5年ほど前に稼働していたIntel(R) Core(TM) i7-8700 CPU @ 3.20GHz（6Core 12Thread）に加え、新規に12th Gen Intel(R) Core(TM) i5-12400（6Core 12Thread）を購入して主、従の関係を構築しました。なお、XCP-ngではintelのE Coreについて強くお勧めしないとのことです。こういった情報は原則、コミュニティから収集することになります。Vates社は有償サポートで収益を上げるモデルを選択していますが、コミュニティ上での無償サポートも積極的です。</p><h3 id="VMのUEFI"><a href="#VMのUEFI" class="headerlink" title="VMのUEFI"></a>VMのUEFI</h3><p>XCP-ngの検証を始めた時にはVMのセキュアブートは設定できたと記憶しているのですが、現時点で設定可能であるものの、VMの情報からはUEFIに対応していないという表記が出ます。確かにUEFIモードで起動しているようなのですが、現時点でその影響は判明していません。特に運用上実害は出ていません。</p><h2 id="XCP-ngのモジュールや関連プロダクト"><a href="#XCP-ngのモジュールや関連プロダクト" class="headerlink" title="XCP-ngのモジュールや関連プロダクト"></a>XCP-ngのモジュールや関連プロダクト</h2><p>最新モジュールは、8.2.1です。ベータバージョンは8.3となります。8.3ベータはAMD CPU向けに色々追加されているのとIPv6の強化などが含まれています。バージョンの更新は非常にゆっくりと進んでいくので8.3ベータはこれで1年以上検証中の状態が続いています。<br>今後構成されるプロダクトとしてXCP-ngを簡易なGUIで操作するXO Liteというプロダクトがありますが、これはまだ機能的に不足していて使えません。また、過去利用されていたものにXCP-ng Centerというプロダクトがありますが、これも非推奨となっています。</p><blockquote><p>XCP-ng ドキュメント<br> <a href="https://docs.xcp-ng.org/">https://docs.xcp-ng.org</a></p></blockquote><blockquote><p>XCP-ng フォーラム<br> <a href="https://xcp-ng.org/forum/">https://xcp-ng.org/forum/</a></p></blockquote><h2 id="Xen-Orchestra"><a href="#Xen-Orchestra" class="headerlink" title="Xen Orchestra"></a>Xen Orchestra</h2><p>Xen Orchestra(XOA)もVates社が製造しています。</p><img src="/new-technology/2024/04/07/xcpng/xoa.png" class="" width="1024" title="alt"><p>XOAはターンキーアプライアンスという名目ですぐに使えると表現されています（車のキーを回してすぐに動く）。これは有償のソフトウェアであり、CitrixのXen Server、XCP-ngを操作するためのGUIクライアントです。セットアップも簡単でXCP-ngに対してコマンド1つでモジュールを送り込み内部でビルドされます。</p><p>これに対してホームユーザーが利用するものは同じXen Orchestraではありますが、ソースコードからコンパイルすることで無償で利用できます。これは一手間掛かりますが、公式に認められた方法であり、オープンソースという建て付けで無償で提供されているものです。<br>同じ、Xen Orchestraであっても、こちらはXOという表記がなされ、有償版と無償版はそれぞれ、XOA、XOと区別されます。</p><p>ここではXOの導入について説明をしていきます。XOはVMの構築、操作、バックアップ、スナップショット、マイグレーション（ノード間のVMの移動）を行います。</p><blockquote><p>Xen Orchestra ドキュメント<br> <a href="https://xen-orchestra.com/docs/">https://xen-orchestra.com/docs/</a></p></blockquote><p>なお、フォーラムはXCP-ngと共通です。</p><h3 id="XOの操作イメージ"><a href="#XOの操作イメージ" class="headerlink" title="XOの操作イメージ"></a>XOの操作イメージ</h3><p>ここで説明する環境は以下の通りです。</p><img src="/new-technology/2024/04/07/xcpng/xo-xcp.drawio.png" class="" width="640" title="alt"><p>VMに対する操作はWebで行います。</p><img src="/new-technology/2024/04/07/xcpng/xo1.png" class="" width="1024" title="alt"><p>これはUbuntuを動作させているところです。ネットワーク、ディスクの基本構成があります。ここでSSH　as userを選ぶとローカル端末のSSHで接続できます。スナップショットやバックアップはすぐに取得できます。ESXi同様にXCP-ng向けのVMToolを導入することで、IPアドレスの把握やXOからvmのシャットダウン、リブートが可能になります（ESXiとは異なり手動でインストールが必要です）。Advancedタグでは、メモリやCPUの上限などを可変できます。<br>バックアップは自動的にスナップショットを取得します。ログも確認が容易ですし、Google等を経由したメール通知もできます。</p><img src="/new-technology/2024/04/07/xcpng/xo2.png" class="" width="1024" title="alt"><p>私の環境では10GbbpsのネットワークでXCP-ngからXOがデータを吸い上げ、それをNASにNFSで書き込んでいます。106MiB&#x2F;sなのでお世辞にもバックアップが早いとは言えませんが、圧縮しながらなのでこんなところなのでしょうか。基本は日時指定でバックアップを取得することになるのであまり気になるような状況でもないでしょう。複数ノードを1つのジョブでバックアップできるため、ノードが多くあればその分利便性を感じられます。</p><p>XCP-ngは2種類のスナップショットの取得方法があります。通常のスナップショットはメモリの情報を保存しません。バックアップなどはこの方式が選択されます。もう一方はメモリの情報を含んだスナップショットであり、こちらは少しの間VMの応答ができません。セットアップ作業の合間にチェックポイントとして状態を保存したい場合は、後者を選択すると良いでしょう。</p><p>同じCPU（intel）同士であれば、ダウンタイムを最小にするライブマイグレーションが可能です。</p><img src="/new-technology/2024/04/07/xcpng/xo3.png" class="" width="1024" title="alt"><p>表示が見切れているのでわかりづらいですが、ここでは同一のリソースプール（Pool1）における、1号機（XCP-ng1）から2号機（XCP-ng2）に対するマイグレーションを実施します。</p><p>この処理は最初に1号機から2号機への、ノード間でそれぞれのストレージ同士でコピー、その後動作したメモリの差分をコピーして完了させます。</p><p>Wi-Fiに接続されたMacbookから、XCP-ng上のUbuntuにiperf3を実行し、ほぼ同時にマイグレーションを開始してみます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[  5] 138.01-139.00 sec   174 MBytes  1.47 Gbits/sec</span><br><span class="line">[  5] 139.00-140.00 sec   178 MBytes  1.49 Gbits/sec</span><br><span class="line">[  5] 140.00-141.00 sec   174 MBytes  1.47 Gbits/sec</span><br><span class="line">[  5] 141.00-142.01 sec   179 MBytes  1.50 Gbits/sec</span><br><span class="line">[  5] 142.01-143.01 sec  78.4 MBytes   657 Mbits/sec</span><br><span class="line">[  5] 143.01-144.00 sec  0.00 Bytes  0.00 bits/sec</span><br><span class="line">[  5] 144.00-145.01 sec  0.00 Bytes  0.00 bits/sec</span><br><span class="line">[  5] 145.01-146.01 sec  40.4 MBytes   339 Mbits/sec</span><br><span class="line">[  5] 146.01-147.00 sec  73.2 MBytes   617 Mbits/sec</span><br><span class="line">[  5] 147.00-148.00 sec  97.8 MBytes   818 Mbits/sec</span><br><span class="line">[  5] 148.00-149.01 sec   112 MBytes   938 Mbits/sec</span><br><span class="line">[  5] 149.01-150.00 sec   125 MBytes  1.05 Gbits/sec</span><br><span class="line">[  5] 150.00-151.00 sec   130 MBytes  1.09 Gbits/sec</span><br><span class="line">[  5] 151.00-152.00 sec   136 MBytes  1.14 Gbits/sec</span><br></pre></td></tr></table></figure><p>2分20秒程度で1号機のノードとの応答が途絶え、それから約3秒後に2号機からiperf3の応答が再開されています。TCPセッションは切断されません。<br>もちろん共有Diskがあればもっとマイグレーションは高速になりますが、個人向けの安価なハードウェアでも、ここまで出来るのは素晴らしいことです。</p><h2 id="XCP-ngのインストール"><a href="#XCP-ngのインストール" class="headerlink" title="XCP-ngのインストール"></a>XCP-ngのインストール</h2><p>8.2のインストールイメージは以下からダウンロードします。<br><a href="https://xcp-ng.org/#easy-to-install">https://xcp-ng.org/#easy-to-install</a></p><p>8.3ベータは以下からダウンロードします。<br><a href="https://xcp-ng.org/blog/2024/02/15/xcp-ng-8-3-beta-2/">https://xcp-ng.org/blog/2024/02/15/xcp-ng-8-3-beta-2/</a></p><p>導入にあたっては、ハードウェアサポートのページをまず参照されることをお勧めします。<br><a href="https://docs.xcp-ng.org/installation/hardware/">https://docs.xcp-ng.org/installation/hardware/</a></p><p>ここでは、問題が少ないと思われるintelマシンに対して8.2.1をインストールすることにします。ISOファイルをダウンロードし、RufusなどでUSBメモリにブートイメージを書き込みます。Rufus上でも特殊な設定は不要でデフォルト設定のまま書き込みます。XCP-ngはUEFIブートに対応していませんのでサーバーとなるPCのセキュアブートは無効にします。なお、稼働するVMはUEFIのセキュアブートにできます。</p><img src="/new-technology/2024/04/07/xcpng/usb.png" class="" width="360" title="alt"><p>ハードウェアによって異なりますが、最初にGRUBの画面が表示され、以下の選択になります。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">*install</span><br><span class="line"> install with alterate kernel(kernel-alt)</span><br><span class="line"> no-serial</span><br><span class="line"> safe</span><br><span class="line"> multipath</span><br><span class="line"> shell</span><br></pre></td></tr></table></figure><p>基本は最初の<code>instal</code>で構いませんが、セットアップ時にストレージ（NVMe）が見えずセットアップ出来ない場合は、Alt Kernel（代替カーネル）を選択してみてください。</p><p>セットアップは以下の手順で進めます。</p><img src="/new-technology/2024/04/07/xcpng/xcp1.png" class="" width="800" title="alt"><p>最初にキーボードを選択します。</p><img src="/new-technology/2024/04/07/xcpng/xcp2.png" class="" width="800" title="alt"><p>セットアップの注意書き（お決まり）です。基本的にはこのままOKで進めていきます。</p><img src="/new-technology/2024/04/07/xcpng/xcp3.png" class="" width="800" title="alt"><p>EULAに同意します。</p><img src="/new-technology/2024/04/07/xcpng/xcp4.png" class="" width="800" title="alt"><p>ストレージを選択します（ここではキャプチャ確保のためにProxmox上で動作させているのでQEMUと表示されています）。<br>8.2のストレージはブロックベース（LVM）がデフォルトです。8.3以降はファイルベースになるようです。</p><img src="/new-technology/2024/04/07/xcpng/xcp5.png" class="" width="800" title="alt"><p>インストール元としてlocal media(USB)を選択します。</p><img src="/new-technology/2024/04/07/xcpng/xcp6.png" class="" width="800" title="alt"><p>インストールメディアの検証の確認です。どちらでも構いません。</p><img src="/new-technology/2024/04/07/xcpng/xcp7.png" class="" width="800" title="alt"><p>メディア検証で問題なしというダイアログです。次に進みます。</p><img src="/new-technology/2024/04/07/xcpng/xcp8.png" class="" width="800" title="alt"><p>パスワードを決めます。</p><img src="/new-technology/2024/04/07/xcpng/xcp9.png" class="" width="800" title="alt"><p>IPアドレスを決めます。サーバーになるので、DHCPではなくStaticで固定IPアドレスにします。</p><img src="/new-technology/2024/04/07/xcpng/xcp10.png" class="" width="800" title="alt"><p>XCP-ng自身のhostnameを決めます。hostnameの一部はランダムに命名されていますが、わかりやすいものに変えた方が良いです。DNSサーバーはご自身のDNS（ルーターまたはゲートウェイ）を指定します。</p><img src="/new-technology/2024/04/07/xcpng/xcp11.png" class="" width="800" title="alt"><p>タイムゾーンは、Asia、Tokyoと指定します。</p><img src="/new-technology/2024/04/07/xcpng/xcp12.png" class="" width="800" title="alt"><img src="/new-technology/2024/04/07/xcpng/xcp13.png" class="" width="800" title="alt"><p>NTPを指定します。<br>ご自身の環境から近く、安定しているNTPサーバーを指定します。上記は指定の一例です。</p><img src="/new-technology/2024/04/07/xcpng/xcp14.png" class="" width="800" title="alt"><p>最後に<strong>Install XCP-ng</strong>のボタンを押下します。</p><img src="/new-technology/2024/04/07/xcpng/xcp15.png" class="" width="800" title="alt"><p>セットアップの進捗を示すダイアログが表示されています。</p><img src="/new-technology/2024/04/07/xcpng/xcp16.png" class="" width="800" title="alt"><p>サプリメントパックをインストールするか聞かれますので、ここはNoを答えます。<br>その後インストールが継続します。</p><img src="/new-technology/2024/04/07/xcpng/xcp17.png" class="" width="800" title="alt"><p>セットアップ完了です。USBメディアを取り外し、OKボタンを押下します。</p><p>セットアップ完了後再起動して以下の画面が表示されます。もしここまで上手く表示されない場合は、マザーボードのBIOSのアップデートをお勧めします。</p><p>XCP-ngにはインストール時に設定したマネジメントネットワークが1つ必要です。このマネジメントネットワークに対してXen Orchestraから接続され制御されることになります。<br>この状態でXCP-ngにはSSHできる状態になっています。または、このメニューの<mark class="label primary">Local Command Shell</mark>を起動します。</p><p>VMがUEFIブートを可能とするため、以下のコマンドを入力します。<br><code>$ secureboot-certs install</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[11:31 xcp-ng3 ~]<span class="comment"># secureboot-certs install</span></span><br><span class="line">Downloading https://www.microsoft.com/pkiops/certs/MicCorKEKCA2011_2011-06-24.crt...</span><br><span class="line">Downloading https://www.microsoft.com/pkiops/certs/MicCorUEFCA2011_2011-06-27.crt...</span><br><span class="line">Downloading https://www.microsoft.com/pkiops/certs/MicWinProPCA2011_2011-10-19.crt...</span><br><span class="line">Downloading https://uefi.org/sites/default/files/resources/dbxupdate_x64.bin...</span><br><span class="line">Successfully installed certificates to the XAPI DB <span class="keyword">for</span> pool.</span><br><span class="line">[11:37 xcp-ng3 ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>ここまででXCP-ngのセットアップは一旦完了です。<br>NICを取り外して別のNICを取り付ける場合には、デバイス論理名（ex:eth0）とデバイスとの関連付けがずれてしまう場合があります。この際は以下のページを参考にしてください。</p><p><a href="https://docs.xcp-ng.org/networking/">https://docs.xcp-ng.org/networking/</a></p><p>同じリソースプールでスムーズにVMの移動（ライブマイグレーション）を行う際は、同一の物理インタフェースが必要となります。もちろん同一製品である必要はありませんが、どのセグメントに属するか、速度タイプなどは同一にする必要があります。</p><h2 id="Xen-Orchestraのインストール"><a href="#Xen-Orchestraのインストール" class="headerlink" title="Xen Orchestraのインストール"></a>Xen Orchestraのインストール</h2><p>XOのセットアップにはインターネットに接続されたLinuxが必要です。ここではXCP-ngとは別にUbuntu22を使ってXOのコンパイル、デプロイを実行していきます。<br>まず、ベアメタルかVMとしてのGUIのあるUbuntu Desktopを用意してください。私の例ではマネジメントネットワークに加え、バックアップのセグメント（SynologyへのNFS接続）とのvNICを2つ用意しています。1つのNICのみであってもXOのセットアップは可能です。<br>ここではProxmox上のUbuntuにXOをセットアップします。Proxmox上でのUbuntuのセットアップは「<a href="/new-technology/2024/02/19/Proxmox-new-vm/" title="ProxmoxVEのVM新規作成（Ubuntu24.04LTS）">ProxmoxVEのVM新規作成（Ubuntu24.04LTS）</a>」の記事を参考にしてください（XOをセットアップする想定でUbuntuを構築しています）。</p><p>クライアントからXOにブラウザで接続して使うことになるので、最初にubuntuのIPアドレスは固定IPアドレスにします。設定ーネットワークから有線設定を変更しておきます。<br>また、XOのセットアップ開始にあたり、最初にLinuxそのもののスナップショットを取得しておくとよいでしょう。</p><p>XOのセットアップには有志であるronivay氏が作成したXenOrchestraInstallerUpdaterを利用します。<br><a href="https://github.com/ronivay/XenOrchestraInstallerUpdater">https://github.com/ronivay/XenOrchestraInstallerUpdater</a></p><h3 id="事前準備"><a href="#事前準備" class="headerlink" title="事前準備"></a>事前準備</h3><p>Ubuntuの<mark class="label primary">ソフトウェアとアップデート</mark>を起動し、<mark class="label primary">Ubuntuのソフトウェア</mark>で<mark class="label primary">ソースコード</mark>のチェックをオンにします。</p><img src="/new-technology/2024/04/07/xcpng/xo4.png" class="" width="640" title="alt"><p>また、<mark class="label primary">他のソフトウェア</mark>の一覧で<mark class="label primary">ソースコード</mark>と記載されているものにチェックをオンにします。</p><img src="/new-technology/2024/04/07/xcpng/xo5.png" class="" width="640" title="alt"><p>これ以降はShellでの操作となるので、SSHでクライアントから接続してコマンドを投入していった方が簡単です（コマンドのコピペが出来るので）。SSH ServerがUbuntuに入っていない場合は、以下のコマンドでインストールします。<br><code>$ sudo apt install openssh-server</code></p><p>Ubuntu DesktopでのShell操作、或いはクライアントからsshして以降の作業を行います（<code>ssh username@your-host</code>)。UbuntuのGUIで実施する場合は、<mark class="label primary">端末</mark>を起動します。</p><h4 id="rootになる"><a href="#rootになる" class="headerlink" title="rootになる"></a>rootになる</h4><p><code>$ sudo -i</code></p><h4 id="gitのインストール"><a href="#gitのインストール" class="headerlink" title="gitのインストール"></a>gitのインストール</h4><p>リポジトリを追加し、gitをインストールします。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ add-apt-repository ppa:git-core/ppa</span><br><span class="line">$ apt update; apt install git</span><br></pre></td></tr></table></figure><h3 id="XenOrchestraInstallerUpdaterのダウンロード、XOのインストール"><a href="#XenOrchestraInstallerUpdaterのダウンロード、XOのインストール" class="headerlink" title="XenOrchestraInstallerUpdaterのダウンロード、XOのインストール"></a>XenOrchestraInstallerUpdaterのダウンロード、XOのインストール</h3><p>GitHubからスクリプトをダウンロードし、cfgファイルのサンプルのコピーを作成します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/ronivay/XenOrchestraInstallerUpdater.git</span><br><span class="line">$ <span class="built_in">cd</span> XenOrchestraInstallerUpdater</span><br><span class="line">~/XenOrchestraInstallerUpdater$ <span class="built_in">cp</span> sample.xo-install.cfg xo-install.cfg</span><br></pre></td></tr></table></figure><p><code>xo-install.cfg</code>ファイルをviで開き、インストールパス、XOが待ち受けるPort、SSL自己証明書を指定します。<br>Ubuntuでは、インストールパスは<code>/usr/lib/</code>配下とします（お好みで変えてください）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/XenOrchestraInstallerUpdater$ vi xo-install.cfg</span><br></pre></td></tr></table></figure><p>3箇所の修正ポイントです。以下の行を見つけます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Port number where xen-orchestra service is bound</span></span><br><span class="line"><span class="comment"># no effect to Xen Orchestra proxy</span></span><br><span class="line">PORT=<span class="string">&quot;80&quot;</span></span><br></pre></td></tr></table></figure><p>PORT&#x3D;”80”をPORT&#x3D;”443”に変更します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Port number where xen-orchestra service is bound</span></span><br><span class="line"><span class="comment"># no effect to Xen Orchestra proxy</span></span><br><span class="line">PORT=<span class="string">&quot;443&quot;</span></span><br></pre></td></tr></table></figure><p>次に以下の行を見つけます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Base dir for installation and future updates</span></span><br><span class="line">INSTALLDIR=<span class="string">&quot;/opt/xo&quot;</span></span><br></pre></td></tr></table></figure><p>INSTALLDIR&#x3D;”&#x2F;opt&#x2F;xo”をINSTALLDIR&#x3D;”&#x2F;usr&#x2F;lib&#x2F;xo”に変更します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Base dir for installation and future updates</span></span><br><span class="line">INSTALLDIR=<span class="string">&quot;/usr/lib/xo&quot;</span></span><br></pre></td></tr></table></figure><p>次に以下の行を見つけます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Location of pem certificate/key files. Installation will automatically configure HTTPS if these are defined. Remember to change PORT variable as well.</span></span><br><span class="line"><span class="comment">#PATH_TO_HTTPS_CERT=$INSTALLDIR/xo.crt</span></span><br><span class="line"><span class="comment">#PATH_TO_HTTPS_KEY=$INSTALLDIR/xo.key</span></span><br></pre></td></tr></table></figure><p>証明書のパスについて2箇所コメントを外します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Location of pem certificate/key files. Installation will automatically configure HTTPS if these are defined. Remember to change PORT variable as well.</span></span><br><span class="line">PATH_TO_HTTPS_CERT=<span class="variable">$INSTALLDIR</span>/xo.crt</span><br><span class="line">PATH_TO_HTTPS_KEY=<span class="variable">$INSTALLDIR</span>/xo.key</span><br></pre></td></tr></table></figure><p>以上でファイルの修正は終了ですので、保存しviを終了します。</p><p>Open SSLをインストールします。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install openssl</span><br></pre></td></tr></table></figure><p>自己証明書を生成します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ openssl req -newkey rsa:4096 \</span><br><span class="line">            -x509 \</span><br><span class="line">            -sha256 \</span><br><span class="line">            -days 3650 \</span><br><span class="line">            -nodes \</span><br><span class="line">            -out /usr/lib/xo/xo.crt  \</span><br><span class="line">            -keyout /usr/lib/xo/xo.key</span><br></pre></td></tr></table></figure><p>証明書の設定では以下、適当なものを入力しておきます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Country Name (2 letter code) [AU]:JP</span><br><span class="line">State or Province Name (full name) [Some-State]:anywhere</span><br><span class="line">Locality Name (eg, city) []:anywhere</span><br><span class="line">Organization Name (eg, company) [Internet Widgits Pty Ltd]:yoshi</span><br><span class="line">Organizational Unit Name (eg, section) []:none</span><br><span class="line">Common Name (e.g. server FQDN or YOUR name) []:yoshi</span><br><span class="line">Email Address []:yoshi0808.blog@gmail</span><br></pre></td></tr></table></figure><p>スクリプトを起動します。<code>$ ./xo-install.sh</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Xen Orchestra configuration will be stored to /root/.config/xo-server/config.toml, <span class="keyword">if</span> you don<span class="string">&#x27;t want it to be replaced with every update, set CONFIGUPDATE to false in xo-install.cfg</span></span><br><span class="line"><span class="string">Xen Orchestra Proxy configuration will be stored to /root/.config/xo-proxy/config.toml. Config won&#x27;</span>t be overwritten during update, ever</span><br><span class="line">-----------------------------------------</span><br><span class="line"></span><br><span class="line">1. Install</span><br><span class="line">2. Update</span><br><span class="line">3. Rollback</span><br><span class="line">4. Install proxy</span><br><span class="line">5. Update proxy</span><br><span class="line">6. Exit</span><br><span class="line"></span><br><span class="line">：</span><br></pre></td></tr></table></figure><p>Installの1を入力してEnterを押下します。必要なモジュール、ソースコードをダウンロードし、コンパイルに入ります。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[info] xo-server and xo-web build takes quite a <span class="keyword">while</span>. Grab a cup of coffee and lay back</span><br></pre></td></tr></table></figure><p>ということで、コーヒーを淹れに行き、3分程度待ちます😊。<br>以下の表示が出たところで、rebootします。事後にはLinixのアプリケーションファイアウォールであるufwを有効にして443のみを開けると良いでしょう（GUIもあります）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[info] Starting xo-server...</span><br><span class="line"> waiting <span class="keyword">for</span> port to be open</span><br><span class="line"></span><br><span class="line">       WebUI started <span class="keyword">in</span> port 443. Make sure you have firewall rules <span class="keyword">in</span> place to allow access.</span><br><span class="line">       Default username: admin@admin.net password: admin</span><br><span class="line"></span><br><span class="line">[info] Installation successful. Enabling xo-server service to start on reboot</span><br><span class="line"></span><br><span class="line">root@xo:~/XenOrchestraInstallerUpdater<span class="comment"># reboot</span></span><br></pre></td></tr></table></figure><p>再起動してインストールは終了です。<br>上記のコメントにある通り、XOの画面からはユーザー:<a href="mailto:&#x61;&#100;&#x6d;&#x69;&#110;&#64;&#x61;&#100;&#x6d;&#105;&#110;&#x2e;&#x6e;&#x65;&#116;">&#x61;&#100;&#x6d;&#x69;&#110;&#64;&#x61;&#100;&#x6d;&#105;&#110;&#x2e;&#x6e;&#x65;&#116;</a>、パスワード：adminでログインします。</p><h3 id="XOの初期設定"><a href="#XOの初期設定" class="headerlink" title="XOの初期設定"></a>XOの初期設定</h3><p>Ubuntuが再起動してきたら、ブラウザから<code>https://XOのIPアドレス/</code>としてXOのGUIに接続します。<br>ブラウザからは自己証明書の警告が表示されますが気にせず継続します。<br>無事、以下のログイン画面が表示されればインストールは成功です。</p><img src="/new-technology/2024/04/07/xcpng/xo6.png" class="" width="360" title="alt"><p>デフォルトアカウントでログインします。</p><img src="/new-technology/2024/04/07/xcpng/xo7.png" class="" width="800" title="alt"><p>ソースコードから作成されたものというダイアログが表示されます。OKをクリックして閉じます。また、画面上部には、”This version is not bundled with any support nor updates. Use it with caution. Why do I see this message?”と表示されていますが、これもサポートなしと理解して使っているので閉じます。そして、左ペインにXOA❓マークがありますが、これをクリックすると、Update❓という表示がされています。この？アイコンは削除できません。XOAはここからアップデートなどの処理が行えますが、これはXOAではなく、XOなのでこのサブメニューは使いません。無視して大丈夫です。</p><h3 id="ユーザーの作成とデフォルトアカウントの削除"><a href="#ユーザーの作成とデフォルトアカウントの削除" class="headerlink" title="ユーザーの作成とデフォルトアカウントの削除"></a>ユーザーの作成とデフォルトアカウントの削除</h3><p>左ペインの<mark class="label primary">Settings</mark>から、<mark class="label primary">Users</mark>を選択します。</p><img src="/new-technology/2024/04/07/xcpng/xo8.png" class="" width="1024" title="alt"><p>上記画面から、ユーザー名、ユーザーの権限は”Admin”を選択、パスワードを入力して<mark class="label primary">Create</mark>ボタンをクリックして管理者を作成します。</p><p>無事作成できたら、左ペインの一番下にあるサインアウトをクリックして、新しい管理者アカウントで入りなおします。<br>ログインできたら、デフォルトのアカウントを右側のゴミ箱アイコンをクリックして削除します。</p><p>任意の作業ですが、最初に仮想環境でスナップショットを取得していれば、ここまでは1つの区切りです。もう一度Linux全体のスナップショットを撮り直す、またはスナップショットは削除して再作成するなどしても良いでしょう。</p><h2 id="Xen-OrchestraからXCP-ngへの接続"><a href="#Xen-OrchestraからXCP-ngへの接続" class="headerlink" title="Xen OrchestraからXCP-ngへの接続"></a>Xen OrchestraからXCP-ngへの接続</h2><p>左ペインの<mark class="label primary">Settings</mark>から<mark class="label primary">Servers</mark>を選択します。</p><img src="/new-technology/2024/04/07/xcpng/xo9.png" class="" width="1024" title="alt"><p>ここでXCP-ngのインストール時に決めたユーザー：root、パスワードをセットします。トグルスイッチの<mark class="label primary">Unauthorized Certificate</mark>は今回作成した自己証明書なのでオンにします。先頭のLabelは自分のメモとしてサーバー名を入力しておきます。</p><mark class="label primary">Connect</mark>ボタンをクリックして接続します。うまくXCP-ngに接続できると<mark class="label primary">Status</mark>がEnableの表示となります。<p>さて、この状態になると、恐らく左ペインの<mark class="label primary">Home</mark>には、！マークが付いていると思われます。</p><mark class="label primary"> Home</mark>→<mark class="label primary">Hosts</mark>と進むとサーバー名が表示されているのでこれをクリックします。<img src="/new-technology/2024/04/07/xcpng/xo10.png" class="" width="1024" title="alt"><mark class="label primary"> Patches</mark>の部分に恐らく数十の数字が書かれていることと思われます。これはXCP-ngでまだ適用されていないパッチの数を示します。<mark class="label primary"> Patches</mark>の項目をクリックして、<mark class="label primary"> Install all patches</mark>ボタンをクリックしてパッチを適用します。適用後は、リブートが必要となります。画面右上のリサイクルマークのようなアイコンが再起動となるのでそれをクリックしてパッチの適用を完了させます。<img src="/new-technology/2024/04/07/xcpng/xo11.png" class="" width="360" title="alt"><p>今はXCP-ngが1台だけですが、複数台を運用することになり、1つのリソースプールに存在する複数台のサーバーに順にパッチを適用する事になります。その際は、常にMasterとなっているサーバーを先にパッチ適用する必要があります。<br>XCP-ngの再起動が完了するとXOは自動的にXCP-ngに接続します。</p><h2 id="XCP-ngネットワークの確認"><a href="#XCP-ngネットワークの確認" class="headerlink" title="XCP-ngネットワークの確認"></a>XCP-ngネットワークの確認</h2><p>XCP-ngへの接続が完了したら、まず<mark class="label primary">Home</mark>→<mark class="label primary">Hosts</mark>と進みます。XCP-ngサーバーをクリックし、CPU&#x2F;メモリ&#x2F;ネットワークを確認しましょう。</p><img src="/new-technology/2024/04/07/xcpng/xo14.png" class="" width="1024" title="alt"><p>ここで、<mark class="label primary">PIFs</mark>というのはPhysical Interfaces（物理インタフェース）の意味です。Private Networkを作成すると、物理Portを指定してそこにVLANを定義するなどできます。そのようにすることで物理インタフェースにVLANタグの付いたパケットが流れます。XCP-ngがスイッチからタグ付きパケットを受け取り、VMにはPrivate Network（論理Port）経由でタグを剥がしてパケットをVMに渡します。またその逆でVMからタグなしのPrivate Network経由でパケットを受け取り、XCP-ngは該当の物理Portにタグ付きでパケットをスイッチに向けて送信します。</p><h2 id="ISOファイルを配置するSRの設定"><a href="#ISOファイルを配置するSRの設定" class="headerlink" title="ISOファイルを配置するSRの設定"></a>ISOファイルを配置するSRの設定</h2><p>VMを作成する前に、OSのISOファイルをアップロードするフォルダが必要です。これはXCP-ng上に作成します。つまりサーバー毎に必要です。大量に利用するなら、NASなどのNFSを用意してそこにマウントできます。ここではとりあえずXCP-ngのローカル上にSR(Storage Repository)を作成します。</p><p>以下のVates社のブログを元に構成します。<br><a href="https://xcp-ng.org/blog/2022/05/05/how-to-create-a-local-iso-repository-in-xcp-ng/">https://xcp-ng.org/blog/2022/05/05/how-to-create-a-local-iso-repository-in-xcp-ng/</a></p><p>ちょうどこの記事を見ていただくと、このブログの最後に記事を書いた方の情報があります。Olivier Lambert氏、Vates社の起業者でありCEOです。Forumにも頻繁にコメントされています。</p><img src="/new-technology/2024/04/07/xcpng/xo12.png" class="" width="480" title="alt"><p>このようにStorage TypeはISO SRのlocalとして作成します。パスは&#x2F;media固定です。</p><p>次に左ペインの<mark class="label primary">Import</mark>→<mark class="label primary">Disk</mark>をクリック、対象のXCP-ngサーバーの指定フォルダ（上記では”ISOs”）を選びます。その画面上でクライアント端末からISOファイルをDrag&amp;Dropできます。</p><p>お疲れ様でした！これでXCP-ngとXEN Orchestraの基本設定は完了です。<br>次の記事で、<strong>New VM</strong>でVMの新規作成を行います。</p><p>この段階でXOがインストールされたUbuntuのOS毎のスナップショットは削除し、一度UbuntuのOSそのもののバックアップを取得されることをお勧めします。</p><h2 id="XOのアップデート"><a href="#XOのアップデート" class="headerlink" title="XOのアップデート"></a>XOのアップデート</h2><p>左ペインの<mark class="label primary">About</mark>からXOのモジュールについてアップデート状況が確認できます。現時点ではコンパイルしたばかりなので、”Your Xen Orchestra is up to date ”という表示になっているはずです。<br>しばらく時間が経過するとこの表記はGitのMasterブランチに対して遅れを取っていきます。”You are not up to date with master. xx commits behind “という表記に変わります。かなり細かい単位でコミットされていきますが、Communityの情報を見ながら適宜アップデートする事になります。この際もコンパイルが必要です。最初にXenOrchestraInstallerUpdaterでInstallを選びましたが、再びスクリプトからUpdateを実行することで常にXOは最新モジュールとなります。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo -i</span><br><span class="line">$ <span class="built_in">cd</span> XenOrchestraInstallerUpdater</span><br><span class="line">$ git pull origin master</span><br><span class="line">$ ./xo-install.sh</span><br></pre></td></tr></table></figure><p>ここで<code>2.Update</code>を選択して更新します。</p><p> GitHub上のXenOrchestraInstallerUpdaterを見る限りは数ヶ月に1度くらいの頻度で更新されているので、毎回<code>git pull 〜</code>は必要ありません。これはGitHubのページなどで情報を確認しながら、適宜アップデートしてください。</p><h2 id="XCP-ngの独自用語"><a href="#XCP-ngの独自用語" class="headerlink" title="XCP-ngの独自用語"></a>XCP-ngの独自用語</h2><p> XCP-ngのホストそのものはXenの世界でdom0と呼ばれます。色々コミュニティを見ていてdom0は何ぞや？と思われる方もいらっしゃると思うので補足です。dom0には色々なツールなどをインストールすることは避けた方が良さそうです(iperf3など)。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/04/07/xcpng/title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;
ESXi代替としての仮想環境ソフトウェアのXCP-ng、またそのオペレーションをGUIで支援するXen Orchestraの概要およびセットアップを行います。Xen Orchestraは有償ソフトウェアですが、オープンシステムとして提供されており、コンパイル、ビルドすることで無償で利用できます。</summary>
    
    
    
    
    <category term="XCP-ng" scheme="https://yoshi0808.github.io/new-technology/tags/XCP-ng/"/>
    
  </entry>
  
  <entry>
    <title>UniFi Express</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/03/06/unifi-express/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/03/06/unifi-express/</id>
    <published>2024-03-06T01:20:08.000Z</published>
    <updated>2024-03-07T09:58:27.830Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/03/06/unifi-express/Title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p><p>この記事ではUniFiネットワークの導入未経験の方を対象に、UniFiの新しい小型ゲートウェイUniFi Expressの具体的なセットアップおよび性能確認、機能紹介を目的としています。検証のため製品提供を受けていますのでこの記事はPR要素を含みます。</p><span id="more"></span><h2 id="経緯"><a href="#経緯" class="headerlink" title="経緯"></a>経緯</h2><p>普段からUbiquiti製品を使っている私は、いつもUbiquitiの皆さまには製品サポートなどで大変お世話になっています。一方、FacebookのUbiquiti日本公式コミュニティではユーザーの質問などに微力ながらサポートするように心がけています。いつものようにUbiquitiのご担当者さまから製品設定についてアドバイス頂いていた折、新製品「UniFi Express」の検証はいかがですか？と打診があり、快く引き受けさせていただきました。普段はアクセスポイント（AP）、スイッチは使っていますが、他社製セキュリティゲートウェイがお気に入りでなかなかUniFiのゲートウェイを使う機会がありませんでした。</p><p>UniFiは簡単な操作で分かりやすさを目的としている一方で、パワーユーザーの高度な要求に応えていることもあり、一旦ネットワークの世界の深みに入るといきなり難易度が増す事になります。</p><p>Expressは従来の機能豊富なUniFiゲートウェイから負荷が掛かるIPSなどの処理を省き、できるだけシンプルな形でUniFiのゲートウェイをUniFi初心者にも簡単に使えるようにしたゲートウェイです。</p><p>3月となり、新生活が始まる時期でもあります。引っ越しされて新しい住環境にネットワークを敷設される場合は、小型の置き場所に困らないExpressは使い勝手が良いと思われます。</p><h2 id="UniFi-Express"><a href="#UniFi-Express" class="headerlink" title="UniFi Express"></a>UniFi Express</h2><p>製品の説明ページは以下になります。</p><img src="/new-technology/2024/03/06/unifi-express/0.png" class="" width="1024" title="alt"><blockquote><p>UniFi Express<br> <a href="https://www.ui.com/us/ja/cloud-gateways/wifi-integrated/express">https://www.ui.com/us/ja/cloud-gateways/wifi-integrated/express</a></p></blockquote><h2 id="この記事でのインターネットの構成"><a href="#この記事でのインターネットの構成" class="headerlink" title="この記事でのインターネットの構成"></a>この記事でのインターネットの構成</h2><p>私はauひかりホーム（10ギガ）を導入しており、貸与されたホームゲートウェイ（HGW）があります。その後ろにExpressを配置する形式となります。</p><img src="/new-technology/2024/03/06/unifi-express/diaglam.drawio.png" class="" width="240" title="alt"><h2 id="セットアップ"><a href="#セットアップ" class="headerlink" title="セットアップ"></a>セットアップ</h2><p>Expressはスマホだけでセットアップ可能です。むしろPCのブラウザを使うよりスマホアプリで行う方が便利です。<br>UniFiの製品は説明書というものがありません。いや、あるにはあるのですが、セットアップ方法＝アプリを使う事となっています。</p><img src="/new-technology/2024/03/06/unifi-express/1.png" class="" width="480" title="alt"><p>セットアップに関する説明書は注意書きを除けばこれが全て（That’s all!）です。</p><p>製品と付属品です。本体、電源ケーブル、30cmのLANケーブルが付属します。</p><img src="/new-technology/2024/03/06/unifi-express/2.png" class="" width="800" title="alt"><p>唯一の説明書通りに電源ケーブル、LANポートは2つあります（LAN、WAN）ので、WAN側（地球儀のマークがある方）に接続します。</p><img src="/new-technology/2024/03/06/unifi-express/3.png" class="" width="800" title="alt"><p>私の環境ではこの壁に接続したLANの接続口の先にHGWがあります。</p><p>さて、説明書のQRコードをiPhoneのカメラで読み込み、アプリをダウンロードしましょう。</p><img src="/new-technology/2024/03/06/unifi-express/4.png" class="" width="360" title="alt"><p>※上記の写真のiPhoneはWi-Fiに接続されていますがこれは既存環境のWi-Fiに接続されているものです。</p><img src="/new-technology/2024/03/06/unifi-express/5.png" class="" width="360" title="alt"><p>私の場合、既にUbiquitiのアカウントを保有しアプリにログインできていることや既存のUniFiコンソールに接続されている状態ですが、スマホがBluetooth経由でExpressを見つけると画面にセットアップ開始を促します。</p><img src="/new-technology/2024/03/06/unifi-express/6.png" class="" width="360" title="alt"><p>既存環境があるので選択制となっていますが、「新しいシステムを設定」を選びます。Expressが最初の1台の場合、この画面は出てこないと思われます。</p><p>また、今回の例では既に既存アカウントでアプリにログインしている状態ですが、全く新規の場合は、Ubiquitiのアカウントを新規作成します。</p><img src="/new-technology/2024/03/06/unifi-express/7.png" class="" width="360" title="alt"><p>今回、唯一セットアップしたと思える場所がここだけです。SSIDは既に”UniFi”となっており（変更可能）、ここでWi-Fiパスワードを指定します。</p><img src="/new-technology/2024/03/06/unifi-express/8.png" class="" width="360" title="alt"><p>ここからは眺めているだけです。</p><img src="/new-technology/2024/03/06/unifi-express/9.png" class="" width="360" title="alt"><img src="/new-technology/2024/03/06/unifi-express/10.png" class="" width="360" title="alt"><img src="/new-technology/2024/03/06/unifi-express/11.png" class="" width="360" title="alt"><p>ここで「Wi-Fiネットワークに参加」ボタンをタップします。UniFiアプリはSSID「UniFi」と設定したパスワードをiOSの設定アプリに送り込み自動的にWi-Fi接続が完了します。</p><p>これだけでもうiPhoneはインターネットにアクセスできるようになっています。顧客体験を重要視するUbiquitiらしい仕掛けです。</p><p>さて、アプリの表記では、HGWのDHCPによって割り当てられた<code>192.168.0.2</code>というExpressのWAN側IPアドレス、および、LAN側のIPアドレス<code>192.168.1.1</code>が振られています。</p><img src="/new-technology/2024/03/06/unifi-express/12.png" class="" width="360" title="alt"><p>Wi-Fiを見てみましょう、ExpressはWi-Fiチャンネルを含めて自動という言葉を多く見かけます。5GHzはデフォルトでは40MHzとなっていますが、80MHzに変更できるのでここで変更しておきましょう（最大160MHzにできます）。これ以外の自動は2つあって、Wi-Fiチャンネルおよび出力が自動となっています。日本のWi-Fiの電波出力の上限はざっくり説明すると200mW（23dBm）であり、その上限を超えないような設定となっています。クライアントの接続状況によって適切に電波の出力が調整され省エネにも有効です。</p><img src="/new-technology/2024/03/06/unifi-express/13.png" class="" width="360" title="alt"><p>設定からコンソールを見てみましょう。</p><img src="/new-technology/2024/03/06/unifi-express/14.png" class="" width="360" title="alt"><p>右下の歯車アイコンをタップ→コンソールをタップします。</p><p>ExpressはUniFi OSというOSで動作しており、その中のNetworkApplication（UNA）というアプリが動作しています。基本的にはOSをアップデートすることで内包されているUNAも自動的にアップデートされます。</p><img src="/new-technology/2024/03/06/unifi-express/15.png" class="" width="360" title="alt"><p>最新のUniFiOSにアップデートします。<br>このExpressは、UniFi OSはv3.2.5(Official)となりました。UNAはv8.0.28です。</p><p>今回は初回操作なので手動でアップデートすることにしましたが、毎日夜中3時に自動でアップデートチェックが行われ、自動でアップデートされます。また、Release Channelについては、”Official”(通常）、”Release Candidate”（リリース候補）、あとはUIアカウントのページから”Early Access”(ベータ版）を有効にすれば、3つのバージョンを選択できます。</p><blockquote><p>UI Account<br> <a href="https://account.ui.com/profile">https://account.ui.com/profile</a></p></blockquote><p>慣れるまではOfficialにしておくのがお勧めです。<br>Early Accessは事前確認する利用条件にある通り、守秘義務が存在します。許可なくその内容を第三者に開示してはいけません。安定しない場合も多く、広くユーザーに互換性を確認してもらうためのものです。</p><p>さて、ここまでで初期セットアップは完了です。</p><h2 id="速度チェック"><a href="#速度チェック" class="headerlink" title="速度チェック"></a>速度チェック</h2><p>気になるSpeedtestです。まずはiPhoneでWi-Fiのテストです。</p><img src="/new-technology/2024/03/06/unifi-express/16.png" class="" width="360" title="alt"><p>MTUも何も調整することなく、全くノーマルな状態での実行ですが、十分過ぎる速度です。本体の発熱も少なく、ほんのり暖かい程度です。<br>5GHzで160MHzの帯域を使うのであれば、以下の速度が出ます。</p><img src="/new-technology/2024/03/06/unifi-express/16-1.png" class="" width="360" title="alt"><p>有線とWi-Fiとは一般的に速度差があるので、ネットワーク機器はフローコントロールを有効にするのが普通で、遅いWi-Fiに合わせて有線側を”待たせる”仕組みが必要ですが、ここまで有線とWi-Fiとの速度差が無いとフローコントロールを有効にする必要がありません。<br>実際問題、フローコントロール無しでパケットのドロップが少ないのであればそれが一番効率よく通信でき、速度が出ます。<br>上記のSpeedtestはフローコントロール無しでの結果です。</p><p>Zero wait DFSという機能があり、DFSを回避できる機能もあるようですが、私の環境でタイミング良くレーダーが発生するわけでもなく、この検証は行えませんでした。</p><p>続いてLANケーブルでPCに繋いでみます。MinisforumのUM790Proは最近人気のミニPCですが、Expressはそれより1回り小さいです。</p><img src="/new-technology/2024/03/06/unifi-express/17.png" class="" width="640" title="alt"><p>1Gbpsの帯域をしっかりと使えています。小型ながら性能は大したものです。</p><h2 id="セットアップの補足"><a href="#セットアップの補足" class="headerlink" title="セットアップの補足"></a>セットアップの補足</h2><p>私の環境（auひかり）ではとても簡単にセットアップが完了しました。なお、Expressは現在、Officialリリースにおいてインターネットマルチフィード社が提供するtransix IPv4接続 (DS-Lite) への対応はされていますが、その他のIPv4 over IPv6の対応は現時点でサポート外となっています。</p><p>日本国内の大半がIPv4 over IPv6というわけでもなく、CATVやマンションが提供するLANなども鑑みると、シンプルにExpressを活用できる場所はたくさんあります。</p><p>Expressに関するガイドを以下に記載します。</p><ul><li><p>ネットワークが不安定、Lineなどでやり取りができなくなる。<br> 以下のガイドにMSS Clampingの設定で解決するという投稿がありますので確認ください。<br> Facebook Ubiquiti日本公式コミュニティ<br> <a href="https://www.facebook.com/groups/uijapan/learning_content/?filter=167949146143924&amp;post=3507234616157550">https://www.facebook.com/groups/uijapan/learning_content/?filter=167949146143924&amp;post=3507234616157550</a><br> この設定についてはExpressにブラウザでログインし、WANのMSS Clampingの値をCustomの1414等に設定する必要があります。具体的な設定はISPにより異なります。</p></li><li><p>IPv6 IPoE transix IPv4 (DS-Lite)の設定手順｜Ubiquiti UniFi<br> <a href="https://note.com/ui_japan/n/n3154ff641db5">https://note.com/ui_japan/n/n3154ff641db5</a></p></li></ul><p>インターネットマルチフィードのDS-Liteは以下のISPが対象となります。</p><ul><li>株式会社インターネットイニシアティブ<br> IIJ IPv6 FiberAccess&#x2F;Fサービス タイプIPoE</li><li>株式会社インターネットイニシアティブ<br> IIJmioひかり</li><li>株式会社インターネットイニシアティブ<br> IIJmio FiberAccess&#x2F;NF</li><li>株式会社インターリンク<br> ZOOT NATIVE</li><li>エキサイト株式会社<br> excite MEC光</li><li>エキサイト株式会社<br> BB.excite光Fit</li><li>エキサイト株式会社<br> BB.exciteコネクトIPoE接続プラン</li><li>スターティア株式会社<br> マネージドゲート2</li><li>メディアウェイブシステムズ株式会社<br> Hybrid64 (ハイブリッド・ろくよん）</li><li>メディアウェイブシステムズ株式会社<br> メディアひかり</li></ul><p>（引用： <a href="https://www.mfeed.ad.jp/transix/customers/">https://www.mfeed.ad.jp/transix/customers/</a>）</p><p>PPPoEやIPv4 over IPv6など、既存インフラの課題を頑張って解決する接続方式よりも、普通にIPv4、IPv6それぞれデュアルスタックで接続できるISPを選択するのが一番シンプルだと個人的には思います。PPPoEで、MTUからTCPヘッダおよびIPヘッダを除いたMSS1460バイトを1414バイトに詰め直すというのは、CPU負荷を高める原因となります。また、IPv4 over IPv6の接続では、IPアドレスとポートを他のユーザーと共有するため、固定IPアドレスが使用できず、割り当てられたポートしか開放できません。</p><h2 id="auひかりのIPv6"><a href="#auひかりのIPv6" class="headerlink" title="auひかりのIPv6"></a>auひかりのIPv6</h2><h3 id="HGWの設定"><a href="#HGWの設定" class="headerlink" title="HGWの設定"></a>HGWの設定</h3><p>さて、いくらExpressが簡単と言っても、Ubiquiti製品を選びたいというユーザーはやはりIPv6は使いたいと思われているでしょう。グローバルの一般的なIPv6の割り当て方法がUniFiにはあります。auひかりのユーザーはとても簡単にIPv6に接続できます。ここは少しだけ設定が必要です。なお、ここでのHGWの設定はあくまで戸建向けの光回線での実例です。</p><p>auひかりのHGWにブラウザでログインし<mark class="label primary">DHCPv6サーバ設定</mark>をタップします。</p><img src="/new-technology/2024/03/06/unifi-express/18.png" class="" width="360" title="alt"><p>続いて、IPv6アドレスの割り当て方法を選択します。</p><img src="/new-technology/2024/03/06/unifi-express/19.png" class="" width="360" title="alt"><p>Express向けにはいくつかの組み合わせが可能ですが、設定が3つあるうち設定2または3を選びます。<br>設定2ではIPv6アドレス＋DNSをDHCPv6で、PrefixをRAおよびDHCPv6で配布する方法です。DNS情報はDHCPv6で渡すのでRAオプションのDNSアドレス通知は使いません。設定3はPrefixをDHCPv6で配布します。デフォルトゲートウェイはRAの送信元から導きます。ここでは詳細の説明は割愛します。</p><p>最後に画面上部にある保存ボタンをタップして設定を保存してから、HGWはログアウトします。</p><h3 id="Express-WANの設定"><a href="#Express-WANの設定" class="headerlink" title="Express WANの設定"></a>Express WANの設定</h3><p>スマホアプリの右下の鍵マークアイコンの設定から<mark class="label primary">インターネット</mark>→<mark class="label primary">Primary(WAN1)</mark>→<mark class="label primary">高度な設定</mark>→<mark class="label primary">手動</mark>→<mark class="label primary">IPv6接続先</mark>のトグルを有効に、<mark class="label primary">DHCPv6</mark>を選択し、<mark class="label primary">プレフィックス委任サイズ</mark>を<strong>64</strong>にします。</p><img src="/new-technology/2024/03/06/unifi-express/20.png" class="" width="360" title="alt"><img src="/new-technology/2024/03/06/unifi-express/21.png" class="" width="360" title="alt"><p>あれ？と思った方、そうなんです。auひかりの委任は64ビット（サブネット1つだけ）なんです（ひかり電話を契約していても）。実はExpress以前に自分の使っている他社製ゲートウェイで確認したところ、&#x2F;64しか委任で貰えないようなんです。その製品のサポート担当者からは64ビットのような特殊な委任はサポート外と一刀両断されました。そりゃそうですよね。委任するというくらいなんだから最低でも60ビット（&#x2F;64を15個）など複数のサブネットがあるのが普通です。auひかりには「複数のIPv6サブネットの委任をできるようにお願いします」とは昨年秋に伝えましたが。。。</p><p>いずれにしても今回はExpressの世界、本格的な複数サブネット（VLAN）はまた今度にするとして、まずはシンプルなネットワークを作ることに専念しましょう。</p><p>ちなみに、HGWのLAN側IPv6アドレスは以下が割り当てられていました。</p><img src="/new-technology/2024/03/06/unifi-express/21-1.png" class="" width="360" title="alt"><p><code>240f:xxxx:xxxx:1::/64</code>ではない別のPrefix1つが割り当てられることになります。</p><h3 id="Express-LANの設定"><a href="#Express-LANの設定" class="headerlink" title="Express LANの設定"></a>Express LANの設定</h3><p>ExpressのLANのIPv6設定はブラウザ経由でなくてはなりません。<br>EXpressにブラウザでログインします。<br><code>https://unifi/</code> または<code>https://192.168.1.1</code></p><img src="/new-technology/2024/03/06/unifi-express/22.png" class="" width="360" title="alt"><p>ログイン後、画面右上の歯車アイコンをタップし、LANの設定に入ります。<br>スマホのキャプチャでは視認性が悪いので、ここではPC画面で項目の説明をします。</p><img src="/new-technology/2024/03/06/unifi-express/23.png" class="" width="640" title="alt"><p>IPv6のタブを選択し、<mark class="label primary">Prefix Delegation</mark>を選びます。<br>基本的には上記の画面キャプチャの通り、<mark class="label primary">WAN1</mark>インタフェースを選択します。</p><mark class="label primary">Client Address Assignment</mark>は趣味の範疇ですが、Expressが決定するアドレスにするならDHCPv6を、クライアントに任せるならSLAACを選びます。最近はSLAACでもMACアドレスベースに生成するのではなく、一時アドレスとしてクライアント側がIPアドレスを都度生成するので、IPアドレスを追跡できなくなりセキュリティ上は良いと言われています。但し、自身の管理としてログからは端末を判別しづらくなります。<p>これで設定はOKです。</p><h3 id="接続テスト"><a href="#接続テスト" class="headerlink" title="接続テスト"></a>接続テスト</h3><p>IPv6確認テストサイトで確認しましょう。</p><img src="/new-technology/2024/03/06/unifi-express/24.png" class="" width="800" title="alt"><p>問題なくIPv6で到達できているようです。HGWのPrefixは<code>240f:xxx:xxx:1::/64</code>でしたが、今回のPrefixは<code>240f:xxx:xxx:2::/64</code>となっており、パブリックIPv6アドレスがExpressに委任され、Expressからクライアントに配布されています。</p><blockquote><p>test-ipv6<br> <a href="https://test-ipv6.com/">https://test-ipv6.com</a></p></blockquote><p>これで一通りのセットアップは完了しました。UniFiスマホアプリは外出時に公衆回線からUbiquitiのクラウド経由でExpressに接続可能です。HGWのポート開放は必要ありません。後述するTeleportの技術を使っていてUbiquitiクラウドが接続管理、認証、通知などの役割を担ってくれます。これは無償のハイブリッドクラウド環境ですが、これこそがUbiqiutiが好まれる理由の1つです。</p><h2 id="Expressの機能-設定"><a href="#Expressの機能-設定" class="headerlink" title="Expressの機能&#x2F;設定"></a>Expressの機能&#x2F;設定</h2><p>必要な機能をPickupして見ていきます（多機能でとても全ては紹介しきれません）。トラフィック識別や、広告ブロックのフィルタリング状況はネットワークの見える化としてUbiquiti製品の特徴です。説明不要でグラフィカルで分かりやすいでしょうから、ここでは説明を割愛します。</p><p>管理画面ログイン後、左上のOSセッティングから<mark class="label primary">Console Settings</mark>に進みます。</p><img src="/new-technology/2024/03/06/unifi-express/25.png" class="" width="800" title="alt"><p>詳細の確認やトラブル対応の対策にSSHは事前に有効にしておきましょう。UNAにもSSHの設定がありますが、そちらはExpressが管理する配下のデバイスが対象であり今回は設定しません。</p><p>サポートとのやり取りで「サポートファイルが必要」となれば、画面最下部の<mark class="label primary">Download Support File</mark>から詳細ログをダウンロードし、UI Japanに送ることになります。</p><h3 id="プッシュ通知"><a href="#プッシュ通知" class="headerlink" title="プッシュ通知"></a>プッシュ通知</h3><p>任意設定ですが、アプリの歯車アイコンから<mark class="label primary">プッシュ通知</mark>を有効にしておくといくつかの通知を受けられます。</p><img src="/new-technology/2024/03/06/unifi-express/27.png" class="" width="360" title="alt"><p>障害などの重要なものはデフォルトで含まれています。それ以外にも、VPNの接続があったら通知する、レーダーを受信すると通知するなどいくつかの追加選択が可能です。</p><h3 id="広告ブロック"><a href="#広告ブロック" class="headerlink" title="広告ブロック"></a>広告ブロック</h3><p>UNAの設定（歯車アイコン）から、<mark class="label primary">セキュリティ</mark>を選択します。<br>ここでは<mark class="label primary">広告ブロック</mark>にチェックしておきます。広告ブロックはExpressにおいては、1つのネットワークのみ選択可能です。IPv6を有効にしていても広告は綺麗に消えますのでかなり有効です。<br>DNSシールドはDNSによる名前解決時にDoH（DNS over HTTPS）を使い、GoogleまたはCloudflareで名前解決するものです。TLS&#x2F;SSLで暗号化されているので、プロバイダや途中の経路において、どこにアクセスしているのか判らないようにする目的があります。日本のISPはDDoS対策のために独自のDNSフィルタを実施していることや、その情報を売却するなどの行為が厳しいために日本においてはDNSシールドの重要性はあまり無いものと考えられます。<br>なお、このDNSフィルタを使っていても、広告ブロックは有効です。Expressは広告ドメインを対象にDNSで排除します。</p><p>通常は、以下のクエリを返します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup www.googleadservices.com</span><br><span class="line">Server:240f:xxxx:xxxx:2::1</span><br><span class="line">Address:240f:xxxx:xxxx:2::1<span class="comment">#53</span></span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">Name:www.googleadservices.com</span><br><span class="line">Address: 172.217.xxx.xxx</span><br></pre></td></tr></table></figure><p>DNSフィルタを有効にすると。。。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup www.googleadservices.com.</span><br><span class="line">Server:240f:xxxx:xxxx:2::1</span><br><span class="line">Address:240f:xxxx:xxxx:2::1<span class="comment">#53</span></span><br><span class="line"></span><br><span class="line">Name:www.googleadservices.com</span><br><span class="line">Address: 0.0.0.0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>0.0.0.0を返すのでアクセスできなくなります。<br>控えめな広告であれば私は許容できるのですが、日本特有というか酷い内容の広告は徹底して除外したいものです。今のところExpressは綺麗に広告をカットしてくれています。</p><h2 id="Teleport-VPN"><a href="#Teleport-VPN" class="headerlink" title="Teleport(VPN)"></a>Teleport(VPN)</h2><p>まず、UniFiアプリでTeleportを有効にします。招待のリンクを生成します。</p><img src="/new-technology/2024/03/06/unifi-express/28-1.png" class="" width="360" title="alt"><p>UniFiアプリの設定（歯車アイコン）からWiFimanをインストールし、起動すると右下にTeleportというアイコンがあります。それをタップします。</p><img src="/new-technology/2024/03/06/unifi-express/28.png" class="" width="360" title="alt"><p>上記画面が表示されたら<strong>On</strong>をタップし接続開始するだけです。接続開始するまで10秒強掛かりますが、ポート開放無しにここまで自動でやってくれます。Teleport経由のSpeedtestは40Mbps弱で速いとは言えませんが、とてもお手軽です。</p><h3 id="Local-DNS"><a href="#Local-DNS" class="headerlink" title="Local DNS"></a>Local DNS</h3><p>さて、上記で自宅にVPNで接続できるようになりました。自宅に接続するというのは、そもそもNASやサーバーがある事が前提です。自宅内はローカルのDNS、hosts、NetBIOSでの名前解決を、外からはパブリックのIPをダイナミックDNSで管理し運用されていらっしゃる方も多いでしょう。<br>例えば私はSynologyのDDNSを取り敢えず利用する事にはしていますが、実際に公衆回線からパブリックIPを通して接続はしていません。単純にローカルDNSで、xxxx.synology.meというSynologyから与えられたホスト名＋ドメイン名（FQDN）で自宅ではアクセスしています（Synologyのスマホアプリもその名前（FQDN）を使います）。これはTLS&#x2F;SSL証明書とも関係ありますし、あまり自由な名前にできません。アプリのプッシュ通知による2要素認証もありますし、証明書のエラーになっていては自宅に接続できても使い物になりません。<br>UniFiには、Local DNS機能が存在しており、固定IPと名前とをセットで登録できます。</p><img src="/new-technology/2024/03/06/unifi-express/29.png" class="" width="1024" title="alt"><p>上記の右の赤枠のように、FQDNとプライベートの固定IPアドレスを設定しておきます。NASがDHCPでExpressにIPを要求すると、この固定IPアドレスとローカルDNSへの登録が自動で行われます。</p><img src="/new-technology/2024/03/06/unifi-express/30.png" class="" width="360" title="alt"><p>自宅、外出時のFQDNを統一できることで2要素認証のプッシュ通知、パスワードマネージャーからのID&#x2F;パスワード入力も極めてスムーズです。<br>Express1台でここまで便利に使えるようになります。</p><img src="/new-technology/2024/03/06/unifi-express/31.png" class="" width="1024" title="alt"><blockquote><p>UI Japan Store Express<br><a href="https://jp.store.ui.com/collections/unifi-network-unifi-os-consoles/products/ux">https://jp.store.ui.com/collections/unifi-network-unifi-os-consoles/products/ux</a></p></blockquote><p>価格は26,900円です。</p><h2 id="補足説明"><a href="#補足説明" class="headerlink" title="補足説明"></a>補足説明</h2><p>私のHGWはBL3000HMという機種です。</p><ul><li><a href="/new-technology/2023/01/28/bl3000hm/" title="auひかり BL3000HM">auひかり BL3000HM</a></li></ul><blockquote><p>Ubiquiti Japan ホームページ<br> <a href="https://note.com/ui_japan">https://note.com/ui_japan</a></p></blockquote><blockquote><p>Ubiquiti ヘルプセンター<br> <a href="https://help.jp.ui.com/categories/6583256751383/">https://help.jp.ui.com/categories/6583256751383/</a></p></blockquote><blockquote><p>Ubiquiti コミュニティ（日本）<br> <a href="https://www.facebook.com/groups/uijapan">https://www.facebook.com/groups/uijapan</a></p></blockquote><blockquote><p>Ubiquiti Community（米国中心）<br> <a href="https://community.ui.com/">https://community.ui.com/</a></p></blockquote><p>（製品提供：Ubiquiti Japan株式会社）</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/03/06/unifi-express/Title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;
&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;この記事ではUniFiネットワークの導入未経験の方を対象に、UniFiの新しい小型ゲートウェイUniFi Expressの具体的なセットアップおよび性能確認、機能紹介を目的としています。検証のため製品提供を受けていますのでこの記事はPR要素を含みます。&lt;/p&gt;</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    <category term="Network" scheme="https://yoshi0808.github.io/new-technology/categories/Network/"/>
    
    
    <category term="UniFi" scheme="https://yoshi0808.github.io/new-technology/tags/UniFi/"/>
    
  </entry>
  
  <entry>
    <title>VMWare 無償版ESXiの提供終了について（最終報）</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/03/04/EOS-Free-esxi3/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/03/04/EOS-Free-esxi3/</id>
    <published>2024-03-04T01:09:38.000Z</published>
    <updated>2024-04-07T10:43:06.884Z</updated>
    
    <content type="html"><![CDATA[<h2 id="VMWareからの告知"><a href="#VMWareからの告知" class="headerlink" title="VMWareからの告知"></a>VMWareからの告知</h2><p>2024-02-09ごろに、以下のKBが告知され、無償版ESXiは新たにインストールが不可能となりました。但し、パッチなどは継続的に提供されることが判明しましたので、その内容を持って最終報とさせていただきます。</p><blockquote><p>End Of General Availability of the Free vSphere Hypervisor (ESXi 7.x and 8.x) (2107518)<br> <a href="https://kb.vmware.com/s/article/2107518?lang=en_us">https://kb.vmware.com/s/article/2107518?lang=en_us</a></p></blockquote><blockquote><p>要約：<br> 無償版ESXiはVMWareのWebサイトではもはや利用できません。</p></blockquote><blockquote><p>解決方法：<br> 永久ライセンスから新しいサブスクリプション製品への移行の一環として、無償版ESXiは EOGA (End of General Availability) となりました。現時点では、同等の代替製品はありません。 </p></blockquote><span id="more"></span><p>無償版ESXiのインストールモジュールはすでにダウンロードできなくなりました。</p><p>1月30日に書いた記事「<a href="/new-technology/2024/01/30/EOS-Free-esxi/" title="VMWare 無償版ESXiの提供終了について">VMWare 無償版ESXiの提供終了について</a>」では、今後もESXiを新規利用またはアップグレードされる方はISOファイルのダウンロードとライセンスの取得をお勧めしていましたが、あまりに期間も短くお役に立てなかったかもしれません。</p><p>パッチについては、2024-03-01にESXi 8.0 Update 2bが発表されましたので、無償版ESXiでも当面パッチは提供されることが分かりました。少しホッとしたと同時に、早速、パッチ情報の記事についてアップデートしましたので、ESXi8をお使いの方はパッチの適用を検討ください。</p><p>「<a href="/new-technology/2020/06/14/esxi67-patch/" title="VMware ESXiにパッチを適用する">VMware ESXiにパッチを適用する</a>」</p><h2 id="ESXiの代替の検討"><a href="#ESXiの代替の検討" class="headerlink" title="ESXiの代替の検討"></a>ESXiの代替の検討</h2><p>（ここから先は第2報とほぼ同じ内容です）</p><p>当面はESXiを継続利用できますが、既にISOファイルはダウンロードできませんし、無償ライセンスの新規取得も不可能です。有償のESXiを使うつもりでなければ、代替を検討する必要があります。</p><h2 id="Proxmox-VE"><a href="#Proxmox-VE" class="headerlink" title="Proxmox VE"></a>Proxmox VE</h2><img src="/new-technology/2024/03/04/EOS-Free-esxi3/proxmox.png" class="" width="400" title="alt"><p>ProxmoxはLinuxユーザー、個人を中心に人気のあるプロダクトです。大学や団体の利用実績もあります。ドイツの2名の開発者からスタートした企業です。ESXiは比較的ネットワークカードやNVMeの種類を選びましたから、手軽に始められる仮想環境としてはまずはProxmoxが挙げられます。</p><blockquote><p>Proxmox Virtual Environment<br> <a href="https://www.proxmox.com/en/proxmox-virtual-environment/overview">https://www.proxmox.com/en/proxmox-virtual-environment/overview</a></p></blockquote><img src="/new-technology/2024/03/04/EOS-Free-esxi3/proxmox1.png" class="" width="1024" title="alt"><p>上記は取り急ぎproxmoxをセットアップして動作させたブラウザ画面のキャプチャです。現時点では、Ubuntu22をセットアップした程度でほとんど検証ができていません。</p><p>モニタ類も非常に見やすいです。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/proxmox2.png" class="" width="800" title="alt"><p>Proxmoxにはバックアップサーバーという製品もありますが、Proxmox VE単独でバックアップのスケジューリングができます。これは無償版ESXiと比べて良い点です。SynologyNASのNFS4.1に接続してバックアップしています。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/proxmox3.png" class="" width="640" title="alt"><p>通知は下記のように行われます。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/proxmox4.png" class="" width="640" title="alt"><p>バックアップ速度は4Gbps強です。差分のバックアップ（ブロック変更のみ）は無さそうですね。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">100: 2024-02-17 14:43:09 INFO: transferred 32.00 GiB <span class="keyword">in</span> 63 seconds (520.2 MiB/s)</span><br><span class="line">100: 2024-02-17 14:43:10 INFO: archive file size: 10.06GB</span><br></pre></td></tr></table></figure><p>スナップショットもESXi同等にメモリの状態まで確保できます（ZFSファイルシステムで実行）。</p><p>少し気になる点としては無償で利用するには開発用リポジトリを使うことになり、有償のリポジトリはより安全にテストされたものが利用できる仕組みです。GUIでもモジュールは更新できますが、更新の単位は<code>apt update</code>と同様の感覚です。リモートワークなどに利用しているVMがあるのであればその点は留意する必要があります。</p><p>まだ十分な検証ができていませんが、手軽にESXiからの移行を始めるにはProxmoxの環境で検証をスタートさせるのも良いかもしれません。<br>Proxmox自体、セキュアブートでインストールでき、VMもセキュアブートの設定ができます。</p><p>設定はややLinux寄りです。結局はLinuxのコマンドをGUIにうまく形を変えているとも言えます。ESXiで慣れていると少しギャップがあります。ESXiのVMWare Remote Consoleは素晴らしい製品でしたが、そこまでは行かずとも、別ウィンドウでVNCから暗号化通信でコンソールにアクセスするなど操作性はとても良く、先進的であると感じさせます。</p><p>取り急ぎ、ProxmoxVE8.1のセットアップとVMの新規作成に関する記事を投稿しています。Proxmoxを試してみたい方は参考にしてみてください。</p><ul><li><a href="/new-technology/2024/02/17/ProxmoxVE/" title="ProxmoxVEのインストール">ProxmoxVEのインストール</a></li><li><a href="/new-technology/2024/02/19/Proxmox-new-vm/" title="ProxmoxVEのVM新規作成（Ubuntu24.04LTS）">ProxmoxVEのVM新規作成（Ubuntu24.04LTS）</a></li></ul><h2 id="XCP-ng（XEN-Orchestra）"><a href="#XCP-ng（XEN-Orchestra）" class="headerlink" title="XCP-ng（XEN Orchestra）"></a>XCP-ng（XEN Orchestra）</h2><img src="/new-technology/2024/03/04/EOS-Free-esxi3/xcpng.png" class="" width="800" title="alt"><p>新しいプロダクトではありませんが、Citrixが提供しているXen Serverから派生したオープンソースシステムでVatesという会社が提供しています。2012年にフランスで設立されています。おそらく規模は小さい会社のように見えます。こちらは企業中心、またホームラボでも利用されています。<br>仮想化という概念では素晴らしいものをXenから継承しており、本格的なHypervisorです。ProxmoxはHypervisorとも言えますが、VMが明確に独立しておらずDMAなどのメモリへのアクセスはかなり自由です。一方、XCP-NGは厳格にセパレートされておりセキュリティが高く、安定度も高い物と考えられます。その犠牲になるのは速度ですが、XEN Orchestraという有償のGUI管理ツールはわかりやすいため、ESXiユーザーはこちらの方が気にいるかもしれません。</p><blockquote><p>XCP-ng<br> <a href="https://xcp-ng.org/#easy-to-install">https://xcp-ng.org/#easy-to-install</a></p></blockquote><p>Xen OrchestraのGUIツールは有償ですが、個人が使うためのソースコードが提供されており、自身でコンパイルして利用する分には無償です。有償のプロダクトはXOA（Xen Orchestra Apliance）、ソースコードからビルドしたものはXOと呼ばれ区別されています。</p><p>Proxmoxと比べると少しグラフィカルな面は見劣りするでしょうか。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/xo1.png" class="" width="1024" title="alt"><p>ネットワークなどは簡単にVLANを作成できて一覧として確認できるので管理しやすく思えます。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/xo2.png" class="" width="1024" title="alt"><p>これはMellanox Connect X-3の１つのPort（ネイティブVLAN&#x3D;1）にさらに仮想のVLAN110を加えています。</p><p>こちらもバックアップはスケジューリングできます。ESXiのようにバックアップもブロック単位の差分で取得できます。<br>バックアップのメール通知は以下のような形で行われます。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/xo3.png" class="" width="480" title="alt"><p>VMはブラウザから操作することになりますが、メニューの大きさも相まって、少し使いづらいと感じます。クライアントのVNCからXenOrchestraにSSHしてPort Forwardingすることによって暗号化した上で単独のVNCクライアントから操作できるようですが、こちらはまだ未確認です。</p><img src="/new-technology/2024/03/04/EOS-Free-esxi3/xo4.png" class="" width="1024" title="alt"><p>XCP-ng本体は特に難しいところもなくインストールができます。8.2.1はまだセキュアブートのセットアップはできません。VM自体はセキュアブートの設定ができます。また、Xen Orchestraの管理ツール自体は別ノードからアクセスする方が好ましく、最初からノード単位のフェールオーバーなどを考えて作られています。現在私のセットアップではXen OrchestraをESXiで、昔使っていたintelのPCにXCP-NGをセットアップしています。</p><p>XCP-ngの最新バージョンは現在8.2.1ですが、Ryzen環境で動作させると応答速度やネットワーク速度が遅く、Communityの情報を見ながら、古いintel core i7マシン（Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz）に再インストールするなど、少し回り道してしまいました。8.3はまだベータ版ですが、そこではRyzen版の速度改善が見込めるようなのでこちらはまた少し時間を置いてから検証を開始するつもりです。なお、P-Core&#x2F;E-CoreのCPUは仮想環境でどのようにCPUが使われるのか読めないと考えられ、難しさを感じています。</p><p>XCP-NGはスナップショットやバックアップが少し古い時代を感じさせるところがあります。稼働中のVMをバックアップした後にレストアすると、OSをブートするところから始まります。つまり、メモリの内容が廃棄されてしまいます。オープンしていたファイルがどうなるのか、恐らくロールバックされるとは思いますが、検証をしっかりと行いたい箇所ではあります。</p><p>XO自体のリポジトリはGitHubにあり、かなり細かい単位でMasterブランチ（メインのソースコードの配置場所）がCommitされていきます。どこかでそれらの更新部分を取り込むには改めてXOのソースコードのコンパイルから必要になります。但し、これは簡単なスクリプトで手間をかけずに対処可能です。</p><p>私がXCP-ngに期待しているのはシステムの安定度です。ESXiも本当に安定していて、これまでハードウェアの故障以外でハングしたりすることは全くありませんでした。また、Xen Orchestraは、企業で数十台の仮想サーバを管理することを想定して作られており、管理のしやすさを感じます。</p><p>Proxmox、XCP-ngともに良いプロダクトのようで、最終的にはどちらかの仮想環境をメインに使い、2台構成でライブマイグレーション（仮想マシンのノード間の移動）まで実現できればと考えています。</p><p>海外のホームラボのパワーユーザーはどちらかといえば、XCP-ngを好むようにも見えます。これは簡単なProxmoxは面白くないということなのかもしれません。ESXiの代替としてはXCP-ngが今脚光を浴びているように見えます。</p><p>XCP-ng、Xen Orchestraへの理解を深めるには、ローレンスシステムズのTom氏が解説しているYouTubeビデオがわかりやすいと思います。</p><blockquote><p>Understanding How The XCP-NG &amp; Xen Orchestra Open Source Virtualization Platform Works<br> <a href="https://www.youtube.com/watch?v=CEUFHudLO1g&amp;t=447s">https://www.youtube.com/watch?v=CEUFHudLO1g&amp;t=447s</a></p></blockquote><p>XCP-ngに興味のある方はこちらの記事をご覧ください。</p><ul><li><a href="/new-technology/2024/04/07/xcpng/" title="XCP-ngとXen Orchestra">XCP-ngとXen Orchestra</a></li><li><a href="/new-technology/2024/04/07/xcpng-newvm/" title="XCP-ngのVM新規作成">XCP-ngのVM新規作成</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;VMWareからの告知&quot;&gt;&lt;a href=&quot;#VMWareからの告知&quot; class=&quot;headerlink&quot; title=&quot;VMWareからの告知&quot;&gt;&lt;/a&gt;VMWareからの告知&lt;/h2&gt;&lt;p&gt;2024-02-09ごろに、以下のKBが告知され、無償版ESXiは新たにインストールが不可能となりました。但し、パッチなどは継続的に提供されることが判明しましたので、その内容を持って最終報とさせていただきます。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;End Of General Availability of the Free vSphere Hypervisor (ESXi 7.x and 8.x) (2107518)&lt;br&gt; &lt;a href=&quot;https://kb.vmware.com/s/article/2107518?lang=en_us&quot;&gt;https://kb.vmware.com/s/article/2107518?lang=en_us&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;要約：&lt;br&gt; 無償版ESXiはVMWareのWebサイトではもはや利用できません。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;解決方法：&lt;br&gt; 永久ライセンスから新しいサブスクリプション製品への移行の一環として、無償版ESXiは EOGA (End of General Availability) となりました。現時点では、同等の代替製品はありません。 &lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="ESXi" scheme="https://yoshi0808.github.io/new-technology/tags/ESXi/"/>
    
  </entry>
  
  <entry>
    <title>ProxmoxVEのVM新規作成（Ubuntu24.04LTS）</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/02/19/Proxmox-new-vm/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/02/19/Proxmox-new-vm/</id>
    <published>2024-02-19T00:04:44.000Z</published>
    <updated>2024-06-09T05:01:46.646Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/02/19/Proxmox-new-vm/Title.png" class="" title="alt"><p class="onepoint">この記事で実現すること</p><p>仮想環境のProxmox VEで仮想マシン（VM）の新規作成を行います。例示としてこの記事ではUbuntu24のセットアップを行います。ネットワークインターフェースと仮想マシンとの関係も見ていきます。</p><span id="more"></span><h2 id="Ubuntu-24-04LTSのダウンロード"><a href="#Ubuntu-24-04LTSのダウンロード" class="headerlink" title="Ubuntu 24.04LTSのダウンロード"></a>Ubuntu 24.04LTSのダウンロード</h2><p>最初にUbuntu24.04LTSのダウンロードを行います。</p><blockquote><p>Ubuntu Desktop 24.04 LTS<br> <a href="https://jp.ubuntu.com/download">https://jp.ubuntu.com/download</a><br> ファイル名は「ubuntu-24.04-desktop-amd64.iso」です。</p></blockquote><h2 id="Proxmox-VEのネットワーク構成"><a href="#Proxmox-VEのネットワーク構成" class="headerlink" title="Proxmox VEのネットワーク構成"></a>Proxmox VEのネットワーク構成</h2><p>新規VMのセットアップにはディスク、メモリ、ネットワークを定義することになりますが、VMの新規作成の前にネットワークインタフェースについて見ていきます。</p><p>以下は私の環境の例です。intel X710の4PortとRealtekのオンボードNIC（未使用）の５つが存在します。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox1.png" class="" width="1024" title="alt"><p>X710の4Portは”enp1s0f0”が1Port目、”enp1s0f3”が4Port目となっています。これが物理ネットワークインタフェースです。<br>これに加えて、インストール直後は、vmbr0というネットワークブリッジが作成されており、ここではセットアップ時に決めたIPアドレスが設定されているはずです。vmbr1以降は私が手動で作成しています。</p><p>仮想環境においてはL2ネットワークが重要であり、VMは仮想MACアドレスを保有します。ProxmoxのインタフェースではこのネットワークブリッジがNICの物理MACアドレス以外の仮想マシンのMACアドレスも受け取ることになり、いわば、無差別モード（プロミスキャスモード）で動作します。</p><p>仮想マシンに対してL2レイヤのブリッジ（取り次ぐ）を行うために、<mark class="label primary">Linux Bridge</mark>が必要となります。<br>Proxomoxにおいては命名規約は厳格であり、自由な名前は付けられません。ブリッジにしてもVLANにしても命名規則に従う必要があります。</p><p>ここでは仮想マシンの仮想MACアドレスは作成しません。VMを作成するタイミングで自動生成されることになります。L3レイヤ、つまりIPアドレスに関してProxmoxは意識しません。VMの中のOS任せであり、これはESXiなどの他のハイパーバイザーと考え方は同じです。</p><p>個人的には、物理ネットワークカードのMACアドレスが表示されないのは少しわかりづらく感じます。物理ネットワーク（ネットデバイス）にはコメント欄があるので、そこにMACアドレスを記入しておけば運用面はなんとかなりそうです。</p><h2 id="ISOの保存先"><a href="#ISOの保存先" class="headerlink" title="ISOの保存先"></a>ISOの保存先</h2><p>VMを新規作成する上で、OSのインストールのために予めISOファイルをコピーしておく必要があります。Proxmoxの左ペインから、<mark class="label primary">local(ホスト名)</mark>を選択します（私の環境ではホスト名がpve1という名前です）。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox2.png" class="" width="800" title="alt"><p>ここに<mark class="label primary">ISOイメージ</mark>とあるので、選択します。ここで、<mark class="label primary">アップロード</mark>ボタンをクリックし、ローカルの端末からISOファイルをアップロードします。今回は、Ubuntu24.04デスクトップをインストールするためにファイルアップロードします。</p><h2 id="VMの新規作成"><a href="#VMの新規作成" class="headerlink" title="VMの新規作成"></a>VMの新規作成</h2><p>ここでは２つのネットワークインタフェースを持つUbuntu24をセットアップします。もちろん、１つの場合はより簡単です。<br>Proxmoxの右上にある青いボタン<mark class="label primary">VMを作成</mark>をクリックします。いよいよ仮想マシンの作成に入ります。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox3.png" class="" width="480" title="alt"><p>ホスト名としての名前を（ご自身で決めたものを）入力します。VM IDは100から付番されていきます。また<mark class="label primary">ブート時に起動</mark>するか否かを決定します。</p><h3 id="OSの種類"><a href="#OSの種類" class="headerlink" title="OSの種類"></a>OSの種類</h3><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox4.png" class="" width="480" title="alt"><p>Linuxを選択します。UbuntuやDebianなどをバージョン毎に選ぶのかと思いましたが、種類は多くありません。<mark class="label primary">Kernel6.x-2.6</mark>または<mark class="label primary">Kernel2.4</mark>の2種類です。<mark class="label primary">Kernel6.x-2.6</mark>を選択します。今回は関係ありませんが、Windows11もインストールできるようですね。また、懐かしいSolarisも選択可能となっています。<br>さて、ISOファイルを選択して次に進みます。</p><h3 id="システム"><a href="#システム" class="headerlink" title="システム"></a>システム</h3><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox6.png" class="" width="480" title="alt"><p>ここでは、旧ブートのBIOS（SeaBIOS）かUEFIを選択します。UbuntuはUEFIに対応しているので基本的にはUEFIを選びます。<mark class="label primary">TPM追加</mark>は好みで選んでください。また、<mark class="label primary">Qemuエージェント</mark>のチェックボックスは最初、Offのままにしておきます（後で設定します）。ゲストにインストールするヘルパーデーモンであり、稼働状況をホストが把握するためや、ホストから安全にシャットダウンするなどのアクションができるようになります。ESXiではVMWareToolsに相当するモジュールです。</p><h3 id="ディスク"><a href="#ディスク" class="headerlink" title="ディスク"></a>ディスク</h3><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox7.png" class="" width="480" title="alt"><p>ディスクサイズを設定します。追加のボリュームを加える場合もここで設定します。</p><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox8.png" class="" width="480" title="alt"><p>CPUの種別、CPUのコア数を指定します。Extra CPU Flagsとしていくつかの脆弱性に対応させるためのチェックがあります。私はRyzen５5600GにProxmoxをインストールしているので下記のオプションとしました。<br>CPUの種別は特定されたものがあればそれを、無ければ一般的に<mark class="label primary">x86-64-v2-AES</mark>を選びます。Intel&#x2F;AMDをクラスタで混在させないならそのCPUの最も古いものに合わせておくのが良いようです。詳細はヘルプのCPU TYPEを確認してください。</p><blockquote><p>If you don’t care about live migration or have a homogeneous cluster where all nodes have the same CPU and same microcode version, set the CPU type to host, as in theory this will give your guests maximum performance.</p></blockquote><blockquote><p>If you care about live migration and security, and you have only Intel CPUs or only AMD CPUs, choose the lowest generation CPU model of your cluster.</p></blockquote><blockquote><p>If you care about live migration without security, or have mixed Intel&#x2F;AMD cluster, choose the lowest compatible virtual QEMU CPU type.</p></blockquote><h3 id="メモリ"><a href="#メモリ" class="headerlink" title="メモリ"></a>メモリ</h3><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox9.png" class="" width="480" title="alt"><p>VMで利用するメモリの量を設定します。</p><h3 id="ネットワーク"><a href="#ネットワーク" class="headerlink" title="ネットワーク"></a>ネットワーク</h3><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox10.png" class="" width="480" title="alt"><p>特に変更することはなく、NICのモデルは、<mark class="label primary">VirtIO(準仮想化)</mark>を選んでおきます。おっと、ここではNICを追加することができませんね。後で2枚目のNICを追加することになるのでしょうか。まずはメインの<mark class="label primary">vmbr0</mark>ブリッジを選択しておきます。</p><h3 id="確認"><a href="#確認" class="headerlink" title="確認"></a>確認</h3><p>最後に確認画面で完了します。</p><h2 id="（任意）仮想マシンでネットワークの追加"><a href="#（任意）仮想マシンでネットワークの追加" class="headerlink" title="（任意）仮想マシンでネットワークの追加"></a>（任意）仮想マシンでネットワークの追加</h2><p>2枚目のNICをVMに追加する場合、仮想マシンが作成されたら、以下のようにハードウェアからネットワークの追加を行います。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox12.png" class="" width="1024" title="alt"><h2 id="VMの起動"><a href="#VMの起動" class="headerlink" title="VMの起動"></a>VMの起動</h2><p>左ペインでVMを選択した状態で、画面上部の<mark class="label primary">▶︎開始</mark>をクリックします。</p><p>さて、無事にコンソールから起動してきました。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox13.png" class="" width="1024" title="alt"><p>ProxoxのVMの<mark class="label primary">コンソール</mark>のプルダウンから、<mark class="label primary">VNC</mark>を選ぶと大きな画面でセットアップを進められます。</p><h2 id="Ubuntu24-04-Desktopのインストール"><a href="#Ubuntu24-04-Desktopのインストール" class="headerlink" title="Ubuntu24.04 Desktopのインストール"></a>Ubuntu24.04 Desktopのインストール</h2><p>さて、ここからはUbuntuのセットアップに入ります。とは言っても、殆ど迷うことなくセットアップは完了します。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu1.png" class="" width="800" title="alt"><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu2.png" class="" width="800" title="alt"><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu3.png" class="" width="800" title="alt"><p>迷うのはキーボードぐらいでしょうか。実際にタイプしてよく問題になりそうな記号について確認できます。「検出」を行うと、海外を基準として様々な文字の有無を確認させられるのでかえって面倒です。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu4.png" class="" width="800" title="alt"><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu5.png" class="" width="800" title="alt"><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu6.png" class="" width="800" title="alt"><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu7.png" class="" width="800" title="alt"><p>オフィスツールなどを利用するか否かでセットアップの種類を選択します。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu8.png" class="" width="800" title="alt"><p>追加のドライバなどはお好みで設定してください。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu9.png" class="" width="800" title="alt"><p>ファイルシステムの変更を行う場合（ex. ext4→ZFS）は、ここでカスタマイズします。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu10.png" class="" width="800" title="alt"><p>最初のユーザーを作成します。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu11.png" class="" width="800" title="alt"><p>タイムゾーンを設定して完了です。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu12.png" class="" width="800" title="alt"><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu13.png" class="" width="800" title="alt"><p>Ubuntu Proの設定確認があるので、登録します。できるだけシャットダウンせずに自動的にパッチが適用できます。個人ユーザーの場合は、Ubuntu Oneアカウントを作成し、それからProのレジストを行うことで対応できます。add token manuallyを選択して、Proのレジストが終わってから、トークンをここに貼り付けて完了させます。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu14.png" class="" width="800" title="alt"><p>Ubuntu Oneアカウントがない場合は、こちらからアカウントを作成します。文字列のコピーペーストをするので、UbuntuのFirefoxを使ってアカウントの作成とProのレジストを行ってください。</p><p><a href="https://login.ubuntu.com/">https://login.ubuntu.com/</a></p><p>その後、Ubuntu Proのレジストを以下で行います。<br><a href="https://ubuntu.com/pro">https://ubuntu.com/pro</a></p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu15.png" class="" width="800" title="alt"><p>さて、Proのレジストが完了すると、トークンを入手できますので、Ubuntuのセットアップ画面にトークンを貼り付けます。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu16.png" class="" width="800" title="alt"><p>登録が完了すると以下の画面になります。できるだけリブートせずに自動的にパッチが当たっていくので運用がとても楽になります。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/ubuntu17.png" class="" width="800" title="alt"><h3 id="Open-SSH-Serverのインストール"><a href="#Open-SSH-Serverのインストール" class="headerlink" title="Open SSH Serverのインストール"></a>Open SSH Serverのインストール</h3><p>UbuntuにSSHするために必ず必要なモジュールです。GUIでコマンドを扱うには<mark class="label primary">端末</mark>というアプリケーションを起動します。 そこからopensshをインストールします。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install openssh-server</span><br><span class="line"></span><br><span class="line">パッケージリストを読み込んでいます... 完了</span><br><span class="line">依存関係ツリーを作成しています... 完了</span><br><span class="line">状態情報を読み取っています... 完了</span><br><span class="line">以下の追加パッケージがインストールされます:</span><br><span class="line">  ncurses-term openssh-sftp-server ssh-import-id</span><br><span class="line">提案パッケージ:</span><br><span class="line">  molly-guard monkeysphere ssh-askpass</span><br><span class="line">以下のパッケージが新たにインストールされます:</span><br><span class="line">  ncurses-term openssh-server openssh-sftp-server ssh-import-id</span><br><span class="line">アップグレード: 0 個、新規インストール: 4 個、削除: 0 個、保留: 0 個。</span><br><span class="line">751 kB のアーカイブを取得する必要があります。</span><br><span class="line">この操作後に追加で 6,046 kB のディスク容量が消費されます。</span><br><span class="line">続行しますか? [Y/n] Y</span><br></pre></td></tr></table></figure><p>Ubuntuで<mark class="label primary">端末</mark>アプリケーションを起動する場合、キーボードショートカットによる起動が便利です。セットアップ時のキーボードの選択によって内容は変わりますが、Widnowsは”Ctrl”+”Alt”+”T”で起動します。macOSでは”option”+”control”+”T”で起動します。</p><h2 id="Proxmoxのセットアップの続き"><a href="#Proxmoxのセットアップの続き" class="headerlink" title="Proxmoxのセットアップの続き"></a>Proxmoxのセットアップの続き</h2><p>さて、Proxmoxの世界に戻ります。セットアップしているところでVMのサマリー画面を見ていると結構面白いですね。1vCPUと2GBのメモリでは少々足りないようです。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox14.png" class="" width="1024" title="alt"><p>もちろん後からCPUとメモリは変更できます。4vCPU&#x2F;4GBのメモリでもFirefoxを起動し、Fast.comに接続すると結構しんどそうです（1.5Gbps）。Ryzen7 5700GのESXiでは2vCPU&#x2F;2GBで2.4Gbps、XCP-ngでは古いCore <a href="mailto:&#105;&#55;&#x2d;&#x38;&#x37;&#48;&#48;&#x40;&#x33;&#x2e;&#x32;&#x30;&#71;&#x48;&#x7a;">&#105;&#55;&#x2d;&#x38;&#x37;&#48;&#48;&#x40;&#x33;&#x2e;&#x32;&#x30;&#71;&#x48;&#x7a;</a>で2vCPU&#x2F;2GBで2.8Gbpsなので最適化という意味では若干改善の余地があるような気もします。これがCLIベースのSpeedtestだと3者共に殆ど結果が変わらないので何か描画などに関してオーバーヘッドがあるのかなという気がしています。</p><p>また、ゲストエージェントが未設定という表示もされています。</p><h2 id="VMの確認と後工程"><a href="#VMの確認と後工程" class="headerlink" title="VMの確認と後工程"></a>VMの確認と後工程</h2><p>Ubuntuのセットアップが終了して再起動後、さらにUbuntuモジュールの更新処理が行われていきます。<br>それがひと段落したら、ゲストエージェントをインストールします。Ubuntu上の端末アプリケーションを起動し、以下のコマンドを入力します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install qemu-guest-agent</span><br></pre></td></tr></table></figure><p>これでゲストエージェントのインストールは完了です。一旦、VMをシャットダウンします。<br>続いて、VMのオプションから、<mark class="label primary">QEMU Guest Agent</mark>を有効にします。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox15.png" class="" width="1024" title="alt"><p>再度、Ubuntuを起動し、サマリ情報を参照すると、以下のようにIPアドレスの情報が取得できています。当たり前ですが、IPv6も確認できます。</p><img src="/new-technology/2024/02/19/Proxmox-new-vm/proxmox16.png" class="" width="800" title="alt"><mark class="label primary">More</mark>ボタンをクリックすると、2枚目のNICのIPアドレスも確認できます。<p>これでProxmoxに関して、一通りセットアップからVMの作成までを終えました。CPUタイプのあたりは少し最適化に向けて試行錯誤は必要そうですが、とても簡単にVMが作成できることがわかりました。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/02/19/Proxmox-new-vm/Title.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;仮想環境のProxmox VEで仮想マシン（VM）の新規作成を行います。例示としてこの記事ではUbuntu24のセットアップを行います。ネットワークインターフェースと仮想マシンとの関係も見ていきます。&lt;/p&gt;</summary>
    
    
    
    <category term="Software" scheme="https://yoshi0808.github.io/new-technology/categories/Software/"/>
    
    
    <category term="proxmox Ubuntu" scheme="https://yoshi0808.github.io/new-technology/tags/proxmox-Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>ProxmoxVEのインストール</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/02/17/ProxmoxVE/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/02/17/ProxmoxVE/</id>
    <published>2024-02-17T13:52:00.000Z</published>
    <updated>2024-02-20T14:05:33.844Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/02/17/ProxmoxVE/Title.png" class="" title="alt"><p class="onepoint">この記事で実現すること</p><p>個人ユーザーでも手軽に始められる仮想環境のProxmox VE8.1のインストールを行います。セットアップは非常に簡単ですが、ポイントを絞って解説していきます。</p><span id="more"></span><h2 id="Proxmox-VEとは"><a href="#Proxmox-VEとは" class="headerlink" title="Proxmox VEとは"></a>Proxmox VEとは</h2><p>Proxmox VEは、Debianベースのオープンソース仮想プラットフォームです。LinuxのKVMベースの仮装化とLXCのコンテナに対応しています。KVMはLinuxの一部であり、正統なハイパーバイザーにかなり近いですが、Linuxの中間型ともいえ、メモリ管理はあくまでLinuxとして行われるのが特徴です。Linuxにより近いことでパフォーマンスのボトルネックが少ないとも言えます。一方、セキュリティなどVMの独立性というセキュリティの面では正統なハイパーバイザーよりは劣ります。</p><p>KVMはかなりPC寄りでコマンド中心の管理となり、何らかのGUIツールと組み合わせて利用されることが一般的です。ProxmoxはGUI中心の操作で、それ単体でバックアップやスナップショットなどが実行でき、手軽で便利な仮想環境の最有力候補となります。</p><p>特にLinuxで稼動するツールなどを利用する想定だと、複数個のVMを立てる必要となりますので、最近の多数のコアのPCがあると便利です。ESXiのようにネットワークカードを厳選してしまう事もないので2.5GbEなどをはじめ多くの方が利用できるでしょう。NASとは異なり、仮想環境は一般的に大量のトラフィックを捌くものではないので、単にサーバーを立ち上げるだけであれば1GbEで十分なことも多いでしょう。さほどCPUが強力ではないミニPCを使うケースも多く見られます。<br>一方、ファイアウォールやルーターとして利用する場合は高速なCPUと10GbEのネットワークが必要となるケースもあり、利用方法は2分されます。</p><p>インストールは英語ですが、操作画面の言語は日本語が表示できます。</p><h2 id="価格と安定度"><a href="#価格と安定度" class="headerlink" title="価格と安定度"></a>価格と安定度</h2><p>Proxmoxは有償のプロダクトですが、本番環境で利用しないことを想定して無償で利用できます。それはモジュールなどのアップデートがベータ版としての扱いのモジュールが含まれることになります。これは「サブスクリプション無しのリポジトリ」と呼ばれます。セキュリティパッチなどを考えると原則パッチは当てていくことになりますが、その中に不十分なテストモジュールを含む場合があり、システム全体の安定度はあまり担保されません。自己責任ですので「お勧めしない」ということになります。また、ESXiのような、エンタープライズ向けのシステムではないのでドライバーなどがあまりこなれていないようにも見えます。</p><p>安定度への貢献のため、無償ユーザーがテストを兼ねるというのはよく考えられています。ネットワークのUbiquitiもそうですが、ホームユーザーは積極的にアルファ版のテストから参加されています。</p><p>価格と機能については以下のメニューとなっています。</p><img src="/new-technology/2024/02/17/ProxmoxVE/price.png" class="" width="1024" title="alt"><p>一番下のCommunityでも、Enterpriseリポジトリが使えます。価格は年間、1CPUソケットあたり110ユーロ（約17,800円）です。<br>無償ESXiから乗り換えを検討している状況なら、VMUGというユーザーグループに加入し、VMWare製品を個人利用限定で使う場合を考えると参加費用の年間200ドル（約30,000円）が必要です。これらを両睨みで考えることになるでしょうか。費用を支払う場合は、VMWareの方が色々な製品を使えてお得なのかなと考えられますが、こういった価格帯系は急に変わることも多く悩みどころです。</p><p>私はProxmoxを検証のためしばらく利用するつもりですが、有償のリポジトリとしてはおそらく利用せず、あくまで検証や安定性に難があっても構わない領域で使っていこうと考えています。</p><h2 id="システム要件"><a href="#システム要件" class="headerlink" title="システム要件"></a>システム要件</h2><p>推奨ハードウェアは以下の通りです。</p><ul><li>IntelVT&#x2F;AMD-V、CPUフラグ付きのIntelEMT64またはAMD64。</li><li>メモリ、OSおよびProxmox VEサービス用の最低2GB。さらに、ゲスト用の指定されたメモリ。CephまたはZFSの追加メモリが必要な場合は、使用するストレージTBごとに約1GBのメモリが必要。</li><li>高速で冗長なストレージ、SSDディスクで最高の結果。</li><li>ストレージ：バッテリーで保護された書き込みキャッシュ（BBU）を備えたハードウェアRAID、またはZFSおよびSSDキャッシュを備えた非RAID。</li><li>VMストレージ： ローカルストレージには、バッテリーバックアップ書き込みキャッシュ（BBU）またはZFS用の非RAIDを備えたハードウェアRAIDを使用。ZFS、CephはハードウェアRAIDコントローラと互換性無し。共有および分散ストレージも可能。</li><li>冗長Gbit NIC、優先ストレージ技術とクラスターセットアップに応じて追加のNIC - 10 Gbit以上もサポート。PCI(e)パススルーには、VT-d&#x2F;AMD-d CPUフラグ付きのCPUが必要。</li></ul><p>こうやってRequirementを見てみると個人向けとも言えない本格派の構成を想定しているように見受けられます。本番環境ではお勧めしないとしつつも、その目線の高さを感じられます。<br>最小構成など詳細は以下のリンクを参照してください。</p><blockquote><p>Proxmox システム要件<br> <a href="https://www.proxmox.com/en/proxmox-virtual-environment/requirements?highlight=WyJoYXJkd2FyZSIsImhhcmR3YXJlJ3MiLCJjb21wYXRpYmxlIiwiY29tcGF0aWJpbGl0eSJd">https://www.proxmox.com/en/proxmox-virtual-environment/requirements?highlight=WyJoYXJkd2FyZSIsImhhcmR3YXJlJ3MiLCJjb21wYXRpYmxlIiwiY29tcGF0aWJpbGl0eSJd</a></p></blockquote><h2 id="モジュールのダウンロード"><a href="#モジュールのダウンロード" class="headerlink" title="モジュールのダウンロード"></a>モジュールのダウンロード</h2><p>以下のURLからモジュールをダウンロードします。</p><blockquote><p>Download ISO image<br> <a href="https://www.proxmox.com/en/downloads/proxmox-virtual-environment/iso">https://www.proxmox.com/en/downloads/proxmox-virtual-environment/iso</a></p></blockquote><p>最新バージョンは8.1です。</p><p>WindowsであればRufusなどでUSBメモリにISOファイルをインストールします。</p><blockquote><p>Rufus<br> <a href="https://rufus.ie/ja/">https://rufus.ie/ja/</a></p></blockquote><p>または、WindowsのMicrosoftストアアプリでRufusを検索してインストールします。</p><p>Proxmox 8.1はセキュアブートに対応しています。UEFIでセキュアブートでのインストールがうまくいかない場合は、 UEFIセットアップ画面でセキュアブートをOffに、CMSサポートを有効にするなどして古いブート形式で起動しセットアップを行います。</p><p>その他のOSでメディアを作成するなど、インストールに関する情報は以下を参照してください。</p><blockquote><p>Installing Proxmox VE<br> <a href="https://pve.proxmox.com/pve-docs/chapter-pve-installation.html">https://pve.proxmox.com/pve-docs/chapter-pve-installation.html</a></p></blockquote><h2 id="インストール"><a href="#インストール" class="headerlink" title="インストール"></a>インストール</h2><p>インストールに入る前に、複数のネットワークカードがある場合は、どのPortをメインのマネジメントインタフェースにするか決めておく必要があるので、それぞれのNICのMACアドレスを確認しておく事をお勧めします。</p><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox1.png" class="" width="1024" title="alt"><p>セットアップを起動し、<mark class="label primary">Install Proxmox VE(Graphical)</mark>を選択します。</p><ol><li>EULAへの同意</li><li>Diskのフォーマット選択画面が表示されます。</li></ol><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox2.png" class="" width="1024" title="alt"><ol start="3"><li><p>optionをクリックします。</p></li><li><p>ファイルシステムはデフォルトはext4です。ここで、xfs、zfs、btrfsとが選択できます。<br> ファイルシステムは以下の項目を参考に決定してください。</p></li></ol> <img src="/new-technology/2024/02/17/ProxmoxVE/proxmox3.png" class="" width="1024" title="alt"><p> デフォルトのext4ではLVM（ブロックベース）が選択できるとのことで、コンテナはLVM-Thinが使いやすいようです。zfsはファイルとブロックベースとが利用できます。上記の内容を踏まえてご自身の利用に沿ったファイルシステムを選択します。</p><ol start="5"><li><p>場所とタイムゾーンを指定します。</p></li><li><p>rootでログインするパスワードとメールアドレスを指定します。</p></li><li><p>ネットワークの情報です。サーバーですので固定IPアドレスを振ることをお勧めします。複数のNICがある場合はメインのNICのMACアドレスを選択します。</p> <img src="/new-technology/2024/02/17/ProxmoxVE/proxmox4.png" class="" width="1024" title="alt"></li><li><p>最後に確認画面が表示されて<mark class="label primary">Install</mark>ボタンをクリックしてインストールが始まります。</p></li></ol><h2 id="初期設定"><a href="#初期設定" class="headerlink" title="初期設定"></a>初期設定</h2><p>まずインストール時に決めたパスワードでログインします。ここで言語設定も変更しておきます。</p><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox5.png" class="" width="400" title="alt"><p>最初に「有効なサブスクリプションがありません」というダイアログが出ます。これは無償で使う場合は今後も必ず表示されます。<br>早速、「サブスクリプション無しのリポジトリ」に切り替えます。</p><p>以下の画面から左上のホスト（インストール時のホスト名）を選択し、画面中央の<mark class="label primary">リポジトリ</mark>を選択します。</p><ol><li><mark class="label primary">追加</mark>ボタンから、<mark class="label primary">No-Subscription</mark>をプルダウンから選び追加します。</li><li>右下部分の<mark class="label primary">Enterprise</mark>の文字が含まれる2つのリポジトリを<mark class="label primary">Disable</mark>ボタンをクリックして無効化します。</li></ol><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox6.png" class="" width="1024" title="alt"><h2 id="任意-定期的なジョブ結果を通知するメール設定"><a href="#任意-定期的なジョブ結果を通知するメール設定" class="headerlink" title="(任意)定期的なジョブ結果を通知するメール設定"></a>(任意)定期的なジョブ結果を通知するメール設定</h2><p>以下の画面からSMTPを選択します。</p><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox7.png" class="" width="1024" title="alt"><p>以下の画面で必要項目を入力しますが、簡単なのはGmailを送信者として自分宛のよく使うメアド宛に通知する方法です。</p><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox8.png" class="" width="480" title="alt"><p>Googleアカウントから、<mark class="label primary">セキュリティ</mark>→<mark class="label primary">2段階認証プロセス</mark>→<mark class="label primary">アプリパスワード</mark>へと進みます。</p><p>ここで、アプリ名を入力し、作成ボタンをクリックするとパスワードが生成されます。</p><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox9.png" class="" width="480" title="alt"><p>このパスワードを前述のProxmoxの通知用メール設定の送信者のパスワードとして設定します。基本的にここで設定したGmailのアカウントが発信者として、Proxmoxをインストールした時に設定したメールアドレス宛に通知が行われることになります。<br>このダイアログで設定した後は<mark class="label primary">Test</mark>ボタンで検証可能です。</p><h2 id="任意-バックアップサーバー（NFSなど）への接続"><a href="#任意-バックアップサーバー（NFSなど）への接続" class="headerlink" title="(任意)バックアップサーバー（NFSなど）への接続"></a>(任意)バックアップサーバー（NFSなど）への接続</h2><p>以下のようにメニューから外部サーバーを選択します。</p><img src="/new-technology/2024/02/17/ProxmoxVE/proxmox10.png" class="" width="640" title="alt"><p>注意点としてはサーバーのNFSのバージョンと合わせます。また<mark class="label primary">内容</mark>は<mark class="label primary">VZDumpバックアップファイル</mark>を選択します。<mark class="label primary">Export</mark>はNASなどの外部サーバーのパスを設定しますので、NASなどのマニュアルを確認して設定してください。</p><h2 id="その他"><a href="#その他" class="headerlink" title="その他"></a>その他</h2><ul><li>SSHでログインし、<code>/.ssh</code>にauthorized_keyがありますので、そこに公開鍵をAppendしておけば公開鍵認証が可能です。</li><li>あまり人にお勧めはできませんが、ProxmoxにSSHし、intel X710のファームウェアをアップデートしました（v9.4）。intelのサイトからダウンロードし、Linux用を利用しました。</li></ul><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>これでProxoxの一通りのセットアップが完了です。ネットワークはまだ見ていませんが、これはVMセットアップの時に確認をしていきます。</p><ul><li><a href="/new-technology/2024/02/19/Proxmox-new-vm/" title="ProxmoxVEのVM新規作成（Ubuntu24.04LTS）">ProxmoxVEのVM新規作成（Ubuntu24.04LTS）</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/02/17/ProxmoxVE/Title.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;個人ユーザーでも手軽に始められる仮想環境のProxmox VE8.1のインストールを行います。セットアップは非常に簡単ですが、ポイントを絞って解説していきます。&lt;/p&gt;</summary>
    
    
    
    
    <category term="proxmox" scheme="https://yoshi0808.github.io/new-technology/tags/proxmox/"/>
    
  </entry>
  
  <entry>
    <title>VMWare 無償版ESXiの提供終了について（第2報）</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/02/14/EOS-Free-esxi2/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/02/14/EOS-Free-esxi2/</id>
    <published>2024-02-14T05:09:13.000Z</published>
    <updated>2024-02-19T13:11:23.709Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/02/14/EOS-Free-esxi2/vm1.png" class="" width="1024" title="alt"><span id="more"></span><h2 id="VMWareからの告知"><a href="#VMWareからの告知" class="headerlink" title="VMWareからの告知"></a>VMWareからの告知</h2><p>2024-02-09ごろに、以下のKBが告知されました。</p><blockquote><p>End Of General Availability of the Free vSphere Hypervisor (ESXi 7.x and 8.x) (2107518)<br> <a href="https://kb.vmware.com/s/article/2107518?lang=en_us">https://kb.vmware.com/s/article/2107518?lang=en_us</a></p></blockquote><blockquote><p>要約：<br> 無償版ESXiはVMWareのWebサイトではもはや利用できません。</p></blockquote><blockquote><p>解決方法：<br> 永久ライセンスから新しいサブスクリプション製品への移行の一環として、無償版ESXiは EOGA (End of General Availability) となりました。現時点では、同等の代替製品はありません。 </p></blockquote><p>つまり、無償版ESXiのインストールモジュールはすでにダウンロードできなくなりました。<br>なお、パッチについては、VMWareのカスタマーコネクトにログインした上で、従来通り、製品パッチをダウンロードできます。2&#x2F;14 20時においてダウンロードできました。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/cc.png" class="" width="1024" title="alt"><p>1月30日に書いた記事「<a href="/new-technology/2024/01/30/EOS-Free-esxi/" title="VMWare 無償版ESXiの提供終了について">VMWare 無償版ESXiの提供終了について</a>」では、今後もESXiを新規利用またはアップグレードされる方はISOファイルのダウンロードとライセンスの取得をお勧めしていましたが、あまりに期間も短くお役に立てなかったかもしれません。</p><p>これにはもはや抗うことはできないようです。</p><h2 id="ESXiの代替の検討"><a href="#ESXiの代替の検討" class="headerlink" title="ESXiの代替の検討"></a>ESXiの代替の検討</h2><p>既に稼働済みの無償版ESXiは定期的なオンライン認証などがあるわけではないので当面の間利用は継続できますが、有償のESXiを使うつもりでなければ、移行について検討しなければなりません。</p><h2 id="Proxmox-VE"><a href="#Proxmox-VE" class="headerlink" title="Proxmox VE"></a>Proxmox VE</h2><img src="/new-technology/2024/02/14/EOS-Free-esxi2/proxmox.png" class="" width="400" title="alt"><p>ProxmoxはLinuxユーザー、個人を中心に人気のあるプロダクトです。大学や団体の利用実績もあります。ドイツの2名の開発者からスタートした企業です。ESXiは比較的ネットワークカードやNVMeの種類を選びましたから、手軽に始められる仮想環境としてはまずはProxmoxが挙げられます。</p><blockquote><p>Proxmox Virtual Environment<br> <a href="https://www.proxmox.com/en/proxmox-virtual-environment/overview">https://www.proxmox.com/en/proxmox-virtual-environment/overview</a></p></blockquote><img src="/new-technology/2024/02/14/EOS-Free-esxi2/proxmox1.png" class="" width="1024" title="alt"><p>上記は取り急ぎproxmoxをセットアップして動作させたブラウザ画面のキャプチャです。現時点では、Ubuntu22をセットアップした程度でほとんど検証ができていません。</p><p>モニタ類も非常に見やすいです。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/proxmox2.png" class="" width="800" title="alt"><p>Proxmoxにはバックアップサーバーという製品もありますが、Proxmox VE単独でバックアップのスケジューリングができます。これは無償版ESXiと比べて良い点です。SynologyNASのNFS4.1に接続してバックアップしています。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/proxmox3.png" class="" width="640" title="alt"><p>通知は下記のように行われます。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/proxmox4.png" class="" width="640" title="alt"><p>バックアップ速度は4Gbps強です。差分のバックアップ（ブロック変更のみ）は無さそうですね。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">100: 2024-02-17 14:43:09 INFO: transferred 32.00 GiB <span class="keyword">in</span> 63 seconds (520.2 MiB/s)</span><br><span class="line">100: 2024-02-17 14:43:10 INFO: archive file size: 10.06GB</span><br></pre></td></tr></table></figure><p>スナップショットもESXi同等にメモリの状態まで確保できます（ZFSファイルシステムで実行）。</p><p>少し気になる点としては無償で利用するには開発用リポジトリを使うことになり、有償のリポジトリはより安全にテストされたものが利用できる仕組みです。GUIでもモジュールは更新できますが、更新の単位は<code>apt update</code>と同様の感覚です。リモートワークなどに利用しているVMがあるのであればその点は留意する必要があります。</p><p>まだ十分な検証ができていませんが、手軽にESXiからの移行を始めるにはProxmoxの環境で検証をスタートさせるのも良いかもしれません。<br>Proxmox自体、セキュアブートでインストールでき、VMもセキュアブートの設定ができます。</p><p>設定はややLinux寄りです。結局はLinuxのコマンドをGUIにうまく形を変えているとも言えます。ESXiで慣れていると少しギャップがあります。ESXiのVMWare Remote Consoleは素晴らしい製品でしたが、そこまでは行かずとも、別ウィンドウでVNCから暗号化通信でコンソールにアクセスするなど操作性はとても良く、先進的であると感じさせます。</p><p>取り急ぎ、ProxmoxVE8.1のセットアップとVMの新規作成に関する記事を投稿しました。Proxmoxを試してみたい方は参考にしてみてください。</p><ul><li><a href="/new-technology/2024/02/17/ProxmoxVE/" title="ProxmoxVEのインストール">ProxmoxVEのインストール</a></li><li><a href="/new-technology/2024/02/19/Proxmox-new-vm/" title="ProxmoxVEのVM新規作成（Ubuntu24.04LTS）">ProxmoxVEのVM新規作成（Ubuntu24.04LTS）</a></li></ul><h2 id="XCP-ng（XEN-Orchestra）"><a href="#XCP-ng（XEN-Orchestra）" class="headerlink" title="XCP-ng（XEN Orchestra）"></a>XCP-ng（XEN Orchestra）</h2><img src="/new-technology/2024/02/14/EOS-Free-esxi2/xcpng.png" class="" width="800" title="alt"><p>新しいプロダクトではありませんが、Citrixが提供しているXen Serverから派生したオープンソースシステムでVatesという会社が提供しています。2012年にフランスで設立されています。おそらく規模は小さい会社のように見えます。こちらは企業中心、またホームラボでも利用されています。<br>仮想化という概念では素晴らしいものをXenから継承しており、本格的なHypervisorです。ProxmoxはHypervisorとも言えますが、VMが明確に独立しておらずDMAなどのメモリへのアクセスはかなり自由です。一方、XCP-NGは厳格にセパレートされておりセキュリティが高く、安定度も高い物と考えられます。その犠牲になるのは速度ですが、XEN Orchestraという有償のGUI管理ツールはわかりやすいため、ESXiユーザーはこちらの方が気にいるかもしれません。</p><blockquote><p>XCP-ng<br> <a href="https://xcp-ng.org/#easy-to-install">https://xcp-ng.org/#easy-to-install</a></p></blockquote><p>Xen OrchestraのGUIツールは有償ですが、個人が使うためのソースコードが提供されており、自身でコンパイルして利用する分には無償です。有償のプロダクトはXOA（Xen Orchestra Apliance）、ソースコードからビルドしたものはXOと呼ばれ区別されています。</p><p>Proxmoxと比べると少しグラフィカルな面は見劣りするでしょうか。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/xo1.png" class="" width="1024" title="alt"><p>ネットワークなどは簡単にVLANを作成できて一覧として確認できるので管理しやすく思えます。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/xo2.png" class="" width="1024" title="alt"><p>これはMellanox Connect X-3の１つのPort（ネイティブVLAN&#x3D;1）にさらに仮想のVLAN110を加えています。</p><p>こちらもバックアップはスケジューリングできます。ESXiのようにバックアップもブロック単位の差分で取得できます。<br>バックアップのメール通知は以下のような形で行われます。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/xo3.png" class="" width="480" title="alt"><p>VMはブラウザから操作することになりますが、メニューの大きさも相まって、少し使いづらいと感じます。クライアントのVNCからXenOrchestraにSSHしてPort Forwardingすることによって暗号化した上で単独のVNCクライアントから操作できるようですが、こちらはまだ未確認です。</p><img src="/new-technology/2024/02/14/EOS-Free-esxi2/xo4.png" class="" width="1024" title="alt"><p>XCP-NG本体は特に難しいところもなくインストールができます。8.2.1はまだセキュアブートのセットアップはできません。VM自体はセキュアブートの設定ができます。また、Xen Orchestraの管理ツール自体は別ノードからアクセスする方が好ましく、最初からノード単位のフェールオーバーなどを考えて作られています。現在私のセットアップではXen OrchestraをESXiで、昔使っていたintelのPCにXCP-NGをセットアップしています。</p><p>XCP-NGの最新バージョンは現在8.2.1ですが、Ryzen環境で動作させると応答速度やネットワーク速度が遅く、Communityの情報を見ながら、古いintel core i7マシン（Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz）に再インストールするなど、少し回り道してしまいました。8.3はまだベータ版ですが、そこではRyzen版の速度改善が見込めるようなのでこちらはまた少し時間を置いてから検証を開始するつもりです。なお、P-Core&#x2F;E-CoreのCPUは仮想環境でどのようにCPUが使われるのか読めないと考えられ、難しさを感じています。</p><p>XCP-NGはスナップショットやバックアップが少し古い時代を感じさせるところがあります。稼働中のVMをバックアップした後にレストアすると、OSをブートするところから始まります。つまり、メモリの内容が廃棄されてしまいます。オープンしていたファイルがどうなるのか、恐らくロールバックされるとは思いますが、検証をしっかりと行いたい箇所ではあります。</p><p>XO自体のリポジトリはGitHubにあり、かなり細かい単位でMasterブランチ（メインのソースコードの配置場所）がCommitされていきます。どこかでそれらの更新部分を取り込むには改めてXOのソースコードのコンパイルから必要になります。但し、これは簡単なスクリプトで手間をかけずに対処可能です。</p><p>私がXCP-NGに期待しているのはシステムの安定度です。ESXiも本当に安定していて、これまでハードウェアの故障以外でハングしたりすることは全くありませんでした。また、Xen Orchestraは、企業で数十台の仮想サーバを管理することを想定して作られており、管理のしやすさを感じます。</p><p>Proxmox、XCP-NGともに良いプロダクトのようで、最終的にはどちらかの仮想環境をメインに使い、2台構成でライブマイグレーション（仮想マシンのノード間の移動）まで実現できればと考えています。</p><p>海外のホームラボのパワーユーザーはどちらかといえば、XCP-NGを好むようにも見えます。これは簡単なProxmoxは面白くないということなのかもしれません。ESXiの代替としてはXCP-NGが今脚光を浴びているように見えます。</p><p>XCP-NG、Xen Orchestraへの理解を深めるには、ローレンスシステムズのTom氏が解説しているYouTubeビデオがわかりやすいと思います。</p><blockquote><p>Understanding How The XCP-NG &amp; Xen Orchestra Open Source Virtualization Platform Works<br> <a href="https://www.youtube.com/watch?v=CEUFHudLO1g&amp;t=447s">https://www.youtube.com/watch?v=CEUFHudLO1g&amp;t=447s</a></p></blockquote><p>今後、Xen Orchestraのセットアップ手順などを整理していきたいと考えています。手持ちの予備マシンをProxmoxで使ってしまったのでマシン調達から始めますのでしばらく時間がかかりそうです。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/02/14/EOS-Free-esxi2/vm1.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;</summary>
    
    
    
    
    <category term="ESXi" scheme="https://yoshi0808.github.io/new-technology/tags/ESXi/"/>
    
  </entry>
  
  <entry>
    <title>VMWare 無償版ESXiの提供終了について</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/01/30/EOS-Free-esxi/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/01/30/EOS-Free-esxi/</id>
    <published>2024-01-30T02:00:00.000Z</published>
    <updated>2024-03-04T11:58:19.235Z</updated>
    
    <content type="html"><![CDATA[<h2 id="VMWare製品の買い切りモデルからサブスクリプションモデルへの移行"><a href="#VMWare製品の買い切りモデルからサブスクリプションモデルへの移行" class="headerlink" title="VMWare製品の買い切りモデルからサブスクリプションモデルへの移行"></a>VMWare製品の買い切りモデルからサブスクリプションモデルへの移行</h2><p>VMWareのKBで以下のタイトルの文書が2024&#x2F;1&#x2F;22に公開されています。</p><blockquote><p>VMware End Of Availability of Perpetual Licensing and SaaS Services (96168)<br> <a href="https://kb.vmware.com/s/article/96168?lang=en_US">https://kb.vmware.com/s/article/96168?lang=en_US</a></p></blockquote><p>最終報については、「<a href="/new-technology/2024/03/04/EOS-Free-esxi3/" title="VMWare 無償版ESXiの提供終了について（最終報）">VMWare 無償版ESXiの提供終了について（最終報）</a>」を参照してください。</p><span id="more"></span><p>VMWareはスタンドアロン製品の提供を終了し、サブスクリプションモデルに変更されるとのこと。無償版ESXiは対象外ではという期待もありましたが、上記のKBを補足する形のブログとして以下が公開されています。</p><blockquote><p>VMware End Of Availability of Perpetual Licensing and SaaS Services (VMWare Blog)<br> <a href="https://blogs.vmware.com/cloud-foundation/2024/01/22/vmware-end-of-availability-of-perpetual-licensing-and-saas-services/">https://blogs.vmware.com/cloud-foundation/2024/01/22/vmware-end-of-availability-of-perpetual-licensing-and-saas-services/</a></p></blockquote><p>このページではサブスクリプションへの移行可否を判断可能なプロダクト一覧があります。残念ながら、表の中の移行対象外プロダクトとして、「VMware vSphere Hypervisor (free edition)」の記載があります。</p><p>そもそもの発表は2023年12月11日の発表に遡ります。</p><blockquote><p>VMware by Broadcom、製品ラインアップとライセンス モデルを大幅に簡素化<br> <a href="https://news.vmware.com/company/vmware-by-broadcom-business-transformation">https://news.vmware.com/company/vmware-by-broadcom-business-transformation</a></p></blockquote><p> 正式にサブスクリプションモデルに移行する事が発表された後の製品の明確化という事ですが、ソフトウェアのダウンロード自体はいつ出来なくなっても不思議ではない状態となっています。一方、昨年末の発表でも改めて触れられていますが、すぐにサポート終了というわけではなく、あらかじめ定められたサポート期限（ジェネラルサポート期限）まではパッチなども提供されるとのことです。</p><h2 id="無償版ESXiのサポート期限"><a href="#無償版ESXiのサポート期限" class="headerlink" title="無償版ESXiのサポート期限"></a>無償版ESXiのサポート期限</h2><p>無償版ESXiに関するサポート期限は以下の通りです。</p><img src="/new-technology/2024/01/30/EOS-Free-esxi/lifecycle.png" class="" width="1024" title="alt"><blockquote><p>Product Lifecycle Matrix<br> <a href="https://lifecycle.vmware.com/#/?advancedFilter=checkbox_sup&amp;filters=%7B%22name%22:%22esxi%22,%22lifecycle_policy%22:null,%22text%22:null%7D">https://lifecycle.vmware.com/#/?advancedFilter=checkbox_sup&amp;filters=%7B%22name%22:%22esxi%22,%22lifecycle_policy%22:null,%22text%22:null%7D</a></p></blockquote><p>まず見るべきはパッチ提供が行われるGeneral Supportの期限です。ESXi7は2025&#x2F;4&#x2F;2であり、あと1年と少しです。また、ESXi8については、2027&#x2F;10&#x2F;11と3年半の猶予があります。</p><p>もちろん、今後それなりの費用を支払ってESXiを使う事も選択肢としては挙げられますが、ホームユーザーにとっては高額となるライセンス費用を払ってまでESXiに拘る方は少ないものと考えられます。</p><h2 id="現時点で考えられるアクションプラン"><a href="#現時点で考えられるアクションプラン" class="headerlink" title="現時点で考えられるアクションプラン"></a>現時点で考えられるアクションプラン</h2><p>このような状況からは以下のように考えられるでしょうか。</p><ul><li><p>新規にESXiをインストールしてみたいと考えているユーザー向け<br> 残念ながら、無償での利用終了が覆る事は無いと考えられるため新規にホームユーザーがESXiを覚えようとする事は仕事で利用する等の理由がない限りお勧めできません。</p></li><li><p>既にFree ESXiを運用しているユーザー向け</p><ol><li>代替ソフトウェアを速やかに探し、移行する</li><li>ESXi8のライフサイクルが長いプロダクトにアップグレードの上、当面は情報収集し、ESXiの運用を継続する</li></ol></li></ul><p>なお、既にESXiを運用されている方であっても、何らかのトラブルでクリーンインストールが必要となる可能性は残ります。<br>このため、以下のアクションは速やかに行っておくべきです。またアップグレードでもISOファイルは利用できます。</p><ol><li>無償版ESXi8のモジュール（ISOファイル）をダウンロードしておくこと</li><li>無償版ESXi8のライセンスを取得しておくこと</li></ol><p>詳細は、「<a href="/new-technology/2023/06/18/esxi-upgrade8/" title="VMware ESXiを8.0にアップグレードする">VMware ESXiを8.0にアップグレードする</a>」、「<a href="/new-technology/2023/07/07/building-setup-esxi8/" title="ESXi8.0をRyzen5 5600Gで構築">ESXi8.0をRyzen5 5600Gで構築</a>」の記事を参照してください。</p><h2 id="今後のアクションプラン"><a href="#今後のアクションプラン" class="headerlink" title="今後のアクションプラン"></a>今後のアクションプラン</h2><p>これは各個人によって仮想環境の利用方法や考え方やが異なりますので、コメントは難しいところですがポイントになる点を列挙してみます。</p><ul><li><p>仮想環境のバックアップを主眼にする場合<br>　私の場合はNASのソフトウェアでVMの定期バックアップを取得しており、仮想環境の一番のメリットと感じています。<br>　NASによる仮想環境のバックアップはESXiおよびHyper-V Serverが対象です。<br>　Hyper-V Server 2019も移行対象にはなりますが、既にメインストリームの終了を2024年1月に迎えており、短命と考えられます。</p><blockquote><p>Microsoft Lifecycle<br> <a href="https://learn.microsoft.com/ja-jp/lifecycle/products/hyperv-server-2019">https://learn.microsoft.com/ja-jp/lifecycle/products/hyperv-server-2019</a></p></blockquote><ul><li>今後NASのソフトウェアや他のバックアップソリューションが別の仮想環境システムに対応してくればそれが選択の候補になり得ます。</li><li>Windows Serverのライセンス購入も選択肢となりますが、やはり個人向けには高価で集約するコストメリットが無くなってしまいます。</li><li>Linuxの全体バックアップをNASで確保しつつ、LinuxのKVMで個別の仮想マシンを管理するという方法も考えられます。</li></ul></li><li><p>その他の仮想環境への移行を主眼にする場合<br> 仮想化ソフトウェアの信頼性を見極める必要があります。<br> リモートワークの一部に利用している製品であれば、信頼性（安全性、可用性）が必要ですから、仮想化ソフトウェアが期待に満たない場合はベアメタルに移行する事も必要でしょう。</p></li><li><p>コンテナへの移行など別の技術を活用する場合<br> バージョンアップなどの移行が容易であればよりリソースが少なく済む可能性はあります。最新パッチの当たったイメージが開発ベンダーから提供されるならそれ以上言うことありません。セキュリティ製品などOS単位でのソフトウェアや、VLANや仮想ネットワークなど、ネットワークが主眼である場合は、他のソリューションも視野に入れることとなります。</p></li></ul><h2 id="補足"><a href="#補足" class="headerlink" title="補足"></a>補足</h2><p>VMWareのコミュニティの中心的存在であるVMWareのWilliam氏（lamw）は、定期的なブログのポスト、Community(Flings)でのCommunity Driverなどの再整理など今年に入ってからも意欲的に活動されています。</p><blockquote><p>Wiliam Lam氏のブログ<br> <a href="https://williamlam.com/">https://williamlam.com/</a></p></blockquote><blockquote><p>VMWare Community(Flings)<br> <a href="https://communities.vmware.com/t5/Flings/ct-p/77">https://communities.vmware.com/t5/Flings/ct-p/77</a></p></blockquote><p>私個人としては当面情報収集をし、急いで他のシステムに移行する事は考えていませんが、継続して代替策は検討していきたいと考えています。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;VMWare製品の買い切りモデルからサブスクリプションモデルへの移行&quot;&gt;&lt;a href=&quot;#VMWare製品の買い切りモデルからサブスクリプションモデルへの移行&quot; class=&quot;headerlink&quot; title=&quot;VMWare製品の買い切りモデルからサブスクリプションモデルへの移行&quot;&gt;&lt;/a&gt;VMWare製品の買い切りモデルからサブスクリプションモデルへの移行&lt;/h2&gt;&lt;p&gt;VMWareのKBで以下のタイトルの文書が2024&amp;#x2F;1&amp;#x2F;22に公開されています。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;VMware End Of Availability of Perpetual Licensing and SaaS Services (96168)&lt;br&gt; &lt;a href=&quot;https://kb.vmware.com/s/article/96168?lang=en_US&quot;&gt;https://kb.vmware.com/s/article/96168?lang=en_US&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最終報については、「&lt;a href=&quot;/new-technology/2024/03/04/EOS-Free-esxi3/&quot; title=&quot;VMWare 無償版ESXiの提供終了について（最終報）&quot;&gt;VMWare 無償版ESXiの提供終了について（最終報）&lt;/a&gt;」を参照してください。&lt;/p&gt;</summary>
    
    
    
    
    <category term="ESXi" scheme="https://yoshi0808.github.io/new-technology/tags/ESXi/"/>
    
  </entry>
  
  <entry>
    <title>ZikeDrive Z666 USB4エンクロージャー</title>
    <link href="https://yoshi0808.github.io/new-technology/2024/01/13/ZikeDrive-Z666/"/>
    <id>https://yoshi0808.github.io/new-technology/2024/01/13/ZikeDrive-Z666/</id>
    <published>2024-01-12T15:56:03.000Z</published>
    <updated>2024-02-10T01:05:36.883Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2024/01/13/ZikeDrive-Z666/title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p><p>USB4 40Gbpsに対応したNVMe　M.2対応のSSDエンクロージャーを紹介します。いわゆる外付けディスクです。ノートPCの外付けとして直近のNVMe M.2 SSDの状況を鑑みつつ、USB4&#x2F;Thunderbolt4&#x2F;Thunderbolt3などプロトコルの違い、実運用における速度を見ていきます。</p><span id="more"></span><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>2023年はSSDがとても廉価だった年でした。非常に高性能なNANDフラッシュメモリが台頭してきた事もあり、外付けSSDとしての利用価値が高まってきています。USB-Cのコネクタ形状はiPhone15での対応もあり、最近デファクトになりつつある規格ですが、一方で新しいPCやMacではUSB4&#x2F;Thunderbolt4への対応が進んでいます。OS本体のストレージとは別に目的やジャンル別のデータ保存に外付けディスクを”切り替える”使い方もあろうかと思います。特にノートPCのディスク容量は大きくないですし、あまり使わないデータは外付けディスクで管理したいところです。</p><p>これまでUSB-CのSSDエンクロージャーといえば、USB3.2 Gen2の10Gbpsで接続可能なもの、一般的にはRealtekのRTL9210チップを搭載した安価なものが多くを占めます。今回のZIKE Z666は40Gbps対応となり、今のNVMeの能力を活かすことが期待できます。</p><h2 id="ZIKE-Z666"><a href="#ZIKE-Z666" class="headerlink" title="ZIKE Z666"></a>ZIKE Z666</h2><p>ZIKEはアメリカ発のベンチャー企業で、2021年に起業したアメリカのデラウェア州にある企業です。</p><ul><li>ZIKE<br> <a href="https://ziketech.com/">https://ziketech.com</a></li></ul><p>商品説明のページでは、Z666は3,811MB&#x2F;sの読み取り速度と3,199 MB&#x2F;sの書き込み速度があるとの事。1USB3.2Gen2のSSD外付けドライブの3倍速です。ASMediaのAS2464PDチップを備え、USB4ケーブルが付属、NVMeの取り付けに工具不要。ケースそのものはアルミで作られ、その周りを透明なABS樹脂で覆ったものとなっています。サイズは112×66.8×18(mm)、重さ245gとなっており従来のエンクロージャと比べれば大きめです。外への持ち出しを考えられて作られてます。50度を超え70度にもなるNVMeを直接アルミで放熱することは機械にとっては良くても、人にとっては優しくないわけですが、一般消費者向けに（きちんと）作られた製品です。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/zike-1.png" class="" width="1024" title="alt"><p>ストレージの制限があるノート、特にMacbookのユーザーから人気があります。エンクロージャに取り付け可能な短いケーブルが付属します。Z666はあくまでエンクロージャーですので、中身のNVMeは別途購入する必要があります。<br>スペックの概略は以下の通りです。</p><table><thead><tr><th>各スペック</th><th>説明</th></tr></thead><tbody><tr><td>インタフェース</td><td>USB4 40Gbps Thunderbolt3&#x2F;4互換、USB3.2Gen2 10Gbps、USB3.2Gen1 5Gbps、USB2.0 480Mbps</td></tr><tr><td>SSD形状</td><td>M.2 M-Key PCIe Gen 4x4&#x2F;2280</td></tr><tr><td>容量</td><td>1、2、4、16TBまたはそれ以上</td></tr><tr><td>互換性</td><td>Windows,MacOS,Linux,iPad,PlayStation</td></tr></tbody></table><p>AS2464PDチップとNVMeとの間がPCIe Gen4x4というのが魅力です。<br>ファームウェアのアップデートもウェブサイトで公開されており、質問やユーザーレポートの投稿も可能です。</p><p>詳細は、Zikeのウェブサイトで確認してください。</p><ul><li>Z666<br> <a href="https://ziketech.com/products/zikedrive-worlds-first-and-fastest-usb4-ssd-drive?variant=42809341608097">https://ziketech.com/products/zikedrive-worlds-first-and-fastest-usb4-ssd-drive?variant=42809341608097</a></li></ul><h2 id="ベンチマーク"><a href="#ベンチマーク" class="headerlink" title="ベンチマーク"></a>ベンチマーク</h2><p>ここで利用するSSDについて紹介します。速度だけでいえば、WD_Black SN850X NVMeやSamsungの990Proがメジャーです。しかし、ケーブル接続する外付けディスクの利用目的としてはそこまで速度を求めるものでもないでしょうから、それに準ずる比較的廉価な製品を選定して確認していきます。Gen4x4の速度が必要であればマザーボードに直接NVMeをセットされる事をお勧めします。</p><p>まずは、SK hynix Platinum P41 NVMe 2TBで確認します。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/p41.png" class="" width="480" title="alt"><p>Platinum P41は990Pro、SN850Xと比較し価格は少し廉価ですが、2TBのモデルで速度はRead 7,000MB&#x2F;s、Write 6,500MB&#x2F;sであり、990ProのRead 7,450MB&#x2F;s、Write Write 6,900MB&#x2F;sの速度に迫り実力としては十分です。このモデルはDRAMを持っているので、ベンチマークには有利です。</p><h3 id="Windows-CrystalDiskmark"><a href="#Windows-CrystalDiskmark" class="headerlink" title="Windows CrystalDiskmark"></a>Windows CrystalDiskmark</h3><img src="/new-technology/2024/01/13/ZikeDrive-Z666/CrystalDiskMark.png" class="" width="480" title="alt"><p>ハードウェアはMinisForum UM790 Pro(Windows11 Home)で、USB4ポートで確認しました。フォーマットはexFATです。スペック通りの速度です（書き込みはスペック以上の速度です）。</p><p>デバイスマネージャーから取り外しポリシーを高パフォーマンスに変更するとランダム書き込みの値が改善します。これは普段から接続しっぱなしの方にお勧めの設定です。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/policy.png" class="" width="480" title="alt"><img src="/new-technology/2024/01/13/ZikeDrive-Z666/HighPerformance.png" class="" width="480" title="alt"><h3 id="macOSのベンチマーク"><a href="#macOSのベンチマーク" class="headerlink" title="macOSのベンチマーク"></a>macOSのベンチマーク</h3><img src="/new-technology/2024/01/13/ZikeDrive-Z666/AmorphousDiskMark.png" class="" width="480" title="alt"><p>Macbook Pro(M2)のThunderbolt4ポートで確認しました。フォーマットはAPFSです。Windowsよりは速度は落ちますが、アプリケーションが違うものなので単純比較は難しいところです。macOSでは他にBlackmagicというDiskパフォーマンスベンチマークソフトがあります。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/Blackmagic.png" class="" width="480" title="alt"><p>前回の記事「<a href="/new-technology/2023/12/16/MiniSSDCase/" title="iPhoneに繋がるミニSSDケース">iPhoneに繋がるミニSSDケース</a>」で書いた小型のRTL9210エンクロージャではRead&#x2F;Writeともに980MB&#x2F;s程度でしたから格段に速度が向上しています。<br>もちろん、USB4に対応していないUSB3.x Gen2のホストにZ666を接続した場合は10Gbpsと速度は落ちますが、アクセス可能です。</p><p>USB3.2 Gen2のエンクロージャーをご利用されている方は、読み込み書き込み共にCrystalDiskMarkのシーケンシャルで1,000MB&#x2F;s前後の数字を目にされているのでは無いでしょうか。これは8Gbps前後になりますので、USBを経由する実効速度は理論値よりは2割ほど落ちます。</p><p>今回は最も遅い箇所が40Gbpsのケーブルですから5GB&#x2F;sが理論値となり、それの8割とすれば4GB&#x2F;sです。Windowsの結果を見れば大体このような数字なのかなと感じます。</p><h2 id="Z666のケース構造"><a href="#Z666のケース構造" class="headerlink" title="Z666のケース構造"></a>Z666のケース構造</h2><p>Z666のフタはプラでパチンと嵌め込む形になっているので、手で押し開けます。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/zike-2.png" class="" width="1024" title="alt"><p>上蓋には3mm厚程度のサーマルパッドがあります。本体内部下部にはNVMeを支える2つの長方形のクッションが糊付けされています。<br>NVMeはラバープラグを回転させて固定させる方式です。お世辞にもしっかりと固定されるとはいえませんが蓋を閉めるので大丈夫ということでしょうか。頻繁にNVMeの入れ替えを行う場合を想定して便利に作られています。<br>内部のクッションは剥がせそうではありますが、基本的に片面実装（チップが片方のみあるもの）のNVMeを想定しているようです。<br>また上蓋にサーマルパッドがあることから、ヒートシンク付きのNVMeは使えません。物理的には接続可能ですが、その場合は蓋が閉まりません。</p><p>ケースはABS樹脂とアルミの隙間があるため、ここから熱を逃すようです。ケースの外側はほんのり暖かい程度で熱さは感じません。</p><h2 id="Z666の購入"><a href="#Z666の購入" class="headerlink" title="Z666の購入"></a>Z666の購入</h2><p>ZIKEのWebサイトから海外通販で購入することになります。shopPayがあるので、Ubiquitiなどの他の通販で利用されている場合は再度住所の登録が不要です。日本からは送料無料で1月初旬で18,000円弱です（為替で変動するようです）。</p><p>レビューを見ていると結構楽しいです。皆さんCrystalDiskMarkの画面ショットを貼り付けていらして、このような光景は世界共通ですね。<br>速いのでLaptopでSQL Serverに使えるというコメントがあったり、M2 Ultra Mac Studioに990Proを付けて3200&#x2F;3100のBlackMagicベンチマーク結果で「こんなものなのかな」というコメントなど、平和ですね。</p><h2 id="SSDの進化"><a href="#SSDの進化" class="headerlink" title="SSDの進化"></a>SSDの進化</h2><p>NVMeに限らず、SSDにはDRAMキャッシュがあるもの、ないものと2種類の製品が存在します。</p><p>以下は、Platinum P41　2TBを横から撮影したものです。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/NVMe.png" class="" width="1024" title="alt"><p>右側のM.2コネクタから順に、コントローラー、DRAM、NANDフラッシュ2枚が並んでいます。M.2コネクタから近い順に速いチップを配置していくのが基本です。<br>各社凌ぎを削っている部分ですが、このような配置だとNANDフラッシュは1TBづつ配置されている事になります。<br>コントローラー、DRAMキャッシュ、NANDフラッシュと片面実装にするためにギリギリで詰め込まれているのがわかります。<br>176層というNANDフラッシュ1つに1TB、それを2個搭載する事で2TBという容量を実現しています。</p><p>ただ、このデザインから見えるように、すでに基盤上はチップで埋まっているので、これ以上NANDフラッシュメモリを追加できません。さらに片面のまま4TBの容量とするには微細化が求められることになります。Platinum P41の製品バリエーションとして最大容量は2TBとなっています。<br>WD SN850Xの4TBはいくつかの第三者レビューを見る限りではNANDフラッシュが裏面に2枚あるそうで両面実装となっています。</p><p>Samsungの990Proの4TBは片面実装になっています。王者の貫禄というか、意地でしょうか。凄まじさを感じさせます。</p><blockquote class="blockquote-center"><p>4TB NVMe Laptop Upgrade<br>It’s the one and only on the market—the 990 PRO 4TB is now compatible with laptops. Thanks to Samsung’s NAND Stacking technology, 990 PRO is the first 4TB m.2 NVMe Internal SSD with a single-sided form—meaning it fits easily in the most popular laptops for an instant upgrade in high-performing storage.</p><p>4TB NVMeラップトップ・アップグレード<br>990 PRO 4TBがラップトップに唯一無二の存在となりました。サムスンのNANDスタッキング・テクノロジーのおかげで、990 PROは、片面実装の初の4TB  M.2 NVMe内蔵SSDとなりました。<br>つまり、高性能ストレージを即座にアップグレードするために、最も人気のあるラップトップに簡単に収まることを意味します。</p></blockquote><ul><li>Samsung<br> <a href="https://www.samsung.com/us/computing/memory-storage/solid-state-drives/990-pro-pcie-4-0-nvme-ssd-4tb-mz-v9p4t0b-am/">https://www.samsung.com/us/computing/memory-storage/solid-state-drives/990-pro-pcie-4-0-nvme-ssd-4tb-mz-v9p4t0b-am/</a></li></ul><h2 id="SSDの選択"><a href="#SSDの選択" class="headerlink" title="SSDの選択"></a>SSDの選択</h2><p>先ほど紹介したZIKEの掲示板では高額なホストに高額なNVMe(990Pro)を付けたからといって大したパフォーマンスの向上は見込めないように見えます。</p><p>ケーブルやUSBを経由するオーバーヘッドがある場合には、SSD側のDRAMキャッシュがある程度有効になります。NANDフラッシュへの遅い書き込みをカバーするために、できるだけ応答を早く返すことで遅いケーブル上での待ちを少なくすることが重要です。</p><p>速度以外にも、容量の確保、発熱を抑えることも、コストを抑えることも大事です。</p><p>ZIKEの掲示板でもLexarのNM790というNVMeが紹介されていました。Lexarは昔からカメラを趣味にしている人であればよく知られているブランドで世界的にも有名です。</p><p>このNM790はYMTCの232層NANDフラッシュとMaxioのMAP1602Aコントローラーを使ったNVMeです。他社でもこの組み合わせのNVMeは大量に出回っています。</p><p>このモデルは、DRAMレスとなっており、SK hynixのものよりは1回り小さいNANDチップが4枚片面に乗せられています。コントローラーも1回りサイズが小さくなっており、うまく片面に乗せられたという感じです。このコントローラーは4多重で動作でき、負荷分散ができます。RAIDシステムで分散して処理速度を稼ぐのと同じ考え方ですね。ローテクな感じですが、負荷分散によりボトルネックが小さく、DRAMキャッシュの複雑な機構も不要ですので、廉価で低発熱が期待できます。</p><h3 id="各SSDをZ666で速度テスト"><a href="#各SSDをZ666で速度テスト" class="headerlink" title="各SSDをZ666で速度テスト"></a>各SSDをZ666で速度テスト</h3><p>手元には以下のNVMeを用意し、Macbookで速度検証してみます。</p><ul><li>Samsung 970EVO Plus 1TB</li><li>SK hynix Platinum P41 2TB</li><li>Lexar NM790 2TB</li></ul><p>テスト結果は以下のとおりです。</p><table><thead><tr><th>テスト項目</th><th>Samsung</th><th>SK hynix</th><th>Lexar</th></tr></thead><tbody><tr><td></td><td>970EVO Plus</td><td>Platinum P41</td><td>NM790</td></tr><tr><td>SEQ1M Q8　Read</td><td>3368</td><td>3386</td><td>3379</td></tr><tr><td>SEQ1M Q1　Read</td><td>2901</td><td>3120</td><td>3028</td></tr><tr><td>RND4K QD64　Read</td><td>890</td><td>916</td><td>905</td></tr><tr><td>RND4k QD1　Read</td><td>62</td><td>65</td><td>68</td></tr><tr><td>SEQ1M Q8　Write</td><td>1312</td><td>3178</td><td>2679</td></tr><tr><td>SEQ1M Q1　Write</td><td>1176</td><td>2677</td><td>2887</td></tr><tr><td>RND4K QD64　Write</td><td>262</td><td>305</td><td>221</td></tr><tr><td>RND4k QD1　Write</td><td>46</td><td>44</td><td>31</td></tr><tr><td>コントローラー温度</td><td>65</td><td>61</td><td>47</td></tr><tr><td>DRAM温度</td><td>84</td><td>72</td><td>-</td></tr><tr><td>NAND温度</td><td>72</td><td>60</td><td>50</td></tr></tbody></table><p>※パフォーマンスのテスト数値はMB&#x2F;s、温度は摂氏となります。DiskMarkを2回実行し、赤外線で計測するタイプの温度計でチップ表面を計測し、一番温度の高い数値を採用しています。</p><ul><li>970EVO Plus（PCIe3x4）のSEQ Readはカタログスペック3,500MBなので読み込みのボトルネックは発生していない。</li><li>970EVO Plus（PCIe3x4）のSEQ Writeはカタログスペック3,300MBなのでこの環境では半分以下に落ち込んでいる。逆に言えば、ホスト、ADMediaチップ、NVMeのコントローラーがPCIe4x4で揃っていればボトルネックが生まれにくい。</li><li>PCIe4x4対応のPlatinum P41とNM790のシーケンシャル処理はReadにせよWriteにせよ3,300MBあたりが壁になっている。Macbook本体やASMediaチップがPCIe4x4（理論値64Gbps）であってもケーブルが最大40Gbpsの制約、プロトコル変換のオーバーヘッドに加え、Macbook&#x2F;macOSが持つ何らかの要因によるオーバーヘッドがあると考えられる（Windwos11と比較しても遅く見える）。</li><li>DRAMキャッシュがないNM790は大量のランダムな書き込みには特に弱い。PCIe3x4の970EVO Plusを下回る。</li><li>970EVO Plusは速度が頭打ちになっているにも関わらず発熱量はかなり大きい。</li><li>NM970はかなり温度が低い。DRAMを使わない分処理が単純なのとNANDチップが高性能というのも一理あるかもしれない。</li></ul><p>廉価にPCIe4x4のNVMeを使える機会があるのであれば無理にPCIe3x4の970EVO Plusを使う意味は無さそうです。<br>なお、容量が4TBとなると、この3つのうちではNM790が候補になります。</p><p>あくまでベンチマークだけの話なので参考に留めていただけると幸いです。WindowsのCrystalDiskMarkはスレッド数（多重度）も指定できましたが、macOS版では特に指定がありません。1スレッドという事なのかもしれません。</p><h4 id="大きなサイズのファイルコピー"><a href="#大きなサイズのファイルコピー" class="headerlink" title="大きなサイズのファイルコピー"></a>大きなサイズのファイルコピー</h4><p>ESXiの仮想マシンvmdkファイル42.95GByteを対象とし、macOSからZ666へ書き込みます。</p><table><thead><tr><th>テスト項目</th><th>970EVO Plus</th><th>Platinum P41</th><th>NM790</th></tr></thead><tbody><tr><td>42.95GBファイルをMac→Z666へコピー</td><td>31秒</td><td>13秒</td><td>16秒</td></tr></tbody></table><p>この結果を見る限りではやはりPCIe4x4のチームが有利ですね。外付けDiskで40GByteのファイルが10秒台というのは魅力的です。Platinum P41でベンチマークのシーケンシャルWrite処理を超える3.3GB&#x2F;sという数値が出ています。素晴らしい結果ですが、やっぱりMacBook Pro（M2）では何かしらの3.3GBの壁があるように見えます。</p><h4 id="小さなサイズの多くの数のファイルコピー"><a href="#小さなサイズの多くの数のファイルコピー" class="headerlink" title="小さなサイズの多くの数のファイルコピー"></a>小さなサイズの多くの数のファイルコピー</h4><p>このブログで使っているモジュール群のNode Moduleやgitは細かいファイルをたくさん生成します。<br>2.07GBのフォルダに、54,301ファイルが存在しています。</p><table><thead><tr><th>テスト項目</th><th>970EVO Plus</th><th>Platinum P41</th><th>NM790</th></tr></thead><tbody><tr><td>54,301個のファイルをMac→Z666へコピー</td><td>23秒</td><td>23秒</td><td>23秒</td></tr></tbody></table><table><thead><tr><th>テスト項目</th><th>970EVO Plus</th><th>Platinum P41</th><th>NM790</th></tr></thead><tbody><tr><td>54,301個のファイルをZ666→Macへコピー</td><td>21秒</td><td>21秒</td><td>22秒</td></tr></tbody></table><p>OS処理のオーバーヘッドが大きいようで各NVMeでほぼ同じ時間となりました。ランダムに弱いという点はベンチマークではありましたが、バックアップ目的での小さなファイルコピーを中心に利用するならばあまりメディアの違いは関係なさそうです。速度はおおよそ90MB&#x2F;sです。</p><p>RTL9210の10Gbps対応のエンクロージャにNM790をセットして書き込んでみます。<br>結果は26秒でした。OSが細かいファイルを処理する事はやはりオーバーヘッドが大きいため、90MB&#x2F;s程度の速度であれば高速デバイスのメリットは活かしきれず、USB3.2 Gen2とUSB4との違いはありません。</p><p>今回のケースでは敢えて極端な例を示していますが、一般的によく利用される写真、動画、文書などのファイルであれば効率的にZ666のパフォーマンスを活かせます。</p><h2 id="USB-Thunderboltと対応PC"><a href="#USB-Thunderboltと対応PC" class="headerlink" title="USB&#x2F;Thunderboltと対応PC"></a>USB&#x2F;Thunderboltと対応PC</h2><p>USBについてのおさらいです。</p><table><thead><tr><th>USB規格名</th><th>データ転送速度</th><th>旧名称</th><th>マーケティング名</th></tr></thead><tbody><tr><td>USB3.2 Gen1</td><td>5Gbps</td><td>USB3.1 Gen1、USB3.0</td><td>USB　5Gbps、旧（SuperSpeedUSB、SSマーク）</td></tr><tr><td>USB3.2 Gen2</td><td>10Gbps</td><td>USB3.1 Gen2</td><td>USB　10Gbps、旧（同上）</td></tr><tr><td>USB3.2 Gen2x2、USB4 Gen2x2</td><td>20Gbps</td><td></td><td>USB  20Gbps、旧（SuperSpeed USB 20Gbps、USB4  20Gbps）</td></tr><tr><td>USB4 Gen3x2</td><td>40Gbps</td><td></td><td>USB 40Gbps、旧（USB4 40Gbps）</td></tr><tr><td>USB4 Ver2.0</td><td>80Gbps</td><td></td><td></td></tr></tbody></table><p>まずZ666を利用するにあたり、最低限度の必要な確認です。お使いのPCでUSB4(Thunderbolt4&#x2F;Thunderbolt3)に対応していなければZ666のメリットは活かしきれません。私はUSB3.2Gen2x2のホストを保有していないので確認できませんが、ASMediaのASM2464PDの紹介ページではUSB3.2、USB2.0の後方互換があると記載されています。USB-Cがあってもお使いのPCがUSB3.2 Gen2止まりであれば従来のRealtekのRTL9210のエンクロージャーで十分です。</p><ul><li>ASMedia ASM2464PD<br> <a href="https://www.asmedia.com.tw/product/802zX91Yw3tsFgm4/C64ZX59yu4sY1GW5">https://www.asmedia.com.tw/product/802zX91Yw3tsFgm4/C64ZX59yu4sY1GW5</a></li></ul><p>USB4はThunderbolt3をベースに作られています。同じUSB-Cの形状でもUSBポート、Thunderbolt3&#x2F;4ポートの違いがあり、それぞれのプロトコルの違いがあるので一層理解が難しくなっているのが現状です。</p><p>Thunderbolt3は40Gbps対応とはいえ、Requirement（要求事項）は最低16GbpsのPCIeデータのサポートが求められています。Altモードでデータ、ディスプレイへの出力の合計で40Gbpsです。</p><table><thead><tr><th></th><th>Thundrerbolt4</th><th>Thunderbolt3</th></tr></thead><tbody><tr><td>総帯域幅</td><td>40Gbps</td><td>40Gbps</td></tr><tr><td>データ転送の最小帯域幅</td><td>32Gbps</td><td>16Gbps</td></tr><tr><td>ディスプレイ</td><td>4K  モニター最大 2 台、または 8K モニター 1 台</td><td>4K モニター 1 台</td></tr></tbody></table><p>2018年以降のmacbookをお使いの方はThunderbolt3対応になっていると思います。Windows(intel)のノートPCではThunderbolt3に対応した機種もあります。新しいWindowsノートPCはUSB4に対応したモデルも出てきていますね。外付けディスクだけを考えた場合、Thunderbolt3対応というのはデータ転送において最低16Gbpsを満たす事ですから、外付けディスクで16Gbpsの速度しか出なくても文句は言えません。但し、Requirementと実装とは異なることも多いので個別のホストを確認しないと分かりません。</p><p>macのポートの対応については以下を確認してください。</p><ul><li>Apple Macのポートを調べる<br> <a href="https://support.apple.com/ja-jp/HT201736">https://support.apple.com/ja-jp/HT201736</a></li></ul><p> M1 MacなどはThunderbolt&#x2F;USB4と記載があります。本当はThunderbolt4と書きたいところだったんでしょうけれども何か規格に満たないものがあり、こういった表現に留めているのだと思われます。</p><p>Z666はUSB4に対応したモデルであり、Thunderboltプロトコルとは互換性があります。<br>MacBook ProでZ666とを接続し、システム情報を参照するとThunderbolt4ではなくUSB4モードで接続されています。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">製造元名:Gopod Group Limited.</span><br><span class="line">装置名:USB4 NVMe SSD Pro Enclosure</span><br><span class="line">モード:USB4</span><br><span class="line">装置ID:0xD666</span><br><span class="line">製造元ID:0x2D01</span><br><span class="line">デバイスのリビジョン:0x5A</span><br><span class="line">ファームウェアのバージョン:1.87</span><br><span class="line">状況:装置は接続済み</span><br><span class="line">リンクの状況:0x2</span><br><span class="line">速度:最高40Gb/秒×1</span><br><span class="line">現在のリンク幅:0x2</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>一方、2019年のintel版Macbook AirはUSB4には対応していませんが、Thunderbolt3には対応しています。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">製造元名:Gopod Group Limited.</span><br><span class="line">装置名:USB4 NVMe SSD Pro Enclosure</span><br><span class="line">モード:Thunderbolt 3</span><br><span class="line">装置ID:0xD666</span><br><span class="line">製造元ID:0x1CA</span><br><span class="line">デバイスのリビジョン:0xE3</span><br><span class="line">ファームウェアのバージョン:1.87</span><br><span class="line">状況:装置は接続済み</span><br><span class="line">リンクの状況:0x2</span><br><span class="line">速度:最高40Gb/秒×1</span><br><span class="line">現在のリンク幅:0x2</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>intel版Macbook AirをDiskMarkで確認してみます。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/MBAir.png" class="" width="480" title="alt"><p>もしかしたら遅くなるのかなと考えていましたが、Requirement（16Gbps）以上の良いパフォーマンスを発揮しました。少なくとも32Gbpsは対応してそうです。</p><h3 id="ケーブルについて"><a href="#ケーブルについて" class="headerlink" title="ケーブルについて"></a>ケーブルについて</h3><p>80cmのThunderbolt3ケーブルはUSB4で問題なく使えます。1mを超えるThunderbolt3のパッシブケーブルは20Gbpsですので、十分なパフォーマンスが出ない場合があります。距離が必要であれば少し高額ですが、2mのThunderbolt4アクティブケーブルを用意することになります。私はPlugableのThunderboltケーブルを好んで使っています（Amazonで購入できます）。iPhoneの充電には白色のAmazon Basicのケーブル（通信速度480Mbps）、データ通信用はPD充電（100W）を兼ねて黒色のThunderboltケーブルと使い分けています。</p><p>Z666を使う分には別途ケーブルを購入する必要はありませんが、微妙な接触不良などが思わぬトラブルの原因になるため、事前の確認をお勧めします。Z666に限らず、エンクロージャーを動かしたら切断警告が出たという経験をお持ちの方も多いのではないでしょうか。Z666に付属のケーブルも短すぎてエンクロージャを動かした時に端子に負担を掛けます。しなやかなで、ある程度の長さがあり、端子に負担を掛けないケーブルを利用されることをお勧めします。</p><h2 id="SSDの暗号化"><a href="#SSDの暗号化" class="headerlink" title="SSDの暗号化"></a>SSDの暗号化</h2><p>メディアの持ち出しなどのためにWindowsであれば<strong>Bitlocker To Go</strong>、macOSであれば<strong>APFS（暗号化）</strong>でのフォーマットをお勧めします。</p><p>Bitlocker To GoはWindows Homeでは使えない機能ですが、一度Proで作成してしまえば、Windows Homeでもファイルの読み込み・書き込みが可能です（将来的にはHomeでは使えなくなる可能性があります）。パフォーマンスについてはDiskMarkを見ている限りではランダムは少し速度が落ちますが、シーケンシャルはMac OS、Windowsともに暗号化しない時と殆ど変わりません。</p><p>macOS、Windowsとともに、次回からパスワードを省略できます（macOSはキーチェーンに保存）ので自宅PCでの利用においてはパスワードを意識する事なく便利です。</p><h2 id="Windowsにおける実運用"><a href="#Windowsにおける実運用" class="headerlink" title="Windowsにおける実運用"></a>Windowsにおける実運用</h2><p>Z666にBitLocker ToGoで暗号化された2TBのLexar NM790をセットして書き込みのテストを実施してみます。<br>エクスプローラーでコピーし、対象は写真・動画で、209GBのフォルダサイズです。</p><p>まずはDiskの取り外しポリシーをクイック取り外し（既定：キャッシュ無し）の通常のコピーをパフォーマンスモニターで記録しました。<br>項目はDisk Write Bytes&#x2F;secおよびCurrent Disk Queue Lengthです。Disk Queue Lengthは一般的に2を超える数値だとディスクにボトルネックがあると伝統的に言われています。ハードディスク時代のサーバー管理における一般論ですのであくまで参考値です。<br>4分25秒でコピーが完了しています。</p><h3 id="Lexar-NM790-書き込みキャッシュ無し"><a href="#Lexar-NM790-書き込みキャッシュ無し" class="headerlink" title="Lexar NM790 書き込みキャッシュ無し"></a>Lexar NM790 書き込みキャッシュ無し</h3><img src="/new-technology/2024/01/13/ZikeDrive-Z666/perfmon-nocache.png" class="" width="640" title="alt"><p>緑色のグラフはDisk Write Bytes&#x2F;secで、左の凡例の10の数が1,000Mbpsを示します。<br>赤色のグラフはDisk Queue Lengthで、左の凡例の10の数が1を示します。</p><p>計算上は約788MB&#x2F;sでファイルがコピーされていますが、実際にNVMeに書き込んだ内容は860MB&#x2F;sです。凡そ1,000MB&#x2F;sでコピーしており、最後の20秒で速度が落ちています。速度が落ちた理由はNVMeのSLCバッファが枯渇したものと思われ、200MB&#x2F;sあたりまで落ち込み、Disk Queue Lengthも2のままが継続する比率が高くなっています（青色の枠で囲った部分）。SLCバッファの枯渇はSSDの宿命とも言え、やむを得ませんが、取り外しポリシーがクイック取り外し、暗号化、数MB単位の小さいファイルもあれば、これくらいの速度が現実的です。</p><p>Disk Queue Lengthは取り外しポリシーの制約があり、Diskへの負担はあまり大きくありません。</p><h3 id="Lexar-NM790-書き込みキャッシュ有り"><a href="#Lexar-NM790-書き込みキャッシュ有り" class="headerlink" title="Lexar NM790 書き込みキャッシュ有り"></a>Lexar NM790 書き込みキャッシュ有り</h3><p>取り外しポリシーを高パフォーマンスにします。コピー時間は凡そ1分50秒で2分35秒の短縮です。計算上は約1,900MB&#x2F;sです。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/perfmon-cache.png" class="" width="640" title="alt"><p>前回同様、後半はSLCバッファが枯渇して数値が落ち込むと考えられますが、グラフを見る限りは後半を除けば2,000MB&#x2F;s〜3,000MBの速度でNVMeに書き込んでいます。最初から4〜6あたりのDisk Queue Lengthが発生しており、十分NVMeへの負荷も確認できます。但し、断続的に高止まりしているわけではなく、0〜8の間で行ったり来たりしていますから、ファイルサイズが変化する状況で速度に変化があると考えられます。<br>グラフを眺めていると、後半30秒はDisk Write Bytes&#x2F;secの値が落ち込むと同時にDisk Queue Lengthの数値は若干高い傾向が見られます（青色の枠で囲った部分）。最後の5秒はDisk Write Bytes&#x2F;secがかなり落ち込みNVMeに対する信頼性として一瞬不安になりますが、実際の書き込み量が減るものの、Queueは発生していないのでボトルネックは発生していないと考えられます。</p><p>10gbpsのエンクロージャーを使った場合は、取り外しポリシーを高パフォーマンスの時のDisk Write Bytes&#x2F;secは凡そ950MB&#x2F;sで、クイック取り外しの時は600MB&#x2F;sでした（後半の処理速度低下部分を除く）。</p><h3 id="SK-hynix-Platinum-P41"><a href="#SK-hynix-Platinum-P41" class="headerlink" title="SK hynix Platinum P41"></a>SK hynix Platinum P41</h3><p>Platinum P41の高パフォーマンスでの結果です。コピーの結果は1分35秒でNM790よりは15秒ほど高速でした。</p><img src="/new-technology/2024/01/13/ZikeDrive-Z666/perfmon-p41.png" class="" width="640" title="alt"><p>このNVMeの特性として、初動はスロースタートです。Disk Queue Lengthがいきなり8まで上がります。これはmacOSのベンチマークで確認した際にも少し気になりました。<br>Disk Queue LengthはNM790よりはやや低い数値で安定しています。NM790はQueueが0と8の間を絶えず行ったり来たりしています。一方、P41のQueueは2と3が中心で、時々0になったり4以上となり変動が少ない状況です。これらはDRAMキャッシュの効果といえます。実際のコピー時間として見た場合はNM790と比較してそれほど顕著な差は見受けられません。単純にコピーではない、動画編集処理やゲームなど低レイテンシが求められるような用途には向いていると考えられます。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>最後のWindowsでのテストはリアルな速度を示しました。SSDの容量が埋まっている場合はSLCバッファの数も足りなくなり、これよりもパフォーマンスは落ち込むものと考えられますが、今回の検証の目的からも外れるため、ここまでといたします。</p><p>結論として、外付けディスクの速度を上げるためには、デバイスコントローラー（AS2464PD）、ケーブル（Thunderbolt4／USB4）、NVMeメディア（PCIe4x4）、ホストコントローラー（PC本体）のすべての速度をバランス良く高める必要があります。</p><p>私は4TBのNM790でMacbookのバックアップ（TimeMachine）のパーティションを1TB、その他動画・写真の管理・編集および映画や音楽、モジュールのダウンロードなどを3TBとしてシンプルな用途で使っています。色々なデータでTimeMachineのバックアップが膨らんでいくのも避けたいと考えています。</p><p>ZIKEDRIVE Z666が登場したこと、高速なNVMeが登場したことで、外付けディスクは実運用でかなり快適に使えるようになりました。</p><h2 id="補足"><a href="#補足" class="headerlink" title="補足"></a>補足</h2><p>2024-02-10 更新</p><p>Z666のファームウェアアップデータの提供は取り下げになったようです。今はZIKEのホームページで表示がされていません。<br>なお、同じAS2464のチップを搭載したJEYIのエンクロージャーはeBayで購入できます。こちらの製品はファームウェアがきちんと提供されています。実際に私もeBayで購入したものをファームウェアアップデートして利用しています。Z666とJEYIのものとは私の環境においては違いは見受けられません。</p><blockquote><p>Jeyi ASM2464 USB4 Enclosure Firmware<br><a href="https://www.jeyi.com/pages/downloads?spm=..index.header_1.1">https://www.jeyi.com/pages/downloads?spm=..index.header_1.1</a></p></blockquote><p>ーーー</p><p>Z666のファームウェアは2024年1月3日に更改されたものの、アップデータとしてのConfigが誤っているようでアップデートが出来ません。<br>単にファームのファイル名が誤っているように見えて、Configを修正すれば実行できるとは思いますが、他のパラメータもたくさんあり、一旦はZIKE社に問い合わせています。また情報が得られたら記事をアップデートしたいと思います。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2024/01/13/ZikeDrive-Z666/title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;
&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;USB4 40Gbpsに対応したNVMe　M.2対応のSSDエンクロージャーを紹介します。いわゆる外付けディスクです。ノートPCの外付けとして直近のNVMe M.2 SSDの状況を鑑みつつ、USB4&amp;#x2F;Thunderbolt4&amp;#x2F;Thunderbolt3などプロトコルの違い、実運用における速度を見ていきます。&lt;/p&gt;</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    
    <category term="M.2 NVMe" scheme="https://yoshi0808.github.io/new-technology/tags/M-2-NVMe/"/>
    
    <category term="ZikeDrive" scheme="https://yoshi0808.github.io/new-technology/tags/ZikeDrive/"/>
    
    <category term="USB4" scheme="https://yoshi0808.github.io/new-technology/tags/USB4/"/>
    
    <category term="Thunderbolt3" scheme="https://yoshi0808.github.io/new-technology/tags/Thunderbolt3/"/>
    
    <category term="Thunderbolt4" scheme="https://yoshi0808.github.io/new-technology/tags/Thunderbolt4/"/>
    
    <category term="MinisForum UM790 Pro" scheme="https://yoshi0808.github.io/new-technology/tags/MinisForum-UM790-Pro/"/>
    
    <category term="Lexar NM790" scheme="https://yoshi0808.github.io/new-technology/tags/Lexar-NM790/"/>
    
    <category term="SK hynix Platinum P41" scheme="https://yoshi0808.github.io/new-technology/tags/SK-hynix-Platinum-P41/"/>
    
  </entry>
  
  <entry>
    <title>iPhoneに繋がるミニSSDケース</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/12/16/MiniSSDCase/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/12/16/MiniSSDCase/</id>
    <published>2023-12-15T17:40:54.000Z</published>
    <updated>2024-01-06T22:35:18.436Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/12/16/MiniSSDCase/iPhone.png" class="" title="alt"><p>iPhone15のUSB-Cに繋がるミニSSDケースを紹介します。これは、M2-2230という小型のSSDが組み込めるケースです。iPhoneは破損防止のためにケースを使っていらっしゃる方が多いとは思いますが、ケースとUSB-C接続端子とが競合し、USB-C端子が本体に挿さりきらないという問題がありますが、このケースはやや長めの端子になっており、スマホケースを使う前提に作られているようです。</p><span id="more"></span><h2 id="SDカードの速度"><a href="#SDカードの速度" class="headerlink" title="SDカードの速度"></a>SDカードの速度</h2><p>SDカードはちょっとしたデータの受け渡しに使え便利ですが速度という意味では少し取り残されてきた感があります。長期保存にも向きませんが、安価なのでOSのセットアップなどではまだまだ主流です。もっともSDカードは、ビデオカメラで動画を撮るのが主目的ですので、その速度とは常に動画の解像度と比較されることになります。</p><p>分かりやすい目安の表が SD Associationから提示されている以下の図になります。</p><img src="/new-technology/2023/12/16/MiniSSDCase/speedclass.png" class="" title="alt"><blockquote><p> Copyright © SD Association. All Rights Reserved.<br><a href="https://www.sdcard.org/ja/developers-2/sd-standard-overview/speed-class/">https://www.sdcard.org/ja/developers-2/sd-standard-overview/speed-class/</a></p></blockquote><p>フルHDの動画であれば、UHS-3を使えば一般的に問題無いというレベルです。4K動画となると、解像度に加え、フレームレートも大きく関わってきますから、少し留意が必要となってきます。</p><p>こういった一般用途に加え、機器の持つデータの移行やバックアップなどが通常の利用用途に必要な方は、少しSDカードでは物足りなくなり、データ量としてカバーできるポータブルHDDの出番になります。</p><h2 id="M2-2230のSSDケース"><a href="#M2-2230のSSDケース" class="headerlink" title="M2.2230のSSDケース"></a>M2.2230のSSDケース</h2><p>PCで一般的に用いられるM.2-2280を使えば高速化でき便利ですが、これだと少し大きさとしてポケットに入るとまでは言いづらく、嵩張ります。M.2-2230という小さなSSDであれば随分小型化できます。今回それにぴったりのSSDケースを紹介します。</p><p>中国メーカーのITGZという会社の製品です。秋葉原のラジオデパートにあるテクノハウス東映に入荷したという情報から、10月ごろに店舗に足を運んだのですが、あっさり売り切れということでした。Amazonでも販売しているようですが、結局は中国からの発送なのか時間も掛かるようでしたので、いつものeBayで落札し、1ヶ月ほど待つことにしました。</p><p>ケースは金属製で、ヒートシンク代りにもなり、放熱しやすい仕組みになっています。放熱のサーマルパッドも2枚付属しています。<br>ケース付属のドライバーでケースを分解し、SSDを取り付けます。</p><img src="/new-technology/2023/12/16/MiniSSDCase/case.png" class="" width="800" title="alt"><ul><li>SSDケース　US$15.95（eBay 送料込み）</li></ul><h2 id="M-2-SSD"><a href="#M-2-SSD" class="headerlink" title="M.2 SSD"></a>M.2 SSD</h2><p>M.2 SSD自体もeBayで落札しました。WD SN740の1TBモデルです。</p><p>上記の写真はサーマルパッドをつけてSSDを組み込んだところです。もう1枚のサーマルパッドを付けると上蓋が閉まりきらなかったので付けないことにしました。もちろん、SSD側のシールを剥がして対応する事も出来なくはありませんが、よくシールを剥がしてミスって破損させるケースもあるようなので、原則はSSDのシールはそのままにします。WesternDigital社はこのシールを剥がすと保証対象外とするようですね。私の場合はeBay購入なのでそもそも保証はありませんが。。。</p><p>M.2 2230自体があまり普及していないようですがAmazonなら数社ほどメーカーのSSDは入手できます。10月にテクノハウス東映に訪問した際は、確かトランセンド社とMicron社を筆頭に、いくつかのメーカーのSSDが廉価に販売されていたと記憶しています。</p><h2 id="Macbookでのベンチマーク"><a href="#Macbookでのベンチマーク" class="headerlink" title="Macbookでのベンチマーク"></a>Macbookでのベンチマーク</h2><p>MacBookのAmorphousDiskMarkでベンチマークを計測してみます。</p><img src="/new-technology/2023/12/16/MiniSSDCase/diskmark.png" class="" width="480" title="alt"><p>想定通り、シーケンシャルは8Gbps(980MB&#x2F;s)程度と良い数値が出ています。SDインタフェースの90MB&#x2F;sを大きく凌駕しています。10GbEのネットワークを持つNASに繋いだ時とほぼ同程度の速度です（ネットワークレイテンシが無いぶんランダムの書き込みはSSDが高速です）。</p><p>インターネット、NAS、ポータブルSSDと10Gbpsでそれぞれの速度差が無いと使い勝手が格段に良くなります。Wi-Fiも6Eで高速にはなりましたが、1.6Gbps程度でレイテンシも大きいので、大きなデータを扱う際は、PCなどをLANに繋ぎ直すという行為はまだ当面続きそうです。</p><p>なお、スマホケースに組み込まれたiPhoneに接続することを想定しているのか少しUSB-Cの端子が長めになっています。よって、MacBookなどに繋げた際は、少し本体とケースの間に隙間ができます。</p><img src="/new-technology/2023/12/16/MiniSSDCase/macbook.png" class="" width="480" title="alt"><h2 id="発熱"><a href="#発熱" class="headerlink" title="発熱"></a>発熱</h2><p>高速な通信には発熱は避けられません。MacでDiskMarkを2回実行し、ケースの温度を測ったところ51度ありました。</p><img src="/new-technology/2023/12/16/MiniSSDCase/temp.png" class="" width="480" title="alt"><p>51度は指でケースを触れてだいたい3秒程度我慢できるくらいでしょうか。</p><h2 id="iPhoneでのProRes撮影"><a href="#iPhoneでのProRes撮影" class="headerlink" title="iPhoneでのProRes撮影"></a>iPhoneでのProRes撮影</h2><p>なお、iPhone15 ProでApple ProResエンコーディングでの動画撮影をしてみました。自動的にUSBCに動画を保存するようになります。一応、撮影&#x2F;保存は出来るんですが、複数回、動画を撮影しようとするとiPhoneのカメラアプリが固まってしまいます。RTL9210チップとの相性なのか、再初期化（OSからのファイルのクローズ、再オープン）に無応答となるようですので、このケースではiOSのProRes撮影に正式に対応できていない可能性があります。30秒の4K&#x2F;30FPSの撮影で3GB強の容量が消費されます。MacBookで再生するときちんと録画はされているようです。またiOSの”ファイル”アプリケーションでUSB-Cへのファイルのコピーも問題なく可能なことを確認しています。</p><p>また、この際のケース温度は46度でした。普通の人が普通に使うとしたら、この熱量に驚くでしょうが、高速通信に慣れている方であれば許容範囲なのでしょうか。</p><h2 id="その他"><a href="#その他" class="headerlink" title="その他"></a>その他</h2><p>最近、円安も少し落ち着いてきましたね。来年春くらいにはさらに円安が落ち着くことを期待したいところです。以前に「<a href="/new-technology/2022/06/28/multi-currency-account/" title="マルチカレンシー口座 WISE">マルチカレンシー口座 WISE</a>」の記事でマルチカレンシー口座について記事を書きました。ドル決済を利用される方はeBayの為替手数料抑制のためにWISEの利用を検討されることをお勧めします。売買の都度、円から外貨に自動で交換し決済を完了させることができ、カード会社の手数料やPayPalの手数料よりは廉価です。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/12/16/MiniSSDCase/iPhone.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;p&gt;iPhone15のUSB-Cに繋がるミニSSDケースを紹介します。これは、M2-2230という小型のSSDが組み込めるケースです。iPhoneは破損防止のためにケースを使っていらっしゃる方が多いとは思いますが、ケースとUSB-C接続端子とが競合し、USB-C端子が本体に挿さりきらないという問題がありますが、このケースはやや長めの端子になっており、スマホケースを使う前提に作られているようです。&lt;/p&gt;</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    
    <category term="M.2 NVMe" scheme="https://yoshi0808.github.io/new-technology/tags/M-2-NVMe/"/>
    
  </entry>
  
  <entry>
    <title>Sophos Firewall v20</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/11/12/xg-v20/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/11/12/xg-v20/</id>
    <published>2023-11-11T19:01:00.000Z</published>
    <updated>2023-11-12T04:31:09.127Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/11/12/xg-v20/Title.png" class="" title="alt"><h2 id="Sophos-Firewall-v20"><a href="#Sophos-Firewall-v20" class="headerlink" title="Sophos Firewall v20"></a>Sophos Firewall v20</h2><p>Sophos Firewall v20が2023年11月06日に発表されました。個人向けとしては、IPv6 DHCP Prefix Delegationのサポートがなされています。</p><span id="more"></span><h2 id="主なエンハンスの内容"><a href="#主なエンハンスの内容" class="headerlink" title="主なエンハンスの内容"></a>主なエンハンスの内容</h2><ul><li>IPv6 DHCP Prefix Delegation</li><li>IPv6 BGPv6</li><li>Synchronized Securityの強化</li><li>VPN管理の強化</li></ul><p>v20の詳細な説明はSophos Communityを参照してください。</p><blockquote><p><a href="https://community.sophos.com/sophos-xg-firewall/b/blog/posts/sophos-firewall-v20-is-now-available">https://community.sophos.com/sophos-xg-firewall/b/blog/posts/sophos-firewall-v20-is-now-available</a></p></blockquote><p>リリースノートはこちらです</p><blockquote><p><a href="https://docs.sophos.com/releasenotes/index.html?productGroupID=nsg&amp;productID=xg&amp;versionID=20.0">https://docs.sophos.com/releasenotes/index.html?productGroupID=nsg&amp;productID=xg&amp;versionID=20.0</a></p></blockquote><h2 id="Sophos-Firewallのアップデート"><a href="#Sophos-Firewallのアップデート" class="headerlink" title="Sophos Firewallのアップデート"></a>Sophos Firewallのアップデート</h2><p>XGの管理画面にログイン後、左ペインメニューの<mark class="label primary">バックアップ＆ファームウェア</mark>の<mark class="label primary">ファームウェアの確認</mark>でアップデートの案内が順次来ます。個別にバージョンアップのファイルを入手するには、以下のURLからダウンロードします。</p><p><a href="https://support.sophos.com/support/s/article/KB-000043162?language=ja">https://support.sophos.com/support/s/article/KB-000043162?language=ja</a></p><ol><li>上記画面で<mark class="label primary">ファームウェア</mark>の<mark class="label primary">ソフトウェア</mark>のLinkをクリックします。</li><li>“SW-20.0.0_GA.SFW-222.sig”をダウンロードします。</li><li>Sophos Firewallの管理画面にログインし、左ペインメニューの<mark class="label primary">バックアップ＆ファームウェア</mark>の<mark class="label primary">ファームウェアのタブメニュー</mark>から以下の画面に赤丸で囲った矢印のアイコンをクリックし、ダウンロードしたモジュールをアップロードします。</li></ol><img src="/new-technology/2023/11/12/xg-v20/verup.png" class="" width="800" title="alt"><p>ダウンロードしたファームウェアを指定します。</p><img src="/new-technology/2023/11/12/xg-v20/update.png" class="" width="480" title="alt"><p>アップロード＆再起動ボタンをクリックし、v20へのアップグレードを完了させます。</p><h2 id="auひかりのIPv6-DHCP-Prefix-Delegation"><a href="#auひかりのIPv6-DHCP-Prefix-Delegation" class="headerlink" title="auひかりのIPv6 DHCP Prefix　Delegation"></a>auひかりのIPv6 DHCP Prefix　Delegation</h2><p>ようやくIPv6のPrefix委任が使えるようになりました。これは日本だけではなく、世界のホームユーザーからしても待ち望んでいた対応です。これでSophos FirewallのIPv6での苦肉の策である、ULAからIPv6NATという方式から解放されます。ただ個人的には、私の利用しているauひかりの場合残念ながらPrefix Delegationが使えません。いや、正確には64ビットのサブネットが1つだけ割り振られるようではあるのですが、本来、Prefix Delegationは60ビットや56ビットなどの複数のサブネットを受け取り、個々のネットワークに割り当てることになりますから、1つだけあるというのは正規のDelegationという意味合いも少し違います。</p><p>とはいえ、auひかり以外のユーザーのために中身を確認していきます。</p><p>ネットワークの設定からWANを選び、モードは<mark class="label primary">手動</mark>にして<mark class="label primary">DHCPプレフィックスの委任</mark>を選択します。</p><img src="/new-technology/2023/11/12/xg-v20/ipv6-1.png" class="" width="480" title="alt"><mark class="label primary">優先する委任プレフィックス</mark>はホームユーザーは固定IPで予め指定されたPrefixがあるわけでは無いので設定せずOFFのままで構いません。法人の場合など、固定IPv6を保有する場合、Prefixと委任されるレングスとを入力しますが、デフォルトでは空です。私の場合、4バイト目でauひかりから1を貰っていたので、16ビット分のサブネットが使えるかもしれないと試行錯誤で設定しましたが、その情報が消せずに残っています。<p>続いて、LANの設定です。</p><img src="/new-technology/2023/11/12/xg-v20/ipv6-2.png" class="" width="640" title="alt"><p>ここでは、<mark class="label primary">IPの割り当て</mark>に<mark class="label primary">委任</mark>を選びます。続いて、<mark class="label primary">アップストリームのインターフェース</mark>として、WANであるPort2を選びます。<br>auひかりでは、ISP は、IPv6 プレフィックスを委任していませんと警告メッセージが表示されてしまいますが、NTT系などでは56ビットのPrefix委任が行われ設定が可能となるはずです。この中でLANに任意の64ビットのネットワークを割り当てることになります。</p><p>余談ですが、Sophos Firewallv20のEarly Accessプログラムで私は事前検証していたのですが、Sophos Firewallでは&#x2F;48, &#x2F;52, &#x2F;56, そして &#x2F;60がサポートされ、それ以外はサポートされないというSophos側からの回答でした。</p><p>実はEarly Accessのv20ではもう少し挙動が異なり、64ビットは受け取れていました。Sophosの話ではありませんが、Ubiquiti関係のコミュニティでもauひかりからIPv6のDHCPv6-PDは<strong>出来ない事もない</strong>という情報共有もあり64ビット１つは割り当て可能という事実は認識していました。</p><img src="/new-technology/2023/11/12/xg-v20/ea.png" class="" width="480" title="alt"><p>auひかりのWANのPrefixの4バイト目は”1”であり、LANのDelegationで確認したPrefix4バイト目は”2”でした。せめてサブネット１つだけでもIPv6 Delegationが出来ればと思いましたが、残念ながら製品版では、エラーチェックが強化された上で&#x2F;64は排除されてしまいました。</p><p>いっそのこと気前よく&#x2F;48くらい割り当てて貰えないかなと思いつつ、一応auひかりのサポート窓口にDHCPv6 Delegationに対応してほしいという要望は出しておきました。</p><h2 id="アクティブな脅威対応"><a href="#アクティブな脅威対応" class="headerlink" title="アクティブな脅威対応"></a>アクティブな脅威対応</h2><p>Firewallの左ペインメニューでは<mark class="label primary">アクティブな脅威対応</mark>というメニューがあります。<br>ここでは2種類の脅威対応があります。１つは名称変更でATP (Advanced Threat Protection) という旧機能がSophos X-Ops 脅威フィードに名称が変更されています。過去、ログを見ても殆どこのATPに関するログは見ることはありませんでした。</p><p>もう1つは、MDR脅威フィードという機能です。外部の MDR アナリストがネットワークの脅威フィードを特定し、自動的にファイアウォールにプッシュし、複数のファイアウォールモジュールが、これらのフィードに基づいてトラフィックをブロックするとのことです。</p><p>この２つの機能はログでもアクティブな脅威対応という項目で確認できます。</p><div class="note info"><p>仮想環境（ESXi）上にFirewallをインストールされている方はアップグレードの前に、「<a href="/new-technology/2020/10/11/esxi-backup/" title="VMware ESXiの仮想マシンをバックアップする">VMware ESXiの仮想マシンをバックアップする</a>」を参考に、バックアップを確保される事をお勧めします。</p></div>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/11/12/xg-v20/Title.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;h2 id=&quot;Sophos-Firewall-v20&quot;&gt;&lt;a href=&quot;#Sophos-Firewall-v20&quot; class=&quot;headerlink&quot; title=&quot;Sophos Firewall v20&quot;&gt;&lt;/a&gt;Sophos Firewall v20&lt;/h2&gt;&lt;p&gt;Sophos Firewall v20が2023年11月06日に発表されました。個人向けとしては、IPv6 DHCP Prefix Delegationのサポートがなされています。&lt;/p&gt;</summary>
    
    
    
    <category term="Security" scheme="https://yoshi0808.github.io/new-technology/categories/Security/"/>
    
    
    <category term="XG Firewall" scheme="https://yoshi0808.github.io/new-technology/tags/XG-Firewall/"/>
    
  </entry>
  
  <entry>
    <title>iPhone15 ProとWiFi6E</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/10/21/iPhone15pro/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/10/21/iPhone15pro/</id>
    <published>2023-10-20T22:00:00.000Z</published>
    <updated>2023-10-20T22:37:34.927Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/10/21/iPhone15pro/Title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p>iPhone15 Proを購入しました。代表的なものはWi-Fi6Eへの対応ですが、色々なものに繋いだ所感を書いていきます。<span id="more"></span><h2 id="Wi-Fi-6E"><a href="#Wi-Fi-6E" class="headerlink" title="Wi-Fi 6E"></a>Wi-Fi 6E</h2><p>ネットワークに興味がある方としては、iPhone15 Pro&#x2F;Pro MAXがWi-Fi 6Eに対応した事が大きいですね。160MHz幅で接続可能です。 MacbookであればTimeMachineでバックアップの時間短縮できるなど明らかなメリットがあるのですが、スマホではそのメリットが感じにくいところではあります。撮影した4K動画のNASへのアップロードが短縮できることや、画面のリフレッシュ速度も向上し端末全体が高速化しているので、Webブラウジングもより快適に感じます。</p><ul><li><p>SpeedTest</p><img src="/new-technology/2023/10/21/iPhone15pro/speedtest.png" class="" width="360" title="alt"></li><li><p>iPerf3</p><img src="/new-technology/2023/10/21/iPhone15pro/iperf3.png" class="" width="360" title="alt"></li></ul><p>まずまずの速度が出ています。私の環境ではInternet向けにはFirewallが入っていることもあり、一般的にはもう少し速度が出るかもしれません。</p><p>なお、iOSに限らず、macOSでもそうなんですが、Appleデバイス全般の注意事項としては、Wi-Fi 6E単独のチャンネルでは安定せず、2.4GHz、5GHz、6GHz全てを有効にしたSSIDを作成する必要があります。</p><blockquote><p>Apple 製デバイスで Wi-Fi 6E ネットワークを利用する<br> <a href="https://support.apple.com/ja-jp/HT213433">https://support.apple.com/ja-jp/HT213433</a></p></blockquote><p>単独のWi-Fi6EではSpeedtestでも安定せず途中でテストが終了したり不安定です。これはMacbook Pro(2023)でも同じです。<br>6E単独で接続した場合は、iOSで以下の警告が表示されます。</p><img src="/new-technology/2023/10/21/iPhone15pro/ios.png" class="" width="400" title="alt"><p>制約のように見えますが、Wi-Fi6Eの電波の見つけ方の方法によってこのような挙動になります。Apple製品のように、必ずしもWi-Fi6Eのみに接続されていない5GHzの端末ともスムーズに連携するためには必要なのでしょう。</p><h2 id="Wi-Fi-ローミング"><a href="#Wi-Fi-ローミング" class="headerlink" title="Wi-Fi ローミング"></a>Wi-Fi ローミング</h2><p>Wi-Fiローミングというのは同一SSIDで異なるアクセスポイント（AP)に自動で切り替わることです。最近の無線ルーターではメッシュ機能を持つものが増えてきました。例えば、1階から2階に移動した時に近くにあるアクセスポイントに自動的に切り替わり、より快適に使えるようになるというものです。</p><p>このローミングについて説明しだすとかなり長くなるのでここでは簡単にiPhoneに関して説明します。<br>iPhoneはWi-Fiの電波が-70dBmを下回ると、他のAPにローミングしようとします（厳密には他のAPを探すという工程も含まれます）。その際、高速にローミングが行えるかどうかというのがスマホの使い勝手では重要です。</p><p>一般的にスマホがWi-Fiに繋がる場合は、無線に接続する際の認証が行われ、DHCPによってIPアドレスを割り当てるという手順が入ります。この手順をAPが変わるたびに実施していたのでは最低でも1秒程度の切断が発生します。つまり通話中にフロアを移動していると途中でパケットの再送が入りますが、IPアドレスの再取得をやっていたのでは通話、アプリが切断されることになります。これらに対処するものが高速ローミングです。</p><p>高速ローミングは認証情報がキャッシュされることが必須です。私たちが一般的に使うようなSSID毎のパスワードであったり、企業で使われるRADIUS認証によるユーザー認証情報をキャッシュし、別のAPで速やかにIPアドレス引き継ぎと高速な再認証が必要です。</p><p>このような方法によって、高速ローミングが実現し、数十ミリ〜遅くとも100ミリ程度でAPが切り替わり、その際に通話が途絶えることはありません。パケットの再送は確実に行われますが、スマホやリモート会議などでは1秒近くのバッファリングがあるので再送による遅延にユーザーが気づくことはあまりありません。</p><p>お使いのAPによって挙動は変わりますが、以下は私が自宅で1階から2階に移動した時のPingの結果です。PingPlotterというアプリでGoogleまでのラウンドトリップを計測しています。最初に他のAPを探すところで第1段階の遅延、切り替わるところで第2段階の遅延が発生します。</p><img src="/new-technology/2023/10/21/iPhone15pro/plotter.png" class="" width="480" title="alt"><p>丸を2つ示していますが、左側が最初の遅延で250ミリ秒近くあります。これはAPを探している状態に入っています。このタイミングではAPー端末間の通信が保留になり遅延が発生します。本当にタイミングが悪ければパケットを取りこぼすこともあり再送が入ります。が、極めて小さな時間でありTCP&#x2F;IPやアプリケーションの再送機能によって大半はカバーされます。これはやや悪いケースの計測結果であり、一旦情報がキャッシュされるなどしていて、良いケースではその半分程度まで遅延が軽減されます。<br>右側の丸辺りで実際にローミングしています。これは20ミリ秒程度の遅延です。スマホのWi-Fiのアンテナ表示が変わったタイミングを目視により確認しました。</p><p>なお、APを探すところで250ミリあるのは私の環境の問題にも関わっており、iPhoneがAPから離れすぎた状況（-75dBmを下回る）のためと考えられます。電波の強さと端末との距離を考えながらAPの配置を行う必要があり、これには計測とトライアンドエラーの繰り返しが必要です。ちょうど家の端の階段の辺りが電波の弱いところで、そこにAPをさらに置いても良いのですが、100ミリ秒程度の改善でそこまで対応する気にもならずそのままにしています。</p><p>iPerf3を実行しながらフロアを移動した場合、瞬間的にはAPを探すところで数十Mbpsまでに落ち込むケースもありますが、完全に0となったりエラーになることはありません。</p><p>これ以上の話は複雑なのでまた別の機会があれば触れてみたいと思いますが、リビングでTeamsやZoomなどのリモート会議をしていて、家族が帰ってきてバタバタと2階に移動する際にも相手の発言が途切れることはありません。</p><p>iPhone15Proは、以前のiPhone11やiPhone12よりも電波を掴む力は強いように感じます。5GHzの電波ではまれに公衆回線に切り替わっていたお風呂でのブラウジングが捗ります😊</p><h2 id="有線バックホールとメッシュWi-Fi"><a href="#有線バックホールとメッシュWi-Fi" class="headerlink" title="有線バックホールとメッシュWi-Fi"></a>有線バックホールとメッシュWi-Fi</h2><p>APは一般的に有線で接続され、前述したようにローミング機能を提供しますが、個人向けのメーカーでは有線バックホールという名前が使われる場合があります。AP同士のコミュニケーションや通信を有線によって行うためです。一方、この有線バックホールを使わず、AP同士が無線で接続する形態をメッシュと呼んでいるようです。</p><p>このメッシュも独立したチャンネルを使う方法や端末と同一のチャンネルを使う方法など色々あり、各社のマニュアルを見ても、それについてはあまり明確に記載されていないものが多いようです。</p><p>なお、一般的にビジネスで用いられるローミング方式（有線バックホール）では、AP同士は異なる周波数（チャネル）にするのが基本です。<strong>異なるAP</strong>で<strong>同じ周波数</strong>を使っていると、昔の中継機と同じで<strong>それぞれのAPが出す電波同士で干渉してしまい、パフォーマンスが出ません</strong>。メッシュにすると遅くなるという感覚をお持ちの方も多いのではないでしょうか。</p><p>高速なローミングとWi-Fiの最大限のパフォーマンスを引き出すにはAP同士は異なるチャンネルを設定する必要があります。これは製品によって対応できないものもあるようですので確認をお勧めします。</p><p>有線バックホールを使わないケース、これは4LDK以上の広いフロアで物理配線が引けないなどの制約がある場合にやむなくAPをメッシュで分散配置する事については意味があります。ただそのような環境では後述するDFSを除けば、Wi-Fi6Eとなるメリットはあまり見出せないかもしれません。5GHzよりは6GHzの方が壁を通す力は落ちますから、5GHzの方がより電波は強力です。</p><h2 id="メッシュWi-FiとDFS"><a href="#メッシュWi-FiとDFS" class="headerlink" title="メッシュWi-FiとDFS"></a>メッシュWi-FiとDFS</h2><p>個人向けの5GHzでは割り当てられた電波の幅によって80MHz単位で使うことが一般的ですが、5.2GHz帯のみDFSが無く、5.3GHz、5.6GHzはDFSがあります。レーダーを受信するとAPが停波してしまうことになりますから、レーダー回避のために6GHzを使うのは有効です。</p><h2 id="私の環境"><a href="#私の環境" class="headerlink" title="私の環境"></a>私の環境</h2><p>私の環境ではUbiquitiのUniFi製品を利用しています。<br>以下はUniFiのトポロジーで自動的に構成されたネットワーク図です。上流のインターネット回線は、auひかり（10GbE）を使っています。</p><img src="/new-technology/2023/10/21/iPhone15pro/unifi.png" class="" width="800" title="alt"><p>APはU6 Enterpriseという製品で、PoEで2.5GbEのLAN接続と併せてスイッチから電源を取ります。<br>よくよく考えてみれば、クライアントが繋がっているスイッチからいきなりローミングして別のスイッチに切り替われば、スイッチは「いきなり別のスイッチポートから同じMACアドレスの端末のデータが届きネットワークループしてるのではないか」と混乱するはずです。しかし、そこはきちんと制御され、ローミングしたクライアントについて、接続されたすべてのスイッチのMACアドレステーブルを瞬時に更新しにいくようです。</p><blockquote><p>U6 Enterpriseアクセスポイント<br> <a href="https://jp.store.ui.com/collections/unifi-network-wireless/products/u6-enterprise">https://jp.store.ui.com/collections/unifi-network-wireless/products/u6-enterprise</a></p></blockquote><blockquote><p>Switch Enterprise 8 PoE スイッチ<br> <a href="https://jp.store.ui.com/collections/unifi-network-switching/products/switch-enterprise-8-poe">https://jp.store.ui.com/collections/unifi-network-switching/products/switch-enterprise-8-poe</a></p></blockquote><p>UniFi製品については、このブログでも取り上げています。</p><ul><li>「<a href="/new-technology/2022/08/27/ubiquiti-unifi/" title="Ubiquiti UniFiの世界">Ubiquiti UniFiの世界</a>」</li><li>「<a href="/new-technology/2022/11/23/unifi-switch/" title="UniFiスイッチ">UniFiスイッチ</a>」</li><li>「<a href="/new-technology/2022/12/31/unifi-ap/" title="UniFi Wi-Fiシステム">UniFi Wi-Fiシステム</a>」</li></ul><h2 id="公衆回線（5G）"><a href="#公衆回線（5G）" class="headerlink" title="公衆回線（5G）"></a>公衆回線（5G）</h2><p>公衆回線（5G)においては、iPhoneの実力というよりは公衆回線の環境が色濃く出ると思いますが、どうでしょうか。<br>海外サイトのSpeedSmartでは、5Gの速度テストにおいて、iPhone15 ProはiPhone14 Proよりも24％速いとレポートしています。</p><blockquote><p>SpeedSmart.net<br> <a href="https://speedsmart.net/blog/post/2005/iPhone-15-Pro-up-to-24-Faster-5G-Download-Speeds">https://speedsmart.net/blog/post/2005/iPhone-15-Pro-up-to-24-Faster-5G-Download-Speeds</a></p></blockquote><p>米国での5G速度は300Mbpsオーバーとの事です。<br>都内の某所（勤務先）で帰宅時に計測してみました。5G(5Gオート）と4Gとそれぞれ切り替えて計測してみます。</p><p>5G</p><img src="/new-technology/2023/10/21/iPhone15pro/5G.png" class="" width="360" title="alt"><p>4G</p><img src="/new-technology/2023/10/21/iPhone15pro/4G.png" class="" width="360" title="alt"><p>都心ではまずまずの速度です（5Gでは500Mbps超えると期待していましたが）。ビルの中に入っても100Mbps程度しか落ち込みません。</p><p>最も混雑する時間帯と言われる12時過ぎの状況は以下の通りです。</p><p>5G</p><img src="/new-technology/2023/10/21/iPhone15pro/5G1.png" class="" width="360" title="alt"><p>4G</p><img src="/new-technology/2023/10/21/iPhone15pro/4G1.png" class="" width="360" title="alt"><p>5Gは快適ですが、4Gは少し苦しいですね。やはりお昼時は4Gのユーザーがまだまだ多く速度が落ち込むようです。<br>もちろん、地下鉄では4Gですし、5G網も郊外に行くと4Gに切り替わったり途端に数十Mbps程度まで落ち込みます。また、私の計測した場所は「都内でたまたま計測した場所」ですので、ご参考に留めていただければと思います。</p><h2 id="USBハブに繋げてみる"><a href="#USBハブに繋げてみる" class="headerlink" title="USBハブに繋げてみる"></a>USBハブに繋げてみる</h2><p>iPhone15 ProはUSB-Cに対応しました。USB 3.2 Gen2に（USB3.1 Gen2と同義）対応し、10Gbpsの速度が出ます。パッケージに付属してくるUSB-CケーブルはUSB 2.0に対応（480Mbps)との事で高速通信のメリットは活かせません。</p><blockquote><p>Apple iPhone 15 の USB-C コネクタで充電および接続する<br> <a href="https://support.apple.com/ja-jp/HT213839">https://support.apple.com/ja-jp/HT213839</a></p></blockquote><p>「Belkin 7 in 1 USB-C 2.5Gbpsイーサネットハブ」に繋いでみます。</p><img src="/new-technology/2023/10/21/iPhone15pro/hub.png" class="" width="800" title="alt"><p>iPhoneの画面はUSBハブからHDMIで接続されたモニタにも映し出されますし、ネットワーク通信も可能で2.5GbEでの速度が当たり前のように出ます（ハブはUSB-PD電源に接続しています）。</p><img src="/new-technology/2023/10/21/iPhone15pro/speedtesthub.png" class="" width="360" title="alt"><p>念の為、無線を利用しないように機内モードに設定しています。</p><p>スマホの写真をNASに大量にアップロードする時などは、WiFi6Eが速いと言っても、2.5GbEの有線はレイテンシが小さいことによって高速にアップロード可能です。今回、NASにある無駄な写真や動画を一旦削除してスマホから整理済みの全ての写真・動画をSynologyのPhoto Mobileというアプリを使って再アップしたのですが、非常に高速でした。感覚的ですがWiFi6Eの2、3倍といった感じです。アプリの作りにもよりますけれども、写真または動画を1枚単位にアップロードする仕組みのアプリケーションでは、5本も6本ものスレッドで分散してアップロードはしないと思われますのでハードウェアでカバーできる一例でしょうか。こういったケースは今回のようなスマホ入れ替え時など滅多に発生しないケースですが、USB 3.2 Gen2（10GbE）となった事で非常に便利になりました。</p><blockquote><p>Belkin<br> <a href="https://www.belkin.com/jp/usb-c-7-in-1%E3%83%9E%E3%83%AB%E3%83%81%E3%83%9D%E3%83%BC%E3%83%88%E3%82%A2%E3%83%80%E3%83%97%E3%82%BF%E3%83%BC/INC009btSGY.html">https://www.belkin.com/jp/usb-c-7-in-1マルチポートアダプター/INC009btSGY.html</a></p></blockquote><h2 id="Macbookに繋げてみる"><a href="#Macbookに繋げてみる" class="headerlink" title="Macbookに繋げてみる"></a>Macbookに繋げてみる</h2><p>Macbookはテザリングの逆、iOSにネットワーク機能を提供できます。</p><img src="/new-technology/2023/10/21/iPhone15pro/mac.png" class="" width="480" title="alt"><p>実用性を考えると利用するシチュエーションはなかなか見出せませんが、Macbookが10GbEのネットワークに接続されている環境があれば、iPhone15 Proはさらに高速に通信が可能となります。</p><img src="/new-technology/2023/10/21/iPhone15pro/speedtestmac.png" class="" width="360" title="alt"><p>USB 3.2 Gen2やネットワークも10Gbpsとなればそれを基準と考え、その他周辺機器ともできるだけ速度差を無くしたいものです。例えばUSBメモリやSDカードはどうでしょうか？昔ながらにOSのセットアップなどに使ってきた経緯がありますが、技術の進歩でSDカードが大容量になったとしても速度とのバランスが悪いのではないでしょうか。今は10GbpsのUSBのSSDケース（M2.2280）が2、3千円で買えますので、廉価となったNVMeのSSDを挿して使うのはいかがでしょうか？USB3.2 Gen2であれば読み込み、書き込み共に10Gbps出ますし、NASのキャッシュ用で使っていた余りなどがあればそれを再利用するのも良いですね。</p><h2 id="Apple-CarPlay"><a href="#Apple-CarPlay" class="headerlink" title="Apple CarPlay"></a>Apple CarPlay</h2><p>Apple CarPlayは既に知られたサービスでiPhone15 Proになったからといって何かが変わるわけではありません。iOS17からはSharePlayという機能が追加され、車の中で搭乗者が（iPhoneを持っていれば）Apple Musicのセッションに参加し、搭乗者の好きな音楽を運転者のiPhoneのCar Playで再生できるようになりました。仕組みとしてはこれまであったAir Playに近いものがありますね。仲間で音楽もシェアする、時代を感じさせるサービスです。Siriの機能と組み合わせてマップの到着予定時刻を家族に共有できます。<br>iPhoneが車載のBluetoothに接続するとiOSの集中モードが自動的に運転モードに変わり通知などを制限できるようにもできます。<br>CarPlayも地道なアプリケーションの改善によってかなり使い勝手の良いシステムとなっています。</p><img src="/new-technology/2023/10/21/iPhone15pro/carplay.png" class="" width="1024" title="alt"><p>個人的にはThunderbolt3ケーブルでiPhoneとカーナビとを繋いでいるという事実が感慨深いものがあります。。。</p><h2 id="画面との距離"><a href="#画面との距離" class="headerlink" title="画面との距離"></a>画面との距離</h2><p>iPhone15 Proと直接関係ありませんが、iOS17からFaceIDに関連する機能追加として<strong>画面との距離</strong>があります。これはスマホに顔を近づけすぎると眼精疲労警告のため、画面全体が警告メッセージで覆われるというものです。これは子供の視力悪化対策に有用です。iPadでFaceIDに対応している製品は最新のiPad Proしかない（他はTouchID）ので、iOSのタブレットでこの機能を使いたければ（子供に利用させたければ）iPad Proを購入することになるのでしょうか。。。</p><img src="/new-technology/2023/10/21/iPhone15pro/screendistance.png" class="" width="360" title="alt">]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/10/21/iPhone15pro/Title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;
iPhone15 Proを購入しました。代表的なものはWi-Fi6Eへの対応ですが、色々なものに繋いだ所感を書いていきます。</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    <category term="Network" scheme="https://yoshi0808.github.io/new-technology/categories/Network/"/>
    
    
  </entry>
  
  <entry>
    <title>Synology NASでESXi仮想マシンのバックアップを取得する</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/09/16/Synology-abb/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/09/16/Synology-abb/</id>
    <published>2023-09-15T15:44:10.000Z</published>
    <updated>2023-09-16T00:44:28.464Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/09/16/Synology-abb/install.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p><p>SynologyのNASでは無償版ESXiの仮想マシン（VM）バックアップが可能なActive Backup for Business(ABB)というソフトウェアが提供されています。Microsoft Hyper-V2016および2019にも対応しています。無償版ESXiのバックアップソフトは「<a href="/new-technology/2021/03/06/esxi-nakivo/" title="無償版ESXiの高度なバックアップ">無償版ESXiの高度なバックアップ</a>」で書いた有償のもの（1年期限の無償版）は存在します。無償バックアップソフトは無償版ESXiに対応していないという難しい状況でしたが、NASが必須という前提はあるものの、追加コストゼロでESXi仮想マシンのバックアップが可能です。エージェントレスで、ESXi本体やVMには何もインストールする必要はありません。</p><blockquote><p>Synology<br> <a href="https://www.synology.com/ja-jp/dsm/feature/active-backup-business/virtual-machine">https://www.synology.com/ja-jp/dsm/feature/active-backup-business/virtual-machine</a></p></blockquote><span id="more"></span><h2 id="稼働条件"><a href="#稼働条件" class="headerlink" title="稼働条件"></a>稼働条件</h2><p>ABBは基本はSynologyNASのPlusモデルで、Btrfsでフォーマットされたファイルシステムが必要です。一部のPlusモデルにはBtrfsに対応しない製品もあるので事前の確認をお勧めします。</p><p><a href="https://www.synology.com/ja-jp/dsm/packages/ActiveBackup">https://www.synology.com/ja-jp/dsm/packages/ActiveBackup</a></p><h2 id="ABBの主要な機能について"><a href="#ABBの主要な機能について" class="headerlink" title="ABBの主要な機能について"></a>ABBの主要な機能について</h2><p>ここでは、ESXi仮想マシンのバックアップに目的を絞って説明します。</p><ol><li>ESXi7.0、8.0対応</li><li>VMのバックアップを複数世代管理</li><li>ジョブスケジューリング機能<br> ワンタイム、定期、日次、週次、月次を利用できます。</li><li>重複排除<br> VMWareのChange Block Trackingに対応。</li><li>暗号化転送</li><li>バックアップデータの暗号化</li></ol><h2 id="Synology-NASの事前準備"><a href="#Synology-NASの事前準備" class="headerlink" title="Synology NASの事前準備"></a>Synology NASの事前準備</h2><h3 id="ABBのインストール"><a href="#ABBのインストール" class="headerlink" title="ABBのインストール"></a>ABBのインストール</h3><p>NASのWeb画面に管理者としてログインし、パッケージセンターから”Active Backup for Business”をインストールします。</p><img src="/new-technology/2023/09/16/Synology-abb/install.png" class="" width="1024" title="alt"><p>上記はインストール済みの状態ですが、<mark class="label primary">「インストール」ボタン</mark>をクリックしてインストールします。<br>NASのFirewallを利用している場合は自動的にPort5510を開けるようにFirewallにルールが追加されます。</p><h2 id="可用性および機密性向上のために"><a href="#可用性および機密性向上のために" class="headerlink" title="可用性および機密性向上のために"></a>可用性および機密性向上のために</h2><ul><li>フォルダの容量制限（クォータ）についてはABBでは推奨されていません。</li><li>ESXiに対してSSHでの接続が必要です。セキュリティ向上のためroot相当の専用ユーザーをESXiに新規作成されることをお勧めします。</li></ul><h2 id="ESXiの事前準備"><a href="#ESXiの事前準備" class="headerlink" title="ESXiの事前準備"></a>ESXiの事前準備</h2><p>ESXiには以下の設定が必要です。</p><ol><li>VMWare Toolsのインストールが必要です。</li><li>ABBからESXiに対しHTTPS(Port443)、SSH(Port22)を使って接続可能なようにサービスを設定します。</li><li>ABBで無償版ESXiをバックアップするためにはCBT(Changed Block Tracking)を手動で有効にする必要があります。</li><li>（任意）セキュリティ向上のため、ESXi上に管理者アカウントを作成します。</li><li>（任意）セキュリティ向上のため、Port22,443で接続可能なIPアドレスをESXi上のFirewall設定で絞ります。</li></ol><h2 id="ESXi上でHTTPS、SSHの解放"><a href="#ESXi上でHTTPS、SSHの解放" class="headerlink" title="ESXi上でHTTPS、SSHの解放"></a>ESXi上でHTTPS、SSHの解放</h2><p>無償版ESXiを使う場合はブラウザから基本はvSphere Web Clientを使いますので、HTTPS(Pprt443)の解放は特に意識する必要はありません。ESXiのファイアウォールで接続可能なIPアドレスを絞っている場合はNASのIPアドレスから接続できるようにしておきます。</p><p>SSH(Port22)についてはESXiはデフォルトでサービス停止されている状態ですので、シェルおよびSSHのサービスを起動します。<br>左ペインメニューの<mark class="label primary">ホスト</mark>ー<mark class="label primary">管理</mark>の<mark class="label primary">サービスタブ</mark>から<mark class="label primary">TSM</mark>および<mark class="label primary">TSM-SSH</mark>を起動します。<br> <img src="/new-technology/2023/09/16/Synology-abb/esxi1.png" class="" width="800" title="alt"><br>この2つのサービスは右クリックメニューの<mark class="label primary">ポリシー</mark>から<mark class="label primary">ホストと連動して起動および停止します</mark>をチェックしておく事でESXiの起動時に自動的にサービスが起動するようになります。</p><h2 id="VMのChanged-Block-Trackingの設定"><a href="#VMのChanged-Block-Trackingの設定" class="headerlink" title="VMのChanged Block Trackingの設定"></a>VMのChanged Block Trackingの設定</h2><p>ESXiの機能であるChanged Block Tracking(CBT)はVMが稼働していて前回バックアップしたものから未更新のディスクブロックをスキップして差分のみバックアップする機能です。バックアップに必要な領域を削減できます。途中で別のバックアップ製品によるバックアップ、例えばghettoVCBなどでバックアップされると、次回のバックアップはフルバックアップを行います。</p><p>この設定にあたり、事前にVMのデータを退避することをお勧めします。VMを停止のうえで、データストアブラウザからVMの入っているフォルダ毎別の場所にコピーしてください。もし、設定の変更でVMを壊してしまった場合は、当該フォルダの<code>VM名.vmx</code>を右クリックから「VMの登録」で再登録できます。</p><h3 id="設定方法"><a href="#設定方法" class="headerlink" title="設定方法"></a>設定方法</h3><p>最初にVMがインストールされているディスクを調べ、そのSCSI-IDを確認します。<br>ESXi管理画面のVMを選択し右クリックして<mark class="label primary">設定の編集</mark>をクリックします。</p><img src="/new-technology/2023/09/16/Synology-abb/esxi2.png" class="" width="640" title="alt"><mark class="label primary">ハードディスク</mark>の詳細を開き、<mark class="label primary">コントローラの場所</mark>でSCSI-IDを確認します（SCSI(0:0)など）。<ol><li>VMを停止します。</li><li>ESXi管理画面のVMを右クリックして、<mark class="label primary">設定の編集</mark>をクリックします。</li><li><mark class="label primary">VMオプション</mark>タブをクリックします。</li><li><mark class="label primary">詳細</mark>セクションを開き <mark class="label primary">設定パラメータ</mark>の<mark class="label primary">設定の編集</mark>をクリックします。<mark class="label primary">設定パラメータ</mark>ダイアログが開きます。</li><li><mark class="label primary">パラメータの追加</mark>をクリックします。</li><li><code>ctkEnabled</code>パラメータを追加して、その値を<code>true</code>に設定します。</li><li>さらに<mark class="label primary">パラメータの追加</mark>をクリックし、<code>scsi0:0.ctkEnabled</code>を追加して、その値を<code>true</code>に設定します（環境に合わせて<code>scsi0:0</code>の内容は変更してください）。</li><li>OKボタンをクリックし設定を完了させます。</li><li>VMを起動します。</li><li>SSHでESXiに入り、VMが配置されているディレクトリで、<code>VM名-ctk.vmdk</code>ファイルがあることを確認します。</li></ol><p>CBTを無効にする場合はこの逆の手順、ctkEnabledの値をfalseに設定します。<br>VMWareによるCBTの説明は以下を参照してください。</p><blockquote><p>VMware VM上の変更ブロックのトラッキング（CBT） (1020128)<br> <a href="https://kb.vmware.com/s/article/1031873?lang=ja&amp;queryTerm=changed+block+tracking">https://kb.vmware.com/s/article/1031873?lang=ja&amp;queryTerm=changed+block+tracking</a></p></blockquote><h2 id="（任意）管理者アカウントの作成"><a href="#（任意）管理者アカウントの作成" class="headerlink" title="（任意）管理者アカウントの作成"></a>（任意）管理者アカウントの作成</h2><p>セキュリティの観点からrootはできるだけ使わない事をお勧めします。これは一般論でありrootがよく知られたユーザー名だからです。以下の手順で管理者アカウントを作成します。</p><ol><li>管理メニューの左ペイン<mark class="label primary">ホスト</mark>ー<mark class="label primary">管理</mark>から<mark class="label primary">セキュリティとユーザー</mark>に進み、<mark class="label primary">ユーザー</mark>から<mark class="label primary">ユーザーの追加</mark>をクリックします。<img src="/new-technology/2023/09/16/Synology-abb/esxi5.png" class="" width="800" title="alt"></li><li>ABBから接続する専用のユーザー名とパスワードを登録してユーザーの作成を終えます。</li><li>管理メニューの左ペイン<mark class="label primary">ホスト</mark>から<mark class="label primary">アクション</mark>を選択し、プルダウンの<mark class="label primary">権限</mark>をクリックします。</li><li>さらに<mark class="label primary">ユーザーの追加</mark>を選択します。実際には上記で作成したユーザーと同一名のユーザー名を入力します。ロールについては”システム管理者”を選択します。<img src="/new-technology/2023/09/16/Synology-abb/esxi4.png" class="" width="800" title="alt"></li></ol><p>これで新しいユーザーが作成できたので、Web管理画面からログイン可能か確認してください。</p><h2 id="（任意）SSH、Web-Clientのために接続可能なIPアドレスを絞る"><a href="#（任意）SSH、Web-Clientのために接続可能なIPアドレスを絞る" class="headerlink" title="（任意）SSH、Web Clientのために接続可能なIPアドレスを絞る"></a>（任意）SSH、Web Clientのために接続可能なIPアドレスを絞る</h2><p>この機能はESXiではファイアウォールと呼ばれ、Linuxのiptablesやufwと同様にシンプルなものです。ホームユーザーはシンプルなLANで閉じられたアクセスですが、安全のために特にSSHは設定を検討すべきです。<br>Web管理画面の左ペインメニューの <mark class="label primary">ネットワーク</mark>を選択し、<mark class="label primary">ファイアウォール</mark>タブをクリックして見つける事ができます。デフォルトでは一切の制約なく接続可能になっていますので、ここでSSHとWeb Clientに接続可能なIPを登録できます。</p><img src="/new-technology/2023/09/16/Synology-abb/esxi5.png" class="" title="alt"><h2 id="ABBの利用について"><a href="#ABBの利用について" class="headerlink" title="ABBの利用について"></a>ABBの利用について</h2><p>ABBの使い方については公式のクイックガイドが提供されています。</p><blockquote><p>Active Backup for Business クィック スタート ガイド<br> <a href="https://kb.synology.com/ja-jp/DSM/tutorial/Quick_Start_Active_Backup_for_Business">https://kb.synology.com/ja-jp/DSM/tutorial/Quick_Start_Active_Backup_for_Business</a></p></blockquote><p>ABBでは管理者（Administratorsグループ）ユーザーのみが操作できます。</p><h2 id="仮想マシンのABBへの登録"><a href="#仮想マシンのABBへの登録" class="headerlink" title="仮想マシンのABBへの登録"></a>仮想マシンのABBへの登録</h2><p>DSMからABBを起動します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb1.png" class="" title="alt"><p>仮想マシンを対象にします。</p><img src="/new-technology/2023/09/16/Synology-abb/abb2.png" class="" title="alt"><p>最初にバックアップ対象となるESXiを登録します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb3.png" class="" width="640" title="alt"><p>バックアップ対象となるESXiのIPアドレス、アカウントを入力します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb4.png" class="" width="640" title="alt"><p>ESXiに有効な証明書が設定されていないとワーニングが出ますが、ここはそのまま進みます。</p><img src="/new-technology/2023/09/16/Synology-abb/abb5.png" class="" width="640" title="alt"><p>ESXiへの接続が確認されチェックがOKであれば状態が<strong>成功</strong>となります。</p><img src="/new-technology/2023/09/16/Synology-abb/abb6.png" class="" width="640" title="alt"><p>エラーとなった場合は、ESXi側の設定、またはネットワークを確認してください。</p><h2 id="バックアップタスクの登録"><a href="#バックアップタスクの登録" class="headerlink" title="バックアップタスクの登録"></a>バックアップタスクの登録</h2><p>無事にESXiの情報がABBに取り込まれると、仮想マシンの情報が出力されます。</p><img src="/new-technology/2023/09/16/Synology-abb/abb7.png" class="" width="640" title="alt"><p>現在はバックアップが取得されておらず、タスクなしとなっています。</p><p>上記の<mark class="label primary">タスクの作成</mark>ボタンをクリックします。</p><p>仮想マシンが選択されます。</p><img src="/new-technology/2023/09/16/Synology-abb/abb8.png" class="" width="640" title="alt"><p>ここでタスク名を入力します。ここでは、ESXi8のUbuntu22のバックアップを取るのでESXi8.Ubuntu22とします。</p><p>続いてバックアップするフォルダを選択します。デフォルトでは、<mark class="label primary">ActiveBackupforBusiness</mark>になります。</p><img src="/new-technology/2023/09/16/Synology-abb/abb9.png" class="" width="640" title="alt"><p>最初のバックアップ時にフォルダの暗号化&#x2F;圧縮を設定します。私の場合すでに設定済みでありここでは変更できません。</p><img src="/new-technology/2023/09/16/Synology-abb/abb10.png" class="" width="640" title="alt"><p>バックアップオプションを選択します。Windows、Linuxのバックアップ時には<mark class="label primary">アプリケーション対応バックアップを有効化</mark>にチェックすることが推奨されます。<br>また、ESXiのCBTが有効である場合は<mark class="label primary">変更ブロック　トラッキングを有効化</mark>のチェックが有効になります。</p><img src="/new-technology/2023/09/16/Synology-abb/abb11.png" class="" width="640" title="alt"><p>改めて構成チェックが行われます。</p><img src="/new-technology/2023/09/16/Synology-abb/abb12.png" class="" width="640" title="alt"><p>続いて定期的なバックアップの設定です。</p><img src="/new-technology/2023/09/16/Synology-abb/abb13.png" class="" width="640" title="alt"><p>保持ポリシーを選定します。これはディスクの容量やバックアップ期間などに合わせて設定します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb14.png" class="" width="640" title="alt"><p>復元を許可するユーザーを設定します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb15.png" class="" width="640" title="alt"><p>最後のサマリで確認をし完了させます。今すぐバックアップを取得することもできます。</p><img src="/new-technology/2023/09/16/Synology-abb/abb16.png" class="" width="640" title="alt"><h2 id="仮想マシンのバックアップ実行"><a href="#仮想マシンのバックアップ実行" class="headerlink" title="仮想マシンのバックアップ実行"></a>仮想マシンのバックアップ実行</h2><p>64GBのシックプロビジョニングのUbuntu22の仮想マシンを手動でバックアップをしてみました。バックアップ速度についても計測してみます。</p><p><strong>環境</strong></p><p>ESXi8</p><table><thead><tr><th>パーツ</th><th>製品名</th></tr></thead><tbody><tr><td>CPU</td><td>AMD Ryzen5 5600G 6コア&#x2F;12スレッド 3.9-4.4GHz</td></tr><tr><td>メモリ</td><td>16GB(8GB×2) DDR4-3200</td></tr><tr><td>NVMe</td><td>WesternDigital Blue 500GB SSD &#x2F; NVMe M.2[PCIe 3.0×4]</td></tr><tr><td>NIC</td><td>Mellanox Connect X5(MCX512A-ACAT) SFP28 2Port</td></tr></tbody></table><p>Synology 1621+</p><table><thead><tr><th>パーツ</th><th>製品名</th></tr></thead><tbody><tr><td>CPU</td><td>AMD Ryzen V1500B クアッド コア 2.2 GHz</td></tr><tr><td>メモリ</td><td>8GB(4GB×2)</td></tr><tr><td>SSD</td><td>Samsung 870EVO 4TB(MZ-77E4T0B&#x2F;IT) &#x2F; SATA x 6(RAID5)</td></tr><tr><td>NIC</td><td>Mellanox Connect X4(MCX4121A-ACAT) SFP28 2Port</td></tr></tbody></table><p>SFP28(25GbE)のスイッチポートにそれぞれDACケーブルで接続しています。</p><p>ログの結果も非常に詳細で分かりやすいです。ここはさすがソフトウェアが売りのSynologyですね。</p><img src="/new-technology/2023/09/16/Synology-abb/time.png" class="" width="800" title="alt"><p>開発者が障害切り分けのために利用するログではなく、ユーザーに価値のある情報（ログ）を提供しています。これは他のメーカーとは根本的に出来が違います。</p><p>通知設定しているとメールも届きます。</p><blockquote><p>**** のバックアップタスク ESXi8.Ubuntu22 が完了しました。<br> 開始時間：2023-09-02 12:46<br> 終了時間：2023-09-02 12:47<br> 転送サイズ：24.7 GB<br> デバイス リスト：Ubuntu22</p></blockquote><p> 送信元 ****</p><p>まずは圧縮効果が出ており、64GBの仮想マシンが24.7GBとなっています。</p><p>さらに30分後、もう一度バックアップを取得してみます。今度は数秒で終了しました。通知では3.1MBとなっていました。これはESXiのCBTが有効で差分のみバックアップするためわずかの量に収まっていることになります。仮想マシンの稼働時間が長くなるとそれだけバックアップ量も増えることになります。</p><p>ちなみに、同一の環境でghettoVCBスクリプトでバックアップを取得した場合は以下の通り35秒でした。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2023-09-03 01:27:50 -- info: ============================== ghettoVCB LOG START ==============================</span><br><span class="line">2023-09-03 01:27:52 -- info: Creating Snapshot <span class="string">&quot;ghettoVCB-snapshot-2023-09-03&quot;</span> <span class="keyword">for</span> Ubuntu22</span><br><span class="line">Destination disk format: VMFS thin-provisioned</span><br><span class="line">Cloning disk <span class="string">&#x27;/vmfs/volumes/datastore1/Ubuntu22/Ubuntu22.vmdk&#x27;</span>...</span><br><span class="line">2023-09-03 01:28:23 -- info: Removing snapshot from Ubuntu22 ...</span><br><span class="line">2023-09-03 01:28:23 -- info: Backup Duration: 31 Seconds</span><br><span class="line">2023-09-03 01:28:23 -- info: Successfully completed backup <span class="keyword">for</span> Ubuntu22!</span><br><span class="line"></span><br><span class="line">2023-09-03 01:28:25 -- info: <span class="comment">###### Final status: All VMs backed up OK! ######</span></span><br><span class="line"></span><br><span class="line">2023-09-03 01:28:25 -- info: ============================== ghettoVCB LOG END ================================</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ABBの実行内容について"><a href="#ABBの実行内容について" class="headerlink" title="ABBの実行内容について"></a>ABBの実行内容について</h2><p>ABBの実行している内容は、ghettoVCBとほぼ変わりません。ESXiのAPIでESXiのスナップショットを取得しつつ、無償版ESXiではバックアップ関係のAPIが使えないためSSHで各種操作をして仮想マシンの情報を吸い上げています。<br>普段私はESXiにSSHで接続する際にはrootで公開鍵認証をしています（YubiKeyに秘密鍵を入れています）。ABBでは公開鍵認証は使えないようですので、今回示したように、別アカウントでパスワードを設定しています。ESXiのパスワードは他の用途を含めてABB以外では使うことがなく操作ミスなどによるパスワード漏洩の心配も不要です。</p><h2 id="復元"><a href="#復元" class="headerlink" title="復元"></a>復元</h2><p>ABBでバックアップを取得した日時（スナップショット）毎にESXiに復元します。</p><p>ABBの左ペインのメニューから仮想マシンを選択し、さらに実際に復元する仮想マシンを選択します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb17.png" class="" width="1024" title="alt"><p>仮想マシンを選択した状態では背景が薄いグレーになりますので、ここで<mark class="label primary">復元</mark>ボタンをクリックします。</p><p>続いて、復元ポイント（バックアップを取得した日付と時刻）を選択し、<mark class="label primary">VMWare VSphereへの復元</mark>を選択し、次に進みます。<br>注釈で「ゲストOSファイル（Windows&#x2F;Linux）の復元の場合、Active Backup for Business Portalに進んでください」とありますが、これはファイル単位で復元したい場合です。ここではスナップショット単位に戻す事を目的としていますのでこの説明は省略します。</p><p>続いて復元の仕方を選択します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb18.png" class="" width="640" title="alt"><mark class="label primary">仮想マシンの完全復元</mark>と<mark class="label primary">即時復元</mark>との2種類があります。ここでは完全復元の例について記載します。<p>なお、即時復元はNAS上で重複排除されてバックアップされたそのままの情報がESXiから見えるようになります。そこで仮想マシンを登録するなどすれば、すぐに仮想マシンを起動しその内容にアクセス可能となります。ただし、仮想マシンの実態はNAS上にあるのでパフォーマンスは落ちます。</p><p>復元モードを選択します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb19.png" class="" width="640" title="alt"><mark class="label primary">元の場所に復元</mark>と<mark class="label primary">新しい場所に復元、或いは異なる設定で復元</mark>との2種類があります。<p>一般的にはMACアドレスはESXi上で動的に生成されますが、元の場所、つまりこれまでの仮想マシン同様のIPアドレス、構成で戻すのであればIPアドレスの引き継ぎなども鑑み、元のMACアドレスで戻すことになります。新しい場所、つまり新しい仮想マシンとして複製するのであれば、後者を選択します。</p><p>なお、MACアドレスが静的な場合のオプションもありますがここでは割愛します。</p><p>この例では元の場所に戻します（仮想マシンの稼働中に復元します）。</p><p>最後に構成の最終確認をして実行します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb20.png" class="" width="640" title="alt"><p>対象のデータストア、ネットワーク（VLAN）を念のため確認してください。</p><mark class="label primary">復元後、自動的にVMの電源をオンにします</mark>のチェックは手前が省けるのでオンで良いでしょう。構成を変更したい場合は外すなど状況に合わせて選択します。<p>ちなみに、私の構成では、<code>vmfs/volumes/datastore1</code>にUbuntu22というフォルダが作成され、その中に仮想マシンの関連ファイルが登録されています（新規に仮想マシンを作成した一般的な構成です）。</p><p>ESXiの稼働中の画面は以下の通りです。</p><img src="/new-technology/2023/09/16/Synology-abb/esxi6.png" class="" width="1024" title="alt"><p>さて、実行中のアラートが表示されますがOKで続行します。</p><img src="/new-technology/2023/09/16/Synology-abb/abb21.png" class="" width="360" title="alt"><p>実行結果です。</p><img src="/new-technology/2023/09/16/Synology-abb/time2.png" class="" width="800" title="alt"><p>普通にUbuntuにESXi管理コンソール経由で接続でき、SSHも問題ありません。仮想MACアドレスは同一のもので復元されておりIPアドレスも前回と同じものでした。<br>復元動作は完璧です。</p><p>さて、復元では留意する点として、仮想マシンのESXi上の管理IDが変わる事が挙げられます。</p><p>復元後のフォルダ構成を確認しましたが、特にフォルダパスも変更はなく、復元前とは変更されたようには見受けられません。復元のログではテンポラリのフォルダを作成しているように見えますが、最終的には<code>vmfs/volumes/datastore1</code>にUbuntu22というフォルダにて復元されています。</p><p>ESXiの管理IDは特に意識しない場合も多いのですが、ブラウザからESXiの管理コンソールを起動せずにいきなり仮想マシンを起動する場合は、<code>vmrc://ユーザーID@ホスト名/?moid=管理ID</code>　ですぐに仮想マシン（GUI）にアクセスできますが、このIDが変更されているので、ESXi管理コンソールで新しいIDを確認する必要があります。</p><p>なお、これによってABBでバックアップしていた構成も変わることになるので、これまでタスク化されているバックアップは失敗することになりますので改めて仮想マシンの登録情報を編集しておく必要があります。</p><blockquote><p>警告,2023-09-03 12:42:22,前回のバージョンからのディスク [[datastore1] Ubuntu22&#x2F;Ubuntu22.vmdk] が見つかりません。それは削除されたか、あるいはパススルー、RDM、あるいは独立したディスクへ変更された可能性があります。バックアップ タスクはディスクをバックアップしません。</p></blockquote><p>このエラーは構成情報の変更を検知したという事でしょう。私はこの対策として、旧環境でのバックアップの定期的な実行を取りやめる設定に変更し、新しいバックアップタスクを改めて作成するようにしています。それでしばらく時間が経過してから古いバックアップファイルを削除することにしています。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>非常に簡単なGUI操作で後は殆ど気にすることなく定期的な仮想マシンのバックアップが行えます。速度も必要十分で特に指摘する点は見つかりません。仮想マシンの一部のファイルを取り出したいなどのニーズにも応えられますし、本格的なバックアップソフトウェアです。小規模なビジネスやホームユーザーには十分すぎる機能を持ち合わせていると言えるでしょう。</p><p>仮想環境としてESXiを選定するメリットとして、第一に使いやすさと安定性、セキュリティレベルが高いということが挙げられますが、こういったスタンダードなNASがESXiのバックアップをサポートしている事も大きなメリットではないでしょうか。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/09/16/Synology-abb/install.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;SynologyのNASでは無償版ESXiの仮想マシン（VM）バックアップが可能なActive Backup for Business(ABB)というソフトウェアが提供されています。Microsoft Hyper-V2016および2019にも対応しています。無償版ESXiのバックアップソフトは「&lt;a href=&quot;/new-technology/2021/03/06/esxi-nakivo/&quot; title=&quot;無償版ESXiの高度なバックアップ&quot;&gt;無償版ESXiの高度なバックアップ&lt;/a&gt;」で書いた有償のもの（1年期限の無償版）は存在します。無償バックアップソフトは無償版ESXiに対応していないという難しい状況でしたが、NASが必須という前提はあるものの、追加コストゼロでESXi仮想マシンのバックアップが可能です。エージェントレスで、ESXi本体やVMには何もインストールする必要はありません。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Synology&lt;br&gt; &lt;a href=&quot;https://www.synology.com/ja-jp/dsm/feature/active-backup-business/virtual-machine&quot;&gt;https://www.synology.com/ja-jp/dsm/feature/active-backup-business/virtual-machine&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="Network" scheme="https://yoshi0808.github.io/new-technology/categories/Network/"/>
    
    <category term="Software" scheme="https://yoshi0808.github.io/new-technology/categories/Software/"/>
    
    
    <category term="ESXi" scheme="https://yoshi0808.github.io/new-technology/tags/ESXi/"/>
    
    <category term="10GbE" scheme="https://yoshi0808.github.io/new-technology/tags/10GbE/"/>
    
    <category term="25GbE" scheme="https://yoshi0808.github.io/new-technology/tags/25GbE/"/>
    
    <category term="Synology" scheme="https://yoshi0808.github.io/new-technology/tags/Synology/"/>
    
  </entry>
  
  <entry>
    <title>Sophos Firewall v19.5 MR-3</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/08/20/xg-v195mr3/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/08/20/xg-v195mr3/</id>
    <published>2023-08-19T15:00:00.000Z</published>
    <updated>2023-08-20T00:20:19.429Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/08/20/xg-v195mr3/title.png" class="" title="alt"><h2 id="Sophos-Firewall-v19-5-MR3"><a href="#Sophos-Firewall-v19-5-MR3" class="headerlink" title="Sophos Firewall v19.5 MR3"></a>Sophos Firewall v19.5 MR3</h2><p>Sophos Firewall v19.5 MR3が2023年8月2日に発表されました。</p><span id="more"></span><h2 id="主なエンハンスの内容"><a href="#主なエンハンスの内容" class="headerlink" title="主なエンハンスの内容"></a>主なエンハンスの内容</h2><p>MR3では65以上のパフォーマンスおよび安定化・セキュリティ向上に対応しています。また、今後、リモートアクセス製品であるZTNAのセキュアアクセスに対応させる予定とのこと。<br>私の所感としては、これまでのSophos FirewallのVPNではそれなりに便利に活用していますが、ZTNAで透過的にリモートアプリケーションが利用できるようになるとの事であれば期待が持てます。但し、ZTNAの導入にはSophos Centralが必要であること（無料）、ZTNAの価格についてホームユーザーの扱いがどうなるかはまだ判明しないように見えます。<br>システム構成としてはActive Directoryとの統合連携など法人向けには必須の要件が含まれているので、ホームユーザーからは少し遠い存在になってしまうかもしれません。</p><p>v19.5 MR3の詳細な説明はRelease Notesを参照してください。</p><blockquote><p><a href="https://docs.sophos.com/releasenotes/index.html?productGroupID=nsg&amp;productID=xg&amp;versionID=19.5">https://docs.sophos.com/releasenotes/index.html?productGroupID=nsg&amp;productID=xg&amp;versionID=19.5</a></p></blockquote><p>Ipsec-VPNでSSL&#x2F;TLSインスペクションが動作しないという不具合の改善も含まれています。</p><h2 id="Sophos-Firewallのアップデート"><a href="#Sophos-Firewallのアップデート" class="headerlink" title="Sophos Firewallのアップデート"></a>Sophos Firewallのアップデート</h2><p>XGの管理画面にログイン後、左ペインメニューの<mark class="label primary">バックアップ＆ファームウェア</mark>の<mark class="label primary">ファームウェアの確認</mark>に通知が来る場合があります(以下はMR-2の画面です)。</p><img src="/new-technology/2023/08/20/xg-v195mr3/notice.png" class="" width="480" title="alt"><p>また、アップデートの案内が来ていなくても、MySophosにログインし、バージョンアップの差分モジュールをダウンロードします。</p><ol><li>Sophosのサイトの上部の「ソフォスについて」のプルダウンメニューから、<mark class="label primary">ライセンスとアカウント</mark>をクリックします。<blockquote><p><a href="https://www.sophos.com/ja-jp.aspx">https://www.sophos.com/ja-jp.aspx</a></p></blockquote></li><li>Sophos IDをお持ちでなければIDを作成します。</li><li>ログイン後、<mark class="label primary">Network Protection</mark>をクリックします。</li><li><mark class="label primary">Firmware Updates</mark>をクリックします。</li><li>「製品名&#x2F;OSを使った検索」で”Firewall”を選択し、その後現れるプルダウンは”Software”を選択します。</li><li><mark class="label primary">Show Available Downloads</mark>ボタンをクリックします。</li></ol><img src="/new-technology/2023/08/20/xg-v195mr3/mysophos.png" class="" width="800" title="alt"><ol><li>上記画面で”SW-19.5.3_MR-3.SFW-652.sig”というアップデータが表示されますのでダウンロードします。</li><li>MY Sophosはここで終了してXGの管理画面にログインし、左ペインメニューの<mark class="label primary">バックアップ＆ファームウェア</mark>の<mark class="label primary">ファームウェアのタブメニュー</mark>から以下の画面に赤丸で囲った矢印のアイコンをクリックし、ダウンロードしたモジュールをアップロードします。</li></ol><img src="/new-technology/2023/08/20/xg-v195mr3/verup.png" class="" width="800" title="alt"><p>アップロード＆再起動ボタンをクリックし、v19.5 MR3へのアップグレードを完了させます。</p><img src="/new-technology/2023/08/20/xg-v195mr3/upgrade.png" class="" width="800" title="alt"><div class="note info"><p>仮想環境（ESXi）上にFirewallをインストールされている方はアップグレードの前に、「<a href="/new-technology/2020/10/11/esxi-backup/" title="VMware ESXiの仮想マシンをバックアップする">VMware ESXiの仮想マシンをバックアップする</a>」を参考に、バックアップを確保される事をお勧めします。</p></div>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/08/20/xg-v195mr3/title.png&quot; class=&quot;&quot; title=&quot;alt&quot;&gt;

&lt;h2 id=&quot;Sophos-Firewall-v19-5-MR3&quot;&gt;&lt;a href=&quot;#Sophos-Firewall-v19-5-MR3&quot; class=&quot;headerlink&quot; title=&quot;Sophos Firewall v19.5 MR3&quot;&gt;&lt;/a&gt;Sophos Firewall v19.5 MR3&lt;/h2&gt;&lt;p&gt;Sophos Firewall v19.5 MR3が2023年8月2日に発表されました。&lt;/p&gt;</summary>
    
    
    
    <category term="Security" scheme="https://yoshi0808.github.io/new-technology/categories/Security/"/>
    
    
    <category term="XG Firewall" scheme="https://yoshi0808.github.io/new-technology/tags/XG-Firewall/"/>
    
  </entry>
  
  <entry>
    <title>Synology DS1621+（DSM7.2）とSSD</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/07/27/Synology1621plus-ssd/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/07/27/Synology1621plus-ssd/</id>
    <published>2023-07-27T02:00:00.000Z</published>
    <updated>2023-07-27T11:37:57.655Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/07/27/Synology1621plus-ssd/synology-title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p><p>サイバー攻撃の話題が相変わらず賑やかな状況下、これまで使っていたNASのソフトウェアの安定性やセキュリティ面の不安があり、安定感のあるSynologyのNASにリプレースしました。昨今SSDが安くなってきた事もあり、節電兼ねてALL SSDのNASをセットアップしてみました。</p><span id="more"></span><h2 id="前提（私の使い方）"><a href="#前提（私の使い方）" class="headerlink" title="前提（私の使い方）"></a>前提（私の使い方）</h2><p>私のNASの用途は、写真や動画のバックアップ、複数のPCで使う文書・PDFなどの同期兼バックアップ、仮想マシンやモジュールのバックアップ用途です。このブログなどはプライベートなものではないので、自宅で保存するよりGitHubのパブリッククラウドに置いておくほうがより現実的ではありますが、操作ミスで消えるリスクも鑑みNASにバックアップを取得しています。</p><p>今のところ、TVや映画などの動画を保存する用途にはしていないので、容量だけでいえば1ベイか2ベイのNASで10TBあれば十分です。特殊要素があるとすれば、仮想マシンのバックアップを頻繁に取得するので、できるだけバックアップ速度を求めます。そういう意味では10GbEのネットワークは必須です。</p><p>NASでは仮想マシンを稼働させる事もできますが、私の用途としてはESXiを一般的なPCにセットアップし、複数の仮想マシンを稼働させているので、NASはストレージがメインです。Windowsファイル共有（SMB）、NFS、iSCSI、せいぜいsyslog、SQLデータベースあたりまで使うといったところです。Ubuntuは個人向けにウィルス対策ソフトが存在しないので、Ubuntuのブラウザでインターネットにアクセスする事は殆どなく、モジュールのダウンロードは（ウィルス対策ソフトが有効な）macOSかWindowsでダウンロードしたものをSMBで共有してUbuntuで利用することが殆どです。</p><p>NASの使い方は利用者によって様々でしょうから、あくまで一例ということでご覧ください。</p><h2 id="Synology機種選定"><a href="#Synology機種選定" class="headerlink" title="Synology機種選定"></a>Synology機種選定</h2><p>6ベイ〜8ベイ程度のNASでそろそろ新モデルが出るかなと思い、年初くらいからウォッチしていましたが、発表されたのはDS1823xs+で、30万円と高額でした。周辺機器の互換性としてEnterpriseクラスの製品が中心で、個人向けとしては少し不向きだなと感じました。メモリは厳格に互換性を重視しつつも、SSDは必ずしも互換性のドライブでなくても良いかと考えていましたが、Enterpriseクラスの厳格性で10万円超えクラスの製品レベルを求められるとコスト面でかなり厳しいと感じました。現行モデルとの比較は以下の通りです。最初からSFP+のネットワークカードを増設する前提で、それなりにCPUパワーのある機種の比較です。10GbE以上の場合、どこまでスループットが出るかという期待も含めての選定です。</p><table><thead><tr><th>機種</th><th>CPU</th><th>CPU TDP</th><th>製造プロセス</th><th>ベイ</th><th>実売価格</th></tr></thead><tbody><tr><td>DS1823xs+</td><td>AMD Ryzen V1780B クアッド コア 3.35 GHz</td><td>45W</td><td>14nm</td><td>8</td><td>30万円</td></tr><tr><td>DS1821+</td><td>AMD Ryzen V1500B クアッド コア 2.2 GHz</td><td>16W</td><td>14nm</td><td>8</td><td>16万円</td></tr><tr><td>DS1621+</td><td>AMD Ryzen V1500B クアッド コア 2.2 GHz</td><td>16W</td><td>14nm</td><td>6</td><td>12.5万円</td></tr></tbody></table><p>意外にも、最新機種のDS1823xs+の製造プロセスは14nmで現行モデルと変わりません。DS1621+&#x2F;DS1821+の現行モデルは発売後2年半が経過しています。それなりに長期間使うことになるNASはEOSLを気にする必要があります。ただし、2012年モデルでもセキュリティパッチはきちんと提供されているので、Synologyのソフトウェア保守に対する考え方は非常にしっかりとしています。2018年に発表されたDS1618+（CPU:intel Atom C3538）は発売後5年でDiscontinuedになっていますが、あくまで製造中止であって、サポートはフルに提供されています。さらに、DS1621+&#x2F;DS1821+は新発表されたDS1823xs+とCPU世代が同じなので、長期的なサポート継続が行われると考えられます。</p><p>ちなみに、V1500BやV1780Bは2つの10GbEチップを内蔵しているんですね。ただし、DS1621+&#x2F;DS1821+には10GbEの口はありません。DS1823xs+は1つの10GbE(RJ45)があるのでその10GbEを活用しているということでしょうか。</p><p>ということで、Synologyはソフトウェアが秀逸である反面、少し高いというイメージを持っていたのですが、実売価格として廉価なDS1621+を購入することにしました。メモリが4GBなので、純正ECCメモリ（1.5万円）4GBを追加し8GBとしました。</p><p>Synologyの保守に関する注意点としては、購入後の保証期間が過ぎたハードウェアの有償修理は行われないという点です。特殊なハードウェアだと電源やファンなど代替品というのも簡単には見つからないのでそこだけが留意する点でしょうか。故障が気になる方は延長保証を検討する必要があります。私は故障した場合は「さだめ」と割り切って新しいハードウェアを買う理由が見つかるので延長保証にはしていません笑</p><blockquote><p>Synology 製品サポート状況<br> <a href="https://www.synology.com/ja-jp/products/status">https://www.synology.com/ja-jp/products/status</a></p></blockquote><h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><img src="/new-technology/2023/07/27/Synology1621plus-ssd/870evo.png" class="" width="320" title="alt"><p>Synologyとしては公式には互換性確認が取れていないSamsungの870EVO 4TB(MZ-77E4T0B&#x2F;IT)が28,000円程度だったこともあり、6つ購入しました（最初に1台購入し、動作確認の上で追加を5台買いました）。仕様は以下の通りTLCで速度、耐久性を重要視しました。</p><ul><li>インターフェース (転送速度・規格値）：SATA 3.0(6Gbps) ※SATA 2.0(3Gbps)およびSATA 1.0(1.5Gbps)互換フォームファクタ：7mm厚2.5インチHDD互換［搭載デバイス］NANDフラッシュ：Samsung 3bit MLC (TLC) V-NANDコントローラ：Samsung MKXコントローラキャッシュメモリ：2GB LPDDR4［パフォーマンス］シーケンシャル：読み出し560 MB&#x2F;s、書き込み：530 MB&#x2F;s</li><li>5年間または最大2,400TBWの限定保証</li></ul><p>4TBのSSDといえば、つい昨年は8万円くらいしていたと記憶していますが、廉価になるスピードも早いですね。世の中では半導体が不足していると言われる一方で、個人向けPCの販売不振によって、SSDなどのパーツが余剰在庫で値崩れしていると聞きますので、SSD全般に関しては今はお得な時期と言えるでしょう。</p><p>DS1621+にはM.2-2280のNVMeキャッシュも搭載可能ですが、SSD RAID5の分散であればキャッシュを必要としない程度に十分な速度が出るものと見込んでいます。キャッシュだけだと見かけのベンチマークは良い数字が出るでしょうが、安定して読み込み・書き込み速度を出すにはSSDでシンプルな構成が一番と考えます。</p><p>なお、このストレージのセットアップ時には互換性の無いDiskである警告メッセージが表示されます。また、Synologyアカウントのページには以下の記載があります。</p><blockquote><p>以下の状況ではテクニカル サポート サービスは提供されません。<br> Synology互換性リストに記載されていないデバイス（ドライブ、メモリモジュール、PCIeカードなど）を使用する。</p></blockquote><p>一度セットアップした後は警告メッセージは表示されていません。</p><p>NASというグループではなく、ConsumerというクラスでSynologyの互換性について検索すると、850EVO、860EVOが一覧に表示されます。何れ870EVOがサポート対象になるのを願うことにします。</p><blockquote><p>Synology 製品互換リスト（機種指定なし）<br> <a href="https://www.synology.com/ja-jp/compatibility?search_by=category&amp;category=hdds_no_ssd_trim&amp;filter_brand=Samsung&amp;filter_class=Consumer&amp;display_brand=other">https://www.synology.com/ja-jp/compatibility?search_by=category&amp;category=hdds_no_ssd_trim&amp;filter_brand=Samsung&amp;filter_class=Consumer&amp;display_brand=other</a></p></blockquote><p>なお、Synologyの互換性試験を軽んじているわけではありませんし、なるべくは互換性のあるものを使おうと考えてはいます。ただし、DS1621+に関してSSDはサードパーティ製で認められたものはなく、SynologyのEnterpriseドライブのみで4TBだと価格が15万円&#x2F;個なので、これは個人で購入するのは困難でしょう。<br>メモリやSSDキャッシュ用途であれば流石に互換性を重視した製品選定をしますが。。。</p><h2 id="NIC"><a href="#NIC" class="headerlink" title="NIC"></a>NIC</h2><img src="/new-technology/2023/07/27/Synology1621plus-ssd/mellanox.png" class="" width="640" title="alt"><p>このブログでは定番のMellanox Connect X4(MCX4121A-ACAT)を選定しました。ebayで1枚$70〜$80（日本円で約1万円）程度です。Synologyで正式に互換性検証されたものは、intel X710-T4がありますが、Connect X4は互換性リストにはありません。1つ昔のモデルのDS1618+はConnect X3には対応しているようです。Connect X4がダメなら純正のSFP28カードを購入するつもりでした。</p><p>前出の互換性リストを見ると、Mellanox Connect X4に対応しているSynology NASもそれなりの数があるようです。</p><blockquote><p>Synology 製品互換リスト<br> <a href="https://www.synology.com/ja-jp/compatibility?search_by=category&amp;category=network_interface_cards&amp;display_brand=other">https://www.synology.com/ja-jp/compatibility?search_by=category&amp;category=network_interface_cards&amp;display_brand=other</a></p></blockquote><h2 id="ハードウェアインストール"><a href="#ハードウェアインストール" class="headerlink" title="ハードウェアインストール"></a>ハードウェアインストール</h2><h3 id="メモリ"><a href="#メモリ" class="headerlink" title="メモリ"></a>メモリ</h3><p>筐体の底の部分に蓋があり、それを外すとメモリモジュールを挿すところがあります。シール付きの別売りモジュール（4GByte）を装着したところです。</p><img src="/new-technology/2023/07/27/Synology1621plus-ssd/memory.png" class="" width="640" title="alt"><h2 id="DiskStationManager（DSM）セットアップ"><a href="#DiskStationManager（DSM）セットアップ" class="headerlink" title="DiskStationManager（DSM）セットアップ"></a>DiskStationManager（DSM）セットアップ</h2><p>DS1621+は今更珍しいハードウェアでも無いですし、DSMのセットアップ情報も世の中に多くあるので、手順については省略します。最初はLAN1にRJ45のCat6ケーブルを接続しセットアップしました。インターネットに接続されている環境で無事DSM7.2のセットアップが完了しました。</p><p>論理Disk（ストレージプール）は初心者向けのSynology Hybrid RAID、または通常のRAIDを選択できますが、速度を重視し、RAID5としました。ダウンタイムを気にしてRAID6にするほど安全第一という事もなく、かといって、RAID0にして故障の際に大掛かりなリカバリのリスクを抱えたくも無いということで無難な選択です。6台のSSDすべてを1つの論理DISKとしてパリティの分散によって障害リスクの抑制、高速化を目指すことにします。</p><p>以前のNASでは、こういった論理ボリュームを作成後、利用するアプリケーションや目的毎のデータサイズによってストレージプールの中にそれぞれのボリュームを作成していました。例えば、macOSのバックアップであるTimeMachineなどでは、決められたディスクサイズの中で最新世代のバックアップを確保する仕組みとなっており、ディスクの容量を事前に決めておかないと（クオータ）、肥大し続ける事になります。PCで言えばパーティションのようなものですね。<br>また、別の目的では仮想マシンのバックアップなどは世代管理も含めて、どれだけのDisk容量を確保すべきかある程度運用しないとわかりません。意外と圧縮が効いて無駄にボリュームの空きができてしまう事はよくある課題です。また、複数ボリュームを作成するとスループットは落ちます。</p><p>NASはこの辺りの事前の計画がとても難しいのですが、DSM7では単一ボリュームに共有フォルダを作成する時にフォルダのサイズ制限を設定できます。これができればわざわざ複数ボリュームを悩みながら作成する事も不要です。これが実現できるのはSynologyがアピールするBtrfs（バターエフエス）ファイルシステムのおかげです。Btrfsではスナップショットを取得してバックアップする際、バックアップ中にファイルが更新されて一貫性が失われないとのことです。ファイルシステムもデータベースの仕組みに近くなっていくんでしょうか。</p><blockquote><p>Synology ナレッジセンター</p></blockquote><p> <a href="https://kb.synology.com/ja-jp/DSM/help/DSM/AdminCenter/file_share_create?version=7#sharedfolderquota">https://kb.synology.com/ja-jp/DSM/help/DSM/AdminCenter/file_share_create?version=7#sharedfolderquota</a><br> <div class="note info"><p>ストレージがBtrfsファイル システムを使用している場合に限り、共有スペースに共有スペースの割り当てを有効にするオプションをできますます。</p></div></p><p>ESXiの仮想マシンのバックアップのために、 SynologyのActive Backup for Businessを使うつもりですので、これは64ビットOSとBtrfsが必須となります。Disk構成は以下のようになりました。</p><img src="/new-technology/2023/07/27/Synology1621plus-ssd/volume.drawio.png" class="" width="480" title="alt"><img src="/new-technology/2023/07/27/Synology1621plus-ssd/synology1.png" class="" width="800" title="alt"><h2 id="消費電力"><a href="#消費電力" class="headerlink" title="消費電力"></a>消費電力</h2><p>SSD6台、Mellanox Connect X4を装着した状態で、ワットチェッカーで計測してみました。以下の通り、おおよそ33W-35W程度で安定しています。なかなかの省電力です。以前に利用していたNASは4台のHDDという事もあり、70W-100W程度でかなり発熱も大きかったのがかなり改善されました。</p><ul><li><p>Synology（SSDx6、Mellanox Connect X4）<br> （33W-35W）</p> <img src="/new-technology/2023/07/27/Synology1621plus-ssd/wchecker1.png" class="" width="360" title="alt"></li><li><p>旧NAS（HDDx4、Mellanox Connect X3）<br> （70W-100W）</p> <img src="/new-technology/2023/07/27/Synology1621plus-ssd/wchecker2.png" class="" width="360" title="alt"></li></ul><h2 id="ネットワーク"><a href="#ネットワーク" class="headerlink" title="ネットワーク"></a>ネットワーク</h2><p>セットアップ終了後、無事Connect X4はNASに以下のように認識されていました。</p><blockquote><p><code>25000 Mbps, 全二重, MTU 1500</code></p></blockquote><p>2つのPortがあるので、1つは25GbE、もう1つは10GbEとして使ってみます。</p><p>お決まりのiperf3の計測です。Connect X4をSFP28でスイッチに接続します。クライアントはWindows11でこちらもConnect X4です。<br>Synologyのコミュニティから提供されているSynoCli Monitor Toolsというパッケージがあり、これをインストールして使ってみます。<br>この組み合わせでは上り、下り共に19〜21Gbps程度であり、及第点という感じでした。</p><p>Windows -&gt; Synology（多重度2）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[ ID] Interval           Transfer     Bitrate</span><br><span class="line">[SUM]   0.00-10.00  sec  22.3 GBytes  19.1 Gbits/sec                  sender</span><br><span class="line">[SUM]   0.00-10.00  sec  22.3 GBytes  19.1 Gbits/sec                  receiver</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Synology NASとESXi上のUbuntuのiPerf3の結果は上り、下り共に十分なパフォーマンスが出ています。</p><p>Synology -&gt; Ubuntu</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[ ID] Interval           Transfer     Bitrate</span><br><span class="line">[  5]   0.00-1.00   sec  2.33 GBytes  20.0 Gbits/sec</span><br><span class="line">[  5]   1.00-2.00   sec  2.59 GBytes  22.3 Gbits/sec</span><br><span class="line">[  5]   2.00-3.00   sec  2.72 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   3.00-4.00   sec  2.59 GBytes  22.2 Gbits/sec</span><br><span class="line">[  5]   4.00-5.00   sec  2.71 GBytes  23.3 Gbits/sec</span><br><span class="line">[  5]   5.00-6.00   sec  2.72 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   6.00-7.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   7.00-8.00   sec  2.70 GBytes  23.2 Gbits/sec</span><br><span class="line">[  5]   8.00-9.00   sec  2.70 GBytes  23.2 Gbits/sec</span><br><span class="line">[  5]   9.00-10.00  sec  2.69 GBytes  23.1 Gbits/sec</span><br><span class="line">- - - - - - - - - - - - - - - - - - - - - - - - -</span><br><span class="line">[ ID] Interval           Transfer     Bitrate         Retr</span><br><span class="line">[  5]   0.00-10.00  sec  26.5 GBytes  22.7 Gbits/sec   22             sender</span><br><span class="line">[  5]   0.00-10.00  sec  26.5 GBytes  22.7 Gbits/sec                  receiver</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Disk速度"><a href="#Disk速度" class="headerlink" title="Disk速度"></a>Disk速度</h2><p>定番のCrystal Diskmarkのベンチマークを実施します。</p><h3 id="25GbE-SFP28-で計測"><a href="#25GbE-SFP28-で計測" class="headerlink" title="25GbE(SFP28)で計測"></a>25GbE(SFP28)で計測</h3><img src="/new-technology/2023/07/27/Synology1621plus-ssd/DiskMark25gbE.png" class="" width="480" title="alt"><p>読み込みは17Gbps、書き込みは14.3Gbpsと、かなり高いスループットが出ています。11Gbps-12Gbps程度であれば省電力を優先し10Gbpsで使おうと考えていましたが、迷いどころです。私が速度を重視するメインの使い道はESXiの仮想マシンのバックアップですので、それはまた別の機会に計測してみます。</p><h3 id="10GbE-SFP-で計測"><a href="#10GbE-SFP-で計測" class="headerlink" title="10GbE(SFP+)で計測"></a>10GbE(SFP+)で計測</h3> <img src="/new-technology/2023/07/27/Synology1621plus-ssd/DiskMark10gbE.png" class="" width="480" title="alt"><p> 10GbEの場合は、読み込み、書き込みともにワイヤレートが出ており、バランスの良い組み合わせでしょうか。NICをSFP+の10GbEにして、もう5W程度省電力を狙うというのも良いですね。</p><h3 id="25GbE-SFP28-にパケット署名を付けて計測"><a href="#25GbE-SFP28-にパケット署名を付けて計測" class="headerlink" title="25GbE(SFP28)にパケット署名を付けて計測"></a>25GbE(SFP28)にパケット署名を付けて計測</h3> <img src="/new-technology/2023/07/27/Synology1621plus-ssd/DiskMark25GbE-PacketSign.png" class="" width="480" title="alt"><p>ビジネスではセキュリティの観点からほぼ必須と指摘されるSMBのパケット署名ですが、意外と落ち込まないですね。これも実運用するには十分な速度が出ています。</p><h2 id="その他、素晴らしい機能"><a href="#その他、素晴らしい機能" class="headerlink" title="その他、素晴らしい機能"></a>その他、素晴らしい機能</h2><p>以前のNASからリプレースして便利に感じた機能をいくつか挙げてみます。</p><ul><li>2要素認証（TouchID、Windows Hello）<br> DSMに2要素認証でログインする場合は、圧倒的に便利です。パスワードレスでTouchID、Windows Helloのみの認証にもできます。<br> なお、YubiKeyのFIDO2も使えますが、PINもあって少し不便に感じます。YubiKeyはDSMへのSSHを公開鍵認証で使っています。iOSアプリのSecure SignInは自宅にいない場合に公衆回線を通じて2要素認証のためのサインインの通知が来るのは良いのですが、許可をタップするとNASへ直接接続しようとするようで、自宅のWi-Fiに接続していない場合は認証がうまく動作しません。これはいずれ機能アップして修正されることを期待します。SynologyのNASはTailScaleのアプリがインストールできるので、これを組み合わせる事で対応できるかもしれません。</li></ul><blockquote><p>tailscale<br>  <a href="https://tailscale.com/">https://tailscale.com</a></p></blockquote><ul><li>ログセンター（Syslog）<br> グラフィカルで分かりやすいです。ネットワーク機器のログを集めるのに使っています。このおかげでSyslogのために別の仮想マシンを用意する必要は無さそうです。以前のNASではフィルタ機能が十分でなく、使っていませんでした。Synologyでは演算子を使っていろいろな条件で絞り込みができます。個人でのログ確認には必要十分です。<img src="/new-technology/2023/07/27/Synology1621plus-ssd/syslog.png" class="" width="800" title="alt"></li></ul><p> 絞り込みも優秀で、ホスト名を入力させるのではなく、すでにログ出力されているホスト名から選択できます。<br>  <img src="/new-technology/2023/07/27/Synology1621plus-ssd/syslog2.png" class="" width="800" title="alt"></p><ul><li><p>ストレージアナライザー</p> <img src="/new-technology/2023/07/27/Synology1621plus-ssd/analyzer.png" class="" width="1024" title="alt">  <p> ファイルサイズの大きいもの順に確認できたり、重複ファイルを確認、削除できます。データの見える化ができて、とても便利です。</p></li><li><p>ファイアウォール<br> これはアプリケーションの自動ブロックと連動していて、このブロックが働いた時、つまり明らかな不正ログインの懸念がある場合のみ通知されます。ですので、普段から通知されることはありません。以前のNASでは許可していないサービスにIPレベルでパケットが到達した段階でエラーとカウントして膨大な件数の拒否カウントが定期的に通知されており、結局通知を止めていたのですが、こちらは現実的なファイアウォール機能となっています。</p><blockquote><p>さまざまなサービスとパッケージが自動ブロックをサポートします。例：DSM、SSH、Telnet、rsync、ネットワーク バックアップ、共有フォルダの同期、FTP、SMB、WebDAV、File Station、Audio Station、Video Station、Download Station、Mail Server、Mail Station、MailPlus、MailPlus Server、VPN Server、Synology Drive Server、および Synology モバイル アプリ。</p></blockquote></li><li><p>Synology Drive<br>　NASでは一般的な機能で、複数クライアント端末とファイル同期を取るソリューションです。以前のNASでは小さいモジュールがたくさん存在するフォルダ、特にGitで使うようなソースコードや小さいモジュールのファイルは、<em>conflict</em>(0)のような競合ファイルがたくさん発生してしまい、全く使えずにいました。GitHubへのプッシュする際に大量の誤ったプッシュ候補のファイルが表示されてしまい、泣く泣く変更したファイルをロールバックする羽目になりました。他の端末との同時更新などの競合がある訳ではなかったのですが、それ以来、一般的な文書のみに使っていました。今回、SynologyのNASになってからはまだ日が浅いですが、このような小さいモジュール群も安定して複製してくれ、複数端末で同期が取れています。</p></li><li><p>DSM画面のレスポンスが良いこと<br>　どのアプリケーションを稼働させても、ウィンドウがもたつくことはありません。</p></li></ul><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>SSDが安くなったおかげで、今回は廉価にNASのリプレースが出来ました。SSDキャッシュはベンチマークこそ良い成績が出ますが、実際の運用においてはなかなか効果を感じづらいところがあります。NVMeではなくSATAなので大きな期待はしていませんでしたが、かなりの速度が出ることを確認できました。私の利用方法は少し特殊と考えられますが、Synologyのソフトウェアが素晴らしいことで、NASを利用している時のストレスが本当に減りました。<br>前述したSyslogや重複ファイルのチェックなど、本当にユーザーフレンドリーで使いやすく他社のNASから乗り換えた時にはこのDSM7.2を使うと、その使い勝手の良さに驚かれるでしょう。またストレージの消費量もかなり低く抑えられています。最近、SynologyはエントリーモデルにおいてもBtrfsに対応するようになったので廉価でも高性能なNASとして利用できそうです。今はNASのバックアップを外付けのHDDにしていますが、あまりに使い勝手が良いので廉価なビジネスモデルにリモートコピーでバックアップを取得するのでも良いかなと思い始めています。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/07/27/Synology1621plus-ssd/synology-title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;

&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;サイバー攻撃の話題が相変わらず賑やかな状況下、これまで使っていたNASのソフトウェアの安定性やセキュリティ面の不安があり、安定感のあるSynologyのNASにリプレースしました。昨今SSDが安くなってきた事もあり、節電兼ねてALL SSDのNASをセットアップしてみました。&lt;/p&gt;</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    <category term="Network" scheme="https://yoshi0808.github.io/new-technology/categories/Network/"/>
    
    
    <category term="10GbE" scheme="https://yoshi0808.github.io/new-technology/tags/10GbE/"/>
    
    <category term="25GbE" scheme="https://yoshi0808.github.io/new-technology/tags/25GbE/"/>
    
    <category term="Synology" scheme="https://yoshi0808.github.io/new-technology/tags/Synology/"/>
    
  </entry>
  
  <entry>
    <title>ESXi8.0をRyzen5 5600Gで構築</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/07/07/building-setup-esxi8/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/07/07/building-setup-esxi8/</id>
    <published>2023-07-07T00:58:48.000Z</published>
    <updated>2024-01-30T05:33:58.738Z</updated>
    
    <content type="html"><![CDATA[<p class="onepoint">この記事で実現すること</p><p>1年半前に、「<a href="/new-technology/2022/02/27/building-setup-esxi7/" title="ESXI7.0をRyzen7 5700Gで構築">ESXI7.0をRyzen7 5700Gで構築</a>」の記事で、Ryzen7 5700GでESXi7のセットアップをしました。今回はESXi8.0の動作確認も含めてRyzen5 5600Gでセットアップしました。</p><span id="more"></span><h2 id="ご注意事項"><a href="#ご注意事項" class="headerlink" title="ご注意事項"></a>ご注意事項</h2><p>2024&#x2F;1&#x2F;22に発表されたVMWareブログによりますと、スタンドアロン製品の提供を終了し、サブスクリプションモデルに変更されることとなりました。この無償版ESXiは今後提供停止となりますが、サポートは継続されるとの事です。<br>無償版ESXiの利用にあたっては、まずこちらの記事「<a href="/new-technology/2024/01/30/EOS-Free-esxi/" title="VMWare 無償版ESXiの提供終了について">VMWare 無償版ESXiの提供終了について</a>」を参照されることをお勧めします。</p><h2 id="ESXi8のためのハードウェア選定検討"><a href="#ESXi8のためのハードウェア選定検討" class="headerlink" title="ESXi8のためのハードウェア選定検討"></a>ESXi8のためのハードウェア選定検討</h2><p>実は最初からESXi8をセットアップするつもりはなく、WindowsPCを新調するつもりでした。私はゲームはやらないので、せいぜい4Kのビデオが見られれば十分というPCの使い方をしており、ビデオカードを購入する事は殆どありません。パソコン工房で「STYLE-S0P5-R55G-EZX」という5600Gを積んだ機種が8万円台と安かった事もあり、あまり深くは考えずに注文しました。</p><blockquote><p>パソコン工房<br> <a href="https://www.pc-koubou.jp/">https://www.pc-koubou.jp</a></p></blockquote><h2 id="ハードウェア構成"><a href="#ハードウェア構成" class="headerlink" title="ハードウェア構成"></a>ハードウェア構成</h2><p>注文したPCは以下の構成でした。<br>【OS】Windows 11 Home<br>　【プロセッサー】AMD Ryzen 5 5600Gプロセッサー (3.9-4.4GHz&#x2F;6コア&#x2F;12スレッド&#x2F;16MBキャッシュ&#x2F;TDP 65W)<br>　【CPU冷却グリス】【熱伝導率： 9W&#x2F;m K】 シルバーグリスArctic Silver 5塗布サービス<br>　【CPUクーラー】静音CPUクーラー Wraith Stealth[トップフロー]<br>　【グラフィックアクセラレーター】Radeon Graphics(CPU統合グラフィックス）<br>　【メインメモリ】16GB(8GB×2)[DDR4-3200 &#x2F; デュアルチャンネル］<br>　【1stストレージ［OSインストール］】500GB SSD &#x2F; NVMe M.2[PCIe 3.0×4]<br>　【チップセット】AMD B550チップセット<br>　【サウンド機能】High Definition Audio subsystem<br>　【内蔵ネットワークカード】有線：1000BASE-T ※無線機能はついておりません<br>　【光学ドライブ】DVDスーパーマルチドライブ［LG GH24NSxx]<br>　【電源】400W[80PLUS BRONZE認証］&#x2F; TFX電源<br>　【ケース】スリムタイプMicroATXケースHEC 7KJC[フロントUSB3.0]ブラック</p><p>さて、PCが届いてから、ハードウェアを確認したところ、NVMeはウェスタンデジタルのBlueが組み込まれていました。また、マザーボードはASRock社のものです。そういえば、前回のESXi7.0のセットアップでは、セキュアブートは断念していました。Win11 Homeがセットアップされているモデルでしたが、WDのBlue（SN570）が入っていた事もあり、ふつふつとESXi8.0をインストールしたいと思い始め、ESXi8をクリーンインストールする事にしました。</p><h3 id="ストレージ"><a href="#ストレージ" class="headerlink" title="ストレージ"></a>ストレージ</h3><p>前回は、VMware Commmunityで鉄板だった970EVO Plusでした。ESXiではSamsungが確実という印象でしたが、980 Pro NVMeでは、ファームウェアの不具合で故障率が高いという報告が上がっています。ESXiはNVMeストレージの種類を選ぶため事前調査が必要ですが、今回、何となくうまく行くだろう感があってBlue（SN570）にESXi8をセットアップしました。結果、全く問題ありませんでした。なぜかESXiの事例としてあまり出てこないのが不思議です。。。</p><p>うまく行かなければ、William Lam氏のNVMeに関する情報で、SabrentのRocket Plus NVMeを試そうと思っていたところでした。<br><a href="https://williamlam.com/2023/02/quick-tip-additional-nvme-vendors-sk-hynix-sabrent-for-esxi-homelab.html">https://williamlam.com/2023/02/quick-tip-additional-nvme-vendors-sk-hynix-sabrent-for-esxi-homelab.html</a></p><h3 id="ネットワークカード"><a href="#ネットワークカード" class="headerlink" title="ネットワークカード"></a>ネットワークカード</h3><p>前回は、intelのX710のSFP+4Portを使いましたが、今回はSFP28の検証も兼ねてMellanox Connect X-5を選定しました。Connect X-4はWindowsやNASで使おうと計画してます。前回はセキュアブートがうまく行かなかった点は課題でしたが、実はそれが功を奏したところもありました。X710のESXiのドライバーはデフォルトではフローコントロール（pauseパラメータ）がオフになっています。それで、ブート時に、<code>/etc/rc.local.d/local.sh</code>にpauseパラメータを有効にする設定を加えていました。もし、セキュアブートであれば、<code>/etc/rc.local.d/local.sh</code>にスクリプトを記述しても無視されます。</p><h3 id="UEFIの設定"><a href="#UEFIの設定" class="headerlink" title="UEFIの設定"></a>UEFIの設定</h3><p>さて、UEFIのリベンジです。色々な情報をこれまで収集し、セキュアブートの初期化をすればセキュアブートが可能と調べがついていました。</p><p>最初、Secure Boot Modeを<mark class="label primary">Custom</mark>に変更し、<mark class="label primary">Install default Secure Boot keys</mark>を実施した上でセットアップしましたが、セキュアブートでインストールされませんでした。以下のページでGIGABYTEのマザーということでセキュアブートに関する情報がありました。</p><p><a href="https://support.pcdiy.newx.co.jp/hc/ja/articles/6572156997657--GIGABYTE%E3%83%9E%E3%82%B6%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E5%85%A8%E8%88%AC-Secure-Boot-%E3%81%AE%E8%A8%AD%E5%AE%9A%E6%96%B9%E6%B3%95%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6">https://support.pcdiy.newx.co.jp/hc/ja/articles/6572156997657--GIGABYTEマザーボード全般-Secure-Boot-の設定方法について</a></p><blockquote><p><strong>Restore Factory Keys</strong> を選択していただき、ポップアップが表示されますのでYes(はい)を選択してください</p></blockquote><p>今回のマザーボードはASRockですが、以下の手順でセキュアブートにできました。</p><ol><li><mark class="label primary">Secure Boot Mode</mark>を<mark class="label primary">Normal</mark>から<mark class="label primary">Custom</mark>に変更する。</li><li><mark class="label primary">Clear Secure Boot Keys</mark>を実行する</li><li><mark class="label primary">Install default Secure Boot keys</mark>を実行する。</li><li><mark class="label primary">Secure Boot Mode</mark>を<mark class="label primary">Normal</mark>に戻す。</li></ol><p>この手順を踏んでセットアップ開始したところ、無事セキュアブートが可能になりました。無償版ESXiはTPMは使えませんので、単に改ざん防止という事になります。<br>簡単な確認方法として、セキュアブートが有効である場合、ESXiの管理コンソールの<mark class="label primary">セキュリティとユーザー</mark>の許容レベルをパートナーからコミュニティに変更できなくなります。また、前述した<code>local.sh</code>もスキップされます。</p><h2 id="インストール"><a href="#インストール" class="headerlink" title="インストール"></a>インストール</h2><p>これまで同様、Rufusで32GBのUSBメモリにISOファイルを登録しUSBブートからESXi8.0Update1aをセットアップします。<br>なお、セットアップされる場合はVMWareのサイトで最新のバージョンを確認下さい。</p><p>VMWare ESXi8.0<br><a href="https://customerconnect.vmware.com/jp/evalcenter?p=free-esxi8">https://customerconnect.vmware.com/jp/evalcenter?p=free-esxi8</a></p><img src="/new-technology/2023/07/07/building-setup-esxi8/esxi1.png" class="" width="800" title="alt"><p>メーカーはiiyamaなのに、なんでMouseComputerなんだろう。。。</p><h2 id="ネットワーク"><a href="#ネットワーク" class="headerlink" title="ネットワーク"></a>ネットワーク</h2><p>ドライバーはnmlx5_coreとなっています。SFP28のDACケーブルをスイッチに接続し、vmnic0が25Gbpsでリンクアップしています。</p><img src="/new-technology/2023/07/07/building-setup-esxi8/esxi2.png" class="" width="800" title="alt"><p>ESXi8にセットアップしたUbuntu22ではOS上は10GbEと認識していますが、速度は23Gbps近くは出ています。</p><img src="/new-technology/2023/07/07/building-setup-esxi8/ubuntu1.png" class="" width="640" title="alt"><p>Ubuntuからの送信</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">yoshi@ub22:~$ iperf3 -c 192.168.x.20</span><br><span class="line">Connecting to host 192.168.x.20, port 5201</span><br><span class="line">[  5] <span class="built_in">local</span> 192.168.x.182 port 47676 connected to 192.168.x.20 port 5201</span><br><span class="line">[ ID] Interval           Transfer     Bitrate         Retr  Cwnd</span><br><span class="line">[  5]   0.00-1.00   sec  2.61 GBytes  22.4 Gbits/sec  6519    967 KBytes</span><br><span class="line">[  5]   1.00-2.00   sec  2.54 GBytes  21.9 Gbits/sec  5013   1.01 MBytes</span><br><span class="line">[  5]   2.00-3.00   sec  2.50 GBytes  21.4 Gbits/sec  3376    667 KBytes</span><br><span class="line">[  5]   3.00-4.00   sec  2.57 GBytes  22.1 Gbits/sec  5961    612 KBytes</span><br><span class="line">[  5]   4.00-5.00   sec  2.53 GBytes  21.8 Gbits/sec  4767    648 KBytes</span><br><span class="line">[  5]   5.00-6.00   sec  2.57 GBytes  22.1 Gbits/sec  6294    765 KBytes</span><br><span class="line">[  5]   6.00-7.00   sec  2.55 GBytes  21.9 Gbits/sec  4271    489 KBytes</span><br><span class="line">[  5]   7.00-8.00   sec  2.56 GBytes  22.0 Gbits/sec  3493    573 KBytes</span><br><span class="line">[  5]   8.00-9.00   sec  2.55 GBytes  21.9 Gbits/sec  5756    789 KBytes</span><br><span class="line">[  5]   9.00-10.00  sec  2.58 GBytes  22.2 Gbits/sec  4816    546 KBytes</span><br><span class="line">- - - - - - - - - - - - - - - - - - - - - - - - -</span><br><span class="line">[ ID] Interval           Transfer     Bitrate         Retr</span><br><span class="line">[  5]   0.00-10.00  sec  25.6 GBytes  22.0 Gbits/sec  50266             sender</span><br><span class="line">[  5]   0.00-10.00  sec  25.6 GBytes  22.0 Gbits/sec                  receiver</span><br><span class="line"></span><br><span class="line">iperf Done.</span><br></pre></td></tr></table></figure><p>Ubuntuの受信</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">yoshi@ub22:~$ iperf3 -c 192.168.x.20 -R</span><br><span class="line">Connecting to host 192.168.x.20, port 5201</span><br><span class="line">Reverse mode, remote host 192.168.x.20 is sending</span><br><span class="line">[  5] <span class="built_in">local</span> 192.168.x.182 port 44930 connected to 192.168.x.20 port 5201</span><br><span class="line">[ ID] Interval           Transfer     Bitrate</span><br><span class="line">[  5]   0.00-1.00   sec  2.68 GBytes  23.0 Gbits/sec</span><br><span class="line">[  5]   1.00-2.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   2.00-3.00   sec  2.72 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   3.00-4.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   4.00-5.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   5.00-6.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   6.00-7.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   7.00-8.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   8.00-9.00   sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">[  5]   9.00-10.00  sec  2.73 GBytes  23.4 Gbits/sec</span><br><span class="line">- - - - - - - - - - - - - - - - - - - - - - - - -</span><br><span class="line">[ ID] Interval           Transfer     Bitrate         Retr</span><br><span class="line">[  5]   0.00-10.00  sec  27.2 GBytes  23.4 Gbits/sec  279             sender</span><br><span class="line">[  5]   0.00-10.00  sec  27.2 GBytes  23.4 Gbits/sec                  receiver</span><br><span class="line"></span><br><span class="line">iperf Done</span><br></pre></td></tr></table></figure><p>受信は25Gbpsのワイヤレートが出ています。<br>Ubuntuからの送信側では再送が多いようです。これはまだESXiの構成または設定の問題なのか私の環境の問題なのかは分かっていません。<br>NVidiaのサイトのInboxドライバの情報はESXi8.0向けは4.23.0.36-8vmwという事になっています。</p><blockquote><p>NVIDIA Native Drivers for VMware ESXi Inbox Drivers Release Notes<br> <a href="https://docs.nvidia.com/networking/display/VMwareESXiInboxDriversReleaseNotes">https://docs.nvidia.com/networking/display/VMwareESXiInboxDriversReleaseNotes</a></p></blockquote><p>なお、最新のESXi8.0Update1aでのMellanoxのドライバのバージョンは以下の通りです。NVidiaのサイトのものよりも新しいですね。これはまた次回にドライバが更新されるかもしれません。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost:~] esxcli software vib list | grep nmlx</span><br><span class="line">nmlx5-core                     4.23.0.36-14vmw.801.0.0.21495797     VMW     VMwareCertified   2023-04-29    host</span><br><span class="line">nmlx5-rdma                     4.23.0.36-14vmw.801.0.0.21495797     VMW     VMwareCertified   2023-04-29    host</span><br></pre></td></tr></table></figure><p>色々な情報を探してみてもやはりESXi7.0の情報は充実しており、まだESXi8.0は安定というには早いかなと感じます。</p><h2 id="ESXiにおけるNICのフローコントロールについて"><a href="#ESXiにおけるNICのフローコントロールについて" class="headerlink" title="ESXiにおけるNICのフローコントロールについて"></a>ESXiにおけるNICのフローコントロールについて</h2><p>ESXiにはフローコントロールの制御について、送信、受信のpauseパラメータを設定できます。<br>Connect X-5を使っている状況でESXiにSSHし、以下のコマンドでpauseパラメータの状況が確認できます。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost:~] esxcli network nic pauseParams list</span><br><span class="line">NIC     Pause Params Supported  Pause RX  Pause TX  Auto Negotiation  Auto Negotiation Resolution Avail  RX Auto Negotiation Resolution  TX Auto Negotiation Resolution</span><br><span class="line">------  ----------------------  --------  --------  ----------------  ---------------------------------  ------------------------------  ------------------------------</span><br><span class="line">vmnic0                    <span class="literal">true</span>      <span class="literal">true</span>      <span class="literal">true</span>             <span class="literal">false</span>                              <span class="literal">false</span>                           <span class="literal">false</span>                           <span class="literal">false</span></span><br><span class="line">vmnic1                    <span class="literal">true</span>      <span class="literal">true</span>      <span class="literal">true</span>             <span class="literal">false</span>                              <span class="literal">false</span>                           <span class="literal">false</span>                           <span class="literal">false</span></span><br></pre></td></tr></table></figure><p><code>Pause Params Supported</code>が<code>true</code>の場合は、フローコントロールの機能を持っています。Pause RXがfalseだとスイッチからpauseフレームの通知を無視してしまいます。またPause TXがfalseだと自身が飽和した時にpauseフレームを送信しません。上記ではデフォルトでフローコントロールがオンになっています。</p><p>一方、ESXi7.0のintel x710では、以下の結果になりました。Pause RX&#x2F;TXがfalseとなっています。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@esxi2:~] esxcli network nic pauseParams list</span><br><span class="line">NIC     Pause Params Supported  Pause RX  Pause TX  Auto Negotiation  Auto Negotiation Resolution Avail  RX Auto Negotiation Resolution  TX Auto Negotiation Resolution</span><br><span class="line">------  ----------------------  --------  --------  ----------------  ---------------------------------  ------------------------------  ------------------------------</span><br><span class="line">vmnic0                    true     false     false             false                              false                           false                           false</span><br><span class="line">vmnic1                    true     false     false             false                              false                           false                           false</span><br><span class="line">vmnic2                    true     false     false             false                              false                           false                           false</span><br><span class="line">vmnic3                    true     false     false             false                              false                           false                           false</span><br></pre></td></tr></table></figure><p>この場合は、前述した、<code>/etc/rc.local.d/local.sh</code>にフローコントロールをOnにするコマンドを列挙します。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">esxcli network nic pauseParams set -n vmnic0 -t t -r t</span><br><span class="line">esxcli network nic pauseParams set -n vmnic1 -t t -r t</span><br><span class="line">esxcli network nic pauseParams set -n vmnic2 -t t -r t</span><br><span class="line">esxcli network nic pauseParams set -n vmnic3 -t t -r t</span><br></pre></td></tr></table></figure><p>繰り返しですが、これはセキュアブートではない場合にのみ設定が可能です。<br>10GbEとWi-Fiなど、<strong>速度差がある端末同士で効率の良い通信を行うためにはフローコントロールは必要</strong>と言えます。フローコントロールが無い場合、私の環境ではWi-Fi6のiperf3の例では900Mbps→750Mbps程度には劣化します。Wi-Fi電波の範囲ギリギリとかWi-Fiの別のAPへのローミングなどセンシティブな箇所で安定度が高まるとお考えください。</p><p>フローコントロールはこのようにホスト側での設定とネットワークスイッチ側と双方で有効にしておく必要があります。</p><p>なお、ESXiにおいて少し高度な話としては、Single Root I&#x2F;O Virtualization（SR-IOV）による仮想マシンにNIC（NICが持つ仮想機能）を直接割り当てる方法で高速化する方法もあります。Windows ServerやRed Hat Enterprise LinuxなどOSを選びますが今後機会があればテストしてみます。</p><img src="/new-technology/2023/07/07/building-setup-esxi8/esxi3.png" class="" width="800" title="alt"><p>※ESXi上のUbuntuはSR-IOVに対応していません。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>25GbEはあくまで実験的に検証しているものであり、私自身がパワーユーザーではない事もあり、今のところメインは10GbEとし、スイッチ間を25GbEで使うつもりでいます。ただし、アプリケーション同士で9Gbps程度の速度が25GbE環境下で出ているからといって、ネットワークを10Gbpsに変更しても影響が出ないかと言われるとそうでもなく、7Gbps程度に落ち込むケースも確認できています。今後色々検証していきたいと考えています。このブログで紹介している25GbEは簡単に接続できているように見えますが、私の使っているネットワークスイッチ（Ubiquiti PRO Aggregationスイッチ）とMellanox Connect Xカードとの相性が良い事もあります。</p>]]></content>
    
    
    <summary type="html">&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;1年半前に、「&lt;a href=&quot;/new-technology/2022/02/27/building-setup-esxi7/&quot; title=&quot;ESXI7.0をRyzen7 5700Gで構築&quot;&gt;ESXI7.0をRyzen7 5700Gで構築&lt;/a&gt;」の記事で、Ryzen7 5700GでESXi7のセットアップをしました。今回はESXi8.0の動作確認も含めてRyzen5 5600Gでセットアップしました。&lt;/p&gt;</summary>
    
    
    
    <category term="Hardware" scheme="https://yoshi0808.github.io/new-technology/categories/Hardware/"/>
    
    
    <category term="ESXi" scheme="https://yoshi0808.github.io/new-technology/tags/ESXi/"/>
    
    <category term="25GbE" scheme="https://yoshi0808.github.io/new-technology/tags/25GbE/"/>
    
  </entry>
  
  <entry>
    <title>VMware ESXiを8.0にアップグレードする</title>
    <link href="https://yoshi0808.github.io/new-technology/2023/06/18/esxi-upgrade8/"/>
    <id>https://yoshi0808.github.io/new-technology/2023/06/18/esxi-upgrade8/</id>
    <published>2023-06-17T22:00:00.000Z</published>
    <updated>2024-01-30T05:47:22.321Z</updated>
    
    <content type="html"><![CDATA[<img src="/new-technology/2023/06/18/esxi-upgrade8/title.png" class="" width="1024" title="alt"><p class="onepoint">この記事で実現すること</p><p>無償版ESXi（VMware vSphere Hypervisor）について、ESXi8.0U1にアップグレードします。最新のESXiは8.0U2となっています。</p><span id="more"></span><h2 id="ご注意事項"><a href="#ご注意事項" class="headerlink" title="ご注意事項"></a>ご注意事項</h2><p>2024&#x2F;1&#x2F;22に発表されたVMWareブログによりますと、スタンドアロン製品の提供を終了し、サブスクリプションモデルに変更されることとなりました。この無償版ESXiは今後提供停止となりますが、サポートは継続されるとの事です。<br>無償版ESXiの利用にあたっては、まずこちらの記事「<a href="/new-technology/2024/01/30/EOS-Free-esxi/" title="VMWare 無償版ESXiの提供終了について">VMWare 無償版ESXiの提供終了について</a>」を参照されることをお勧めします。</p><h2 id="ESXiのアップグレード"><a href="#ESXiのアップグレード" class="headerlink" title="ESXiのアップグレード"></a>ESXiのアップグレード</h2><p>まず正式なアップグレードに関するドキュメントがVMwareより提供されており、こちらでポイントを確認します。アップデートとアップグレードとは異なります。<br>ESXiのバージョン体系は、”x”.”y” update “z” ビルド番号 という並びで表現されます。</p><ul><li>アップグレードは、前2桁（x,y）を上げることを指します。</li><li>アップデートは、前2桁が変わりません。それ以降の数字があるケース、またはUpdate”z”などの形式があります。Update2を省略してU2、さらにU2a、U2cなど英数字が上がっていきます。</li></ul><p><strong>アップデート</strong>によってこれまで動いていたハードウェアが動かなくなるという事は大々的にはおきません（ドライバーの更新によって認識しなくなったりうまく動作しないという一般的な理由はあります）。<strong>アップグレード</strong>ではハードウェアのサポート対象の見直しが入ります。</p><blockquote><p>ESXiのアップグレード<br> <a href="https://docs.vmware.com/jp/VMware-vSphere/8.0/vsphere-esxi-80-upgrade-guide.pdf">https://docs.vmware.com/jp/VMware-vSphere/8.0/vsphere-esxi-80-upgrade-guide.pdf</a></p></blockquote><p>例によってVMwareのマニュアルは法人向けにvCenter Serverを中心に記載されているのでポイントを無償版ESXiに絞ります。</p><ul><li>VMWare互換性ガイドでアップグレードが可能か確認する（P8）</li><li>ESXi8のハードウェア要件（P17）</li><li>アップグレード後はDiskのパーティション要件にてロールバック不可（P19）</li><li>esxcliコマンドまたはISOブートからのアップグレードの2種類がある（P37,P70）</li><li>アップグレードには新たにESXi8.0向けの（無償版ESXiの）ライセンスを登録する（P87）</li><li>仮想マシンとVMware Toolsのアップグレード（P11）</li></ul><p>注意点は以下の通りです。</p><blockquote><p>esxcliコマンドを使用してアップグレードすると、古いバージョンのESXiは新しいVIBのインストールを実行するため、署名が保存されずセキュアブートは実行できません。ISOを使用してアップグレードすると、新しいVIBは署名を保存できます。（P88）</p></blockquote><p>上記の注意点の通り、UEFIのセキュアブートで稼働しているESXiのバージョンアップにはISOを使用してアップグレードすべきと読めます。一方、セキュアブートでなければ、<code>esxcli software profile update --depot=&lt;depot_location&gt; --profile=&lt;profile_name&gt; </code>のコマンドでアップグレード可能です。詳細は、「<a href="/new-technology/2020/06/14/esxi67-patch/" title="VMware ESXiにパッチを適用する">VMware ESXiにパッチを適用する</a>」の記事を参照してください。但し、ESXi8.0におけるハードウェア互換性が維持できるか慎重に確認するためには、ISOでのアップグレードを検討してください。</p><p>VMware互換性ガイドは個人向けのハードウェアが殆ど列挙されておらずチェックが困難なのが実態です。ハードウェアが準拠しているかどうかのチェックについては後述します。</p><p>また、上記マニュアルには注意点としての記載がありませんが、スナップショットを取得していない状態でアップグレードされる事をお勧めします。</p><p>ESXi8にアップグレードする例を記載しています。厳密なアップグレードパスについては以下を確認してください。</p><img src="/new-technology/2023/06/18/esxi-upgrade8/upgradepath.png" class="" width="640" title="alt"><p><a href="https://interopmatrix.vmware.com/Upgrade?productId=1363">https://interopmatrix.vmware.com/Upgrade?productId=1363</a></p><blockquote><p>vCenter Server Back-in-time release<br> <a href="https://kb.vmware.com/s/article/67077#vCenterServer_7.0.x_to_8.0_upgrade_matrix">https://kb.vmware.com/s/article/67077#vCenterServer_7.0.x_to_8.0_upgrade_matrix</a></p></blockquote><h2 id="仮想マシンのバックアップ（任意）"><a href="#仮想マシンのバックアップ（任意）" class="headerlink" title="仮想マシンのバックアップ（任意）"></a>仮想マシンのバックアップ（任意）</h2><p>バージョンアップの前には仮想マシンのバックアップを別の筐体またはメディアに取得される事をお勧めします。「<a href="/new-technology/2020/10/11/esxi-backup/" title="VMware ESXiの仮想マシンをバックアップする">VMware ESXiの仮想マシンをバックアップする</a>」の記事を参照してください。ghettoVCBを使ったバックアップでは、ESXiにsshした上で、次のコマンドで全ての仮想マシンのバックアップ取得が可能です。<code>/bin/sh ./ghettoVCB.sh -a</code></p><h2 id="アップグレード対象のESXi8-0を確認する"><a href="#アップグレード対象のESXi8-0を確認する" class="headerlink" title="アップグレード対象のESXi8.0を確認する"></a>アップグレード対象のESXi8.0を確認する</h2><p>ESXiのISOインストーラのダウンロードは、2023年9月23日時点ではESXi8.0 Update2となっています。</p><blockquote><p>VMware vSphere Hypervisor 8.0 ダウンロード センター(※VMware Customer Connectへログインが必要です)<br> <a href="https://customerconnect.vmware.com/jp/evalcenter?p=free-esxi8">https://customerconnect.vmware.com/jp/evalcenter?p=free-esxi8</a></p></blockquote><h2 id="ESXi8-0インストールメディア（USB）の作成"><a href="#ESXi8-0インストールメディア（USB）の作成" class="headerlink" title="ESXi8.0インストールメディア（USB）の作成"></a>ESXi8.0インストールメディア（USB）の作成</h2><p>ここではUSBメモリを用意し、ESXi8.0のインストーラーをセットアップします。<br>事前にハードウェア互換リストを元に互換性があるかチェックしたいところですが、実際に個人向けのハードウェアは殆ど列挙されていません。</p><blockquote><p>VMware Compatibility Guide<br> <a href="https://www.vmware.com/resources/compatibility/search.php">https://www.vmware.com/resources/compatibility/search.php</a></p></blockquote><p>以前は検証のためにUSB上にESXi7.0をセットアップできましたが、 ESXi8からはUSBへのテストセットアップできなくなっています。ハードウェアが準拠せずアップグレード後起動しない、NICが利用できない可能性があるため、仮想マシンのバックアップを確保される事をお勧めします。なお、個人向けのハードウェアで関係するところは、Mellanox Connect X-3がサポート対象外となりました。Mellanoxユーザーとしては、Connect X-4&#x2F;X-5を使う事になるでしょう。</p><h3 id="ESXi8-0-インストーラーのダウンロード"><a href="#ESXi8-0-インストーラーのダウンロード" class="headerlink" title="ESXi8.0 インストーラーのダウンロード"></a>ESXi8.0 インストーラーのダウンロード</h3><p>以下からISOをダウンロードします。</p><p><a href="https://customerconnect.vmware.com/jp/web/vmware/evalcenter?p=free-esxi8">https://customerconnect.vmware.com/jp/web/vmware/evalcenter?p=free-esxi8</a></p><p>ダウンロードは、”VMware vSphere Hypervisor (ESXi ISO) image”をダウンロードします。</p><p>また、製品のライセンスキーが表示されていますので、メモを取っておいてください。</p><h3 id="Rufusによるisoメディアの作成"><a href="#Rufusによるisoメディアの作成" class="headerlink" title="Rufusによるisoメディアの作成"></a>Rufusによるisoメディアの作成</h3><p>以下のサイトからRufusをWindowsでダウンロードし実行します。</p><blockquote><p>Rufus<br> <a href="https://rufus.ie/ja/">https://rufus.ie/ja/</a></p></blockquote><p> 以下のオプションでUSBメディアにESXi8のインストーラーを書き込みます。</p> <img src="/new-technology/2023/06/18/esxi-upgrade8/rufus1.png" class="" width="480" title="alt"><p> UEFIのセキュアブートに対応させるためにはGPTとUEFIを選択してください。</p><h2 id="ESXi8-0へのアップグレード"><a href="#ESXi8-0へのアップグレード" class="headerlink" title="ESXi8.0へのアップグレード"></a>ESXi8.0へのアップグレード</h2><p>以下の動画を参考にしてください。特に難しいものはありません。途中、新規インストールかアップグレードか選択する箇所があります。この動画では新規インストールを選択していますが、アップグレードを選んでください。</p><blockquote><p><a href="https://www.youtube.com/watch?v=eiZn54GPfzI">https://www.youtube.com/watch?v=eiZn54GPfzI</a></p></blockquote><img src="/new-technology/2023/06/18/esxi-upgrade8/install.png" class="" width="1024" title="alt"><p>アップグレードが終了し、再起動する際にはUSBメディアは外してください。</p><p>無事再起動したら管理画面にログインします。<br>sshでESXiに接続し、<code>esxcli system version get</code>を実行し確認します。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost:~] esxcli system version get</span><br><span class="line">   Product: VMware ESXi</span><br><span class="line">   Version: 8.0.1</span><br><span class="line">   Build: Releasebuild-21495797</span><br><span class="line">   Update: 1</span><br><span class="line">   Patch: 0</span><br><span class="line">[root@localhost:~]</span><br></pre></td></tr></table></figure><p>管理画面でもESXi8になっていることは確認できますし、<code>vmware -l</code>コマンドでも確認できますが、Versionとビルド番号で見るには上記コマンドを使います。</p><h2 id="後処理"><a href="#後処理" class="headerlink" title="後処理"></a>後処理</h2><p>無事アップグレードが成功したら、以下の作業を行います。</p><ol><li>ESXi8.0のライセンス登録<br> ESXiにログイン後、左ペインメニューの<mark class="label primary">ホスト</mark>-<mark class="label primary">管理</mark>から<mark class="label primary">ライセンスタブ</mark>を選択し、<mark class="label primary">ライセンスの割り当て</mark>でダウンロード時に控えたライセンスキーを登録します。</li><li>ESXi8.0の最新パッチ適用<br> ESXiのパッチ適用については、「<a href="/new-technology/2020/06/14/esxi67-patch/" title="VMware ESXiにパッチを適用する">VMware ESXiにパッチを適用する</a>」を参照してください。</li><li>ESXi8.0の構成情報のバックアップ（任意）</li></ol><h2 id="仮想マシンのアップグレード（任意）"><a href="#仮想マシンのアップグレード（任意）" class="headerlink" title="仮想マシンのアップグレード（任意）"></a>仮想マシンのアップグレード（任意）</h2><p>ESXiのバージョンアップ後、仮想マシンのバージョンをアップグレードできます。</p><p>アップグレードしたESXi8.0VMware Toolsよりも新しいバージョンがある場合は以下のように表示されます。</p><img src="/new-technology/2023/06/18/esxi-upgrade8/vmwaretools2.png" class="" width="640" title="alt"><p>この場合はWebUIで左ペインの<mark class="label primary">仮想マシン</mark>で対象仮想マシンを選択し、<mark class="label primary">アクション</mark>メニュー→<mark class="label primary">ゲストOS</mark>から<mark class="label primary">VMware Toolsのアップグレード</mark>を実行します。</p><p>詳細は以下の内容を参照してください。</p><blockquote><p>VMware Tools のアップグレード<br> <a href="https://docs.vmware.com/jp/VMware-Tools/11.3.0/com.vmware.vsphere.vmwaretools.doc/GUID-A2491004-1C67-4E14-B47B-807E20C19108.html">https://docs.vmware.com/jp/VMware-Tools/11.3.0/com.vmware.vsphere.vmwaretools.doc/GUID-A2491004-1C67-4E14-B47B-807E20C19108.html</a></p></blockquote><p>VMware Toolsを最新にした後、仮想マシンハードウェアをアップグレードすることができます。ただし、下記のドキュメントに注意書きがある通り、新しいハードウェアバージョンの付属機能が必要な場合のみ実行することとあり、これはESXiのアップグレードに対して必須事項ではありません。</p><blockquote><p>仮想マシンの互換性の手動アップグレード<br> <a href="https://docs.vmware.com/jp/VMware-vSphere/7.0/com.vmware.vsphere.vm_admin.doc/GUID-60768C2F-72E1-42E0-8A17-CA76849F2950.html">https://docs.vmware.com/jp/VMware-vSphere/7.0/com.vmware.vsphere.vm_admin.doc/GUID-60768C2F-72E1-42E0-8A17-CA76849F2950.html</a></p></blockquote><div class="note warning"><ul><li>仮想マシン ハードウェアをアップグレードすると、一部のアプリケーションまたはオペレーティング システムが適切に動作しなくなることがあります。ハードウェア バージョンのアップグレードは、新しいハードウェア バージョンの付属機能が必要な場合のみ実行します。</li><li>Microsoft Windows 仮想マシンで VMware Tools をアップグレードする前に互換性をアップグレードすると、仮想マシンのネットワーク設定が失われることがあります。</li></ul></div><p>この操作は以下の通りWebUIで左ペインの<mark class="label primary">仮想マシン</mark>で対象仮想マシンを選択し、<mark class="label primary">アクション</mark>メニューから<mark class="label primary">仮想マシンの互換性のアップグレード</mark>を実行します。</p><img src="/new-technology/2023/06/18/esxi-upgrade8/upgrade-vm.png" class="" width="800" title="alt"><h2 id="構成情報のバックアップ（任意）"><a href="#構成情報のバックアップ（任意）" class="headerlink" title="構成情報のバックアップ（任意）"></a>構成情報のバックアップ（任意）</h2><p>今後、パッチ適用を重ねていきますが、ある時点にロールバックしたいと思った時に、ホスト構成バックアップから戻す必要が出てきます。パッチを当てる度に構成情報のバックアップを取得されることをお勧めします。</p><p>参考にするドキュメントはこちらです。</p><blockquote><p>ESXi ホストの構成のバックアップ方法 (2042141)<br> <a href="https://kb.vmware.com/s/article/2042141?lang=ja">https://kb.vmware.com/s/article/2042141?lang=ja</a></p></blockquote><ol><li>SSHでESXiに接続します。</li><li>ストレージの確実な同期のためのコマンド<code>vim-cmd hostsvc/firmware/sync_config</code>を実行します。</li><li>バックアップコマンド<code>vim-cmd hostsvc/firmware/backup_config</code>を実行します。</li><li>画面にダウンロードパスが表示されるのでそのURLにブラウザから接続し構成情報をダウンロードします。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@esxi:~] vim-cmd hostsvc/firmware/sync_config</span><br><span class="line">[root@esxi:~] vim-cmd hostsvc/firmware/backup_config</span><br><span class="line">Bundle can be downloaded at : http://*/downloads/52ce000f-cad4-20c0-078d-a111fa1ad82x/configBundle-esxi.local.tgz</span><br><span class="line">[root@esxi:~]</span><br></pre></td></tr></table></figure><p>先頭に<code>http://*/</code>とありますが、ここはESXiのホスト名またはIPアドレスを指定しブラウザからアクセスします。例えば、<code>http://192.168.1.1/downloads〜</code>という具合です。万が一レストアが必要になってしまった場合はバックアップを取得したバージョンのパッチを適用の上、メンテナンスモードに移行してから<code>vim-cmd hostsvc/firmware/restore_config /your_backup_location/configBundle-esxi.local.tgz</code>で戻します。バックアップを取得してから既にハードウェア構成が変わっていたりする場合は戻せない場合があります。仮想マシンはデータストアブラウザから再登録する必要があります。詳細は上記VMwareのドキュメントを参照してください。</p>]]></content>
    
    
    <summary type="html">&lt;img src=&quot;/new-technology/2023/06/18/esxi-upgrade8/title.png&quot; class=&quot;&quot; width=&quot;1024&quot; title=&quot;alt&quot;&gt;
&lt;p class=&quot;onepoint&quot;&gt;この記事で実現すること&lt;/p&gt;

&lt;p&gt;無償版ESXi（VMware vSphere Hypervisor）について、ESXi8.0U1にアップグレードします。最新のESXiは8.0U2となっています。&lt;/p&gt;</summary>
    
    
    
    <category term="Software" scheme="https://yoshi0808.github.io/new-technology/categories/Software/"/>
    
    
    <category term="ESXi" scheme="https://yoshi0808.github.io/new-technology/tags/ESXi/"/>
    
  </entry>
  
</feed>
